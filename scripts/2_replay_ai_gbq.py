–ê–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è Render
import json
import os
import time
import hashlib
import random
import sys
from datetime import datetime
from playwright.sync_api import sync_playwright
from google.cloud import bigquery
from google.oauth2 import service_account
from googleapiclient.discovery import build
from googleapiclient.http import MediaFileUpload
import zipfile
import tempfile

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –∫–æ—Ä–Ω—é –ø—Ä–æ–µ–∫—Ç–∞
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# –ò–º–ø–æ—Ä—Ç –Ω–∞—Å—Ç—Ä–æ–µ–∫ (–∫–∞–∫ –≤ –ø–µ—Ä–≤–æ–º —Å–∫—Ä–∏–ø—Ç–µ)
try:
    from config.settings import settings
    print("‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–∑ config.settings")
except ImportError:
    print("‚ö†Ô∏è config.settings –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è")
    class MockSettings:
        GOOGLE_APPLICATION_CREDENTIALS = os.environ.get('GOOGLE_APPLICATION_CREDENTIALS', '/etc/secrets/bigquery-credentials.json')
        BQ_PROJECT_ID = os.environ.get('BQ_PROJECT_ID', 'codellon-dwh')
        BQ_DATASET_ID = os.environ.get('BQ_DATASET_ID', 'amplitude_session_replay')
        BQ_TABLE_URLS = os.environ.get('BQ_TABLE_URLS', 'session_replay_urls')
        GDRIVE_FOLDER_ID = os.environ.get('GDRIVE_FOLDER_ID', '1K8cbFU2gYpvP3PiHwOOHS1KREqdj6fQX')
        COOKIES = os.environ.get('COOKIES', '[]')  # JSON —Å—Ç—Ä–æ–∫–∞
        PROCESSING_LIMIT = int(os.environ.get('PROCESSING_LIMIT', '10'))
        MIN_DURATION_SECONDS = int(os.environ.get('MIN_DURATION_SECONDS', '20'))
    
    settings = MockSettings()

USER_AGENTS = [
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.0 Safari/605.1.15",
    "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36",
]

class RenderScreenshotCollector:
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è Render –æ–∫—Ä—É–∂–µ–Ω–∏—è"""
        self.credentials_path = settings.GOOGLE_APPLICATION_CREDENTIALS
        self.bq_project_id = settings.BQ_PROJECT_ID
        self.bq_dataset_id = settings.BQ_DATASET_ID
        self.bq_table_id = settings.BQ_TABLE_URLS
        self.gdrive_folder_id = settings.GDRIVE_FOLDER_ID
        self.processing_limit = settings.PROCESSING_LIMIT
        self.min_duration = settings.MIN_DURATION_SECONDS
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º cookies –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è
        self.cookies = self._load_cookies_from_env()
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Ä–µ–∂–∏–º–∞
        self.safety_settings = {
            'min_delay': 2,
            'max_delay': 4,
            'batch_size': 5,  # –ú–µ–Ω—å—à–µ –¥–ª—è Render
            'batch_pause_min': 30,
            'batch_pause_max': 60,
            'name': 'RENDER_AUTO'
        }
        
        self.full_table_name = f"`{self.bq_project_id}.{self.bq_dataset_id}.{self.bq_table_id}`"
        
        print("üîê –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –¥–ª—è Render...")
        self._init_bigquery()
        self._init_google_drive()

    def _load_cookies_from_env(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ cookies –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è"""
        try:
            cookies_json = settings.COOKIES
            if cookies_json:
                cookies = json.loads(cookies_json)
                print(f"‚úÖ Cookies –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è ({len(cookies)} –∑–∞–ø–∏—Å–µ–π)")
                return cookies
            else:
                print("‚ö†Ô∏è COOKIES –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫")
                return []
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ cookies: {e}")
            return []

    def _init_bigquery(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è BigQuery"""
        try:
            if not os.path.exists(self.credentials_path):
                raise FileNotFoundError(f"Credentials —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {self.credentials_path}")
            
            credentials = service_account.Credentials.from_service_account_file(
                self.credentials_path,
                scopes=["https://www.googleapis.com/auth/bigquery"]
            )
            self.bq_client = bigquery.Client(credentials=credentials, project=self.bq_project_id)
            print("‚úÖ BigQuery –ø–æ–¥–∫–ª—é—á–µ–Ω")
        except Exception as e:
            raise Exception(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ BigQuery: {e}")

    def _init_google_drive(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Google Drive"""
        try:
            credentials = service_account.Credentials.from_service_account_file(
                self.credentials_path,
                scopes=['https://www.googleapis.com/auth/drive']
            )
            self.drive_service = build('drive', 'v3', credentials=credentials)
            print("‚úÖ Google Drive –ø–æ–¥–∫–ª—é—á–µ–Ω")
        except Exception as e:
            raise Exception(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Google Drive: {e}")

    def get_unprocessed_urls(self):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –Ω–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö URL —Å –ª–∏–º–∏—Ç–æ–º"""
        query = f"""
        SELECT 
            session_replay_url,
            amplitude_id,
            session_replay_id,
            duration_seconds,
            events_count,
            record_date
        FROM {self.full_table_name}
        WHERE is_processed = FALSE
        AND duration_seconds >= {self.min_duration}
        ORDER BY record_date DESC
        LIMIT {self.processing_limit}
        """

        print(f"üîç –ü–æ–ª—É—á–∞–µ–º –Ω–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ URL (–ª–∏–º–∏—Ç: {self.processing_limit})...")
        
        try:
            result = self.bq_client.query(query).result()
            urls_data = []
            for row in result:
                urls_data.append({
                    'url': row.session_replay_url,
                    'amplitude_id': row.amplitude_id,
                    'session_replay_id': row.session_replay_id,
                    'duration_seconds': row.duration_seconds,
                    'events_count': row.events_count,
                    'record_date': row.record_date.strftime('%Y-%m-%d')
                })
            print(f"üìä –ù–∞–π–¥–µ–Ω–æ {len(urls_data)} –Ω–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö URL")
            return urls_data
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è URL: {e}")
            raise

    def mark_url_as_processed(self, url, success=True, screenshots_count=0, drive_folder_id=None):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ URL –≤ BigQuery"""
        try:
            update_query = f"""
            UPDATE {self.full_table_name}
            SET 
                is_processed = TRUE,
                processed_datetime = CURRENT_TIMESTAMP(),
                screenshots_count = @screenshots_count,
                drive_folder_id = @drive_folder_id
            WHERE session_replay_url = @url
            """
            job_config = bigquery.QueryJobConfig(
                query_parameters=[
                    bigquery.ScalarQueryParameter("url", "STRING", url),
                    bigquery.ScalarQueryParameter("screenshots_count", "INTEGER", screenshots_count),
                    bigquery.ScalarQueryParameter("drive_folder_id", "STRING", drive_folder_id)
                ]
            )
            self.bq_client.query(update_query, job_config=job_config).result()
            status = "‚úÖ" if success else "‚ö†Ô∏è"
            print(f"{status} URL –æ—Ç–º–µ—á–µ–Ω –∫–∞–∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π (—Å–∫—Ä–∏–Ω—à–æ—Ç–æ–≤: {screenshots_count})")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å—Ç–∞—Ç—É—Å–∞ URL: {e}")

    # ... (–æ—Å—Ç–∞–ª—å–Ω—ã–µ –º–µ—Ç–æ–¥—ã –æ—Å—Ç–∞—é—Ç—Å—è —Ç–∞–∫–∏–º–∏ –∂–µ, –Ω–æ —É–±–∏—Ä–∞–µ–º –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã)
    
    def get_session_id_from_url(self, url):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è ID —Å–µ—Å—Å–∏–∏ –∏–∑ URL"""
        url_hash = hashlib.md5(url.encode()).hexdigest()[:8]
        if "sessionReplayId=" in url:
            parts = url.split("sessionReplayId=")[1].split("&")[0].split("/")
            session_replay_id = parts[0]
            session_start_time = parts[1] if len(parts) > 1 else "unknown"
            return f"{session_replay_id}_{session_start_time}_{url_hash}"
        return f"no_session_id_{url_hash}"

    def wait_for_content(self, page, selector, bad_texts=("Loading", "Loading summary"), 
                        timeout=10, min_text_length=10):
        """–û–∂–∏–¥–∞–Ω–∏–µ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""
        print(f"‚è≥ –ñ–¥–µ–º –∑–∞–≥—Ä—É–∑–∫—É –∫–æ–Ω—Ç–µ–Ω—Ç–∞ (—Ç–∞–π–º–∞—É—Ç {timeout} —Å–µ–∫)...")
        start = time.time()
        last_log = 0
        
        while True:
            el = page.query_selector(selector)
            if el:
                txt = el.inner_text().strip()
                if txt and all(bad not in txt for bad in bad_texts) and len(txt) >= min_text_length:
                    print(f"‚úÖ –ö–æ–Ω—Ç–µ–Ω—Ç –∑–∞–≥—Ä—É–∂–µ–Ω –∑–∞ {time.time() - start:.1f} —Å–µ–∫")
                    return el
            
            elapsed = time.time() - start
            if elapsed - last_log >= 3:
                print(f"‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ... {elapsed:.1f}/{timeout} —Å–µ–∫")
                last_log = elapsed
            
            if elapsed > timeout:
                print(f"‚ö†Ô∏è –ö–æ–Ω—Ç–µ–Ω—Ç –Ω–µ –∑–∞–≥—Ä—É–∑–∏–ª—Å—è –∑–∞ {timeout} —Å–µ–∫")
                return None
            
            time.sleep(0.5)

    def simulate_human_behavior(self, page):
        """–ò–º–∏—Ç–∞—Ü–∏—è —á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–≥–æ –ø–æ–≤–µ–¥–µ–Ω–∏—è"""
        try:
            # –î–≤–∏–∂–µ–Ω–∏—è –º—ã—à–∏
            for _ in range(random.randint(2, 4)):
                x = random.randint(200, 1200)
                y = random.randint(200, 700)
                page.mouse.move(x, y, steps=random.randint(5, 15))
                time.sleep(random.uniform(0.1, 0.3))
            
            # –°–∫—Ä–æ–ª–ª
            if random.random() < 0.4:
                scroll_amount = random.randint(100, 500)
                direction = random.choice([1, -1])
                page.evaluate(f"window.scrollBy(0, {scroll_amount * direction})")
                time.sleep(random.uniform(0.5, 1.5))
        except Exception:
            pass

    def create_and_upload_session_archive(self, session_dir, session_id):
        """–°–æ–∑–¥–∞–Ω–∏–µ –∏ –∑–∞–≥—Ä—É–∑–∫–∞ –∞—Ä—Ö–∏–≤–∞ –≤ Google Drive"""
        try:
            archive_name = f"session_replay_{session_id}_{int(time.time())}.zip"
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
            with tempfile.NamedTemporaryFile(suffix='.zip', delete=False) as temp_file:
                archive_path = temp_file.name
            
            with zipfile.ZipFile(archive_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
                for root, dirs, files in os.walk(session_dir):
                    for file in files:
                        file_path = os.path.join(root, file)
                        arcname = os.path.relpath(file_path, session_dir)
                        zipf.write(file_path, arcname)
            
            print(f"üì¶ –°–æ–∑–¥–∞–Ω –∞—Ä—Ö–∏–≤: {archive_name}")
            
            # –ó–∞–≥—Ä—É–∑–∫–∞ –≤ Google Drive
            file_metadata = {
                'name': archive_name,
                'parents': [self.gdrive_folder_id]
            }
            media = MediaFileUpload(archive_path, resumable=True)
            uploaded_file = self.drive_service.files().create(
                body=file_metadata,
                media_body=media,
                fields='id, name, webViewLink'
            ).execute()
            
            if uploaded_file:
                print(f"‚òÅÔ∏è –ê—Ä—Ö–∏–≤ –∑–∞–≥—Ä—É–∂–µ–Ω –≤ Google Drive")
                print(f"üîó ID —Ñ–∞–π–ª–∞: {uploaded_file.get('id')}")
                
                # –û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
                import shutil
                shutil.rmtree(session_dir, ignore_errors=True)
                os.unlink(archive_path)
                
                return uploaded_file
            else:
                print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∞—Ä—Ö–∏–≤")
                return None
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –∞—Ä—Ö–∏–≤–∞: {e}")
            return None

    def process_single_url(self, page, url_data):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ URL"""
        url = url_data['url']
        session_id = self.get_session_id_from_url(url)
        print(f"‚ñ∂Ô∏è –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–µ—Å—Å–∏—é: {session_id}")
        
        try:
            # –ü–µ—Ä–µ—Ö–æ–¥ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É
            self.simulate_human_behavior(page)
            page.goto(url, timeout=30000)
            time.sleep(random.uniform(2, 5))
            
            # –ü–æ–∏—Å–∫ –∏ –∫–ª–∏–∫ –ø–æ Summary
            summary_tab = page.query_selector("text=Summary")
            if summary_tab:
                self.simulate_human_behavior(page)
                summary_tab.click()
                print("üñ±Ô∏è –ö–ª–∏–∫–Ω—É–ª–∏ –Ω–∞ Summary")
                time.sleep(random.uniform(3, 6))
                summary_el = self.wait_for_content(page, 'p.ltext-_uoww22', timeout=10)
            else:
                print("‚ùå –í–∫–ª–∞–¥–∫–∞ Summary –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!")
                return False, 0
            
            # –°–æ–∑–¥–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è —Å–∫—Ä–∏–Ω—à–æ—Ç–æ–≤
            session_dir = tempfile.mkdtemp(prefix=f"session_{session_id}_")
            screenshot_paths = []
            
            # –°–æ–∑–¥–∞–Ω–∏–µ —Å–∫—Ä–∏–Ω—à–æ—Ç–æ–≤ (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)
            try:
                # User Info
                userinfo_path = self.screenshot_userinfo_block(page, session_id, session_dir)
                if userinfo_path:
                    screenshot_paths.append(userinfo_path)
                
                # Summary
                summary_paths = self.screenshot_summary_flexible(page, session_id, session_dir, summary_el)
                screenshot_paths.extend(summary_paths)
                
                # Sentiment
                sentiment_path = self.screenshot_by_title(page, "Sentiment", session_id, session_dir)
                if sentiment_path:
                    screenshot_paths.append(sentiment_path)
                
                # Actions
                actions_path = self.screenshot_by_title(page, "Actions", session_id, session_dir)
                if actions_path:
                    screenshot_paths.append(actions_path)
                
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Å–∫—Ä–∏–Ω—à–æ—Ç–æ–≤: {e}")
                return False, 0
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
            valid_screenshots = [p for p in screenshot_paths if p and os.path.exists(p)]
            screenshots_count = len(valid_screenshots)
            
            if screenshots_count < 2:
                print(f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Å–∫—Ä–∏–Ω—à–æ—Ç–æ–≤: {screenshots_count}")
                return False, screenshots_count
            
            # –°–æ–∑–¥–∞–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
            metadata = {
                "session_id": session_id,
                "url": url_data['url'],
                "amplitude_id": url_data['amplitude_id'],
                "session_replay_id": url_data['session_replay_id'],
                "duration_seconds": url_data['duration_seconds'],
                "events_count": url_data['events_count'],
                "record_date": url_data['record_date'],
                "processed_at": datetime.now().isoformat(),
                "screenshots": [os.path.basename(path) for path in valid_screenshots],
                "screenshots_count": screenshots_count
            }
            
            metadata_path = os.path.join(session_dir, "metadata.json")
            with open(metadata_path, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, ensure_ascii=False, indent=2)
            
            # –ó–∞–≥—Ä—É–∑–∫–∞ –≤ Google Drive
            uploaded_file = self.create_and_upload_session_archive(session_dir, session_id)
            
            if uploaded_file:
                return True, screenshots_count
            else:
                return False, screenshots_count
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ URL: {e}")
            return False, 0

    # –£–ø—Ä–æ—â–µ–Ω–Ω—ã–µ –º–µ—Ç–æ–¥—ã —Å–∫—Ä–∏–Ω—à–æ—Ç–æ–≤ (–±–µ–∑ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏)
    def screenshot_userinfo_block(self, page, session_id, base_dir):
        """–°–∫—Ä–∏–Ω—à–æ—Ç –±–ª–æ–∫–∞ —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ"""
        try:
            # –ü–æ–∏—Å–∫ –±–ª–æ–∫–∞ —Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
            css_selector = '.cerulean-cardbase.cerulean-alpha-general-card'
            elements = page.query_selector_all(css_selector)
            
            for element in elements:
                try:
                    text = element.inner_text().strip()
                    bbox = element.bounding_box()
                    if (bbox and bbox['y'] < 400 and text and 
                        len(text) > 10 and len(text) < 500):
                        img_path = os.path.join(base_dir, f"{session_id}_userinfo.png")
                        element.screenshot(path=img_path)
                        print("‚úÖ User info —Å–∫—Ä–∏–Ω—à–æ—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω")
                        return img_path
                except Exception:
                    continue
            
            print("‚ö†Ô∏è User info –±–ª–æ–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return None
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–∫—Ä–∏–Ω—à–æ—Ç–∞ user info: {e}")
            return None

    def screenshot_summary_flexible(self, page, session_id, base_dir, summary_el=None):
        """–°–∫—Ä–∏–Ω—à–æ—Ç –±–ª–æ–∫–∞ Summary"""
        try:
            el = summary_el
            if not el:
                el = self.wait_for_content(page, 'p.ltext-_uoww22', timeout=3)
            
            if el:
                text_content = el.inner_text().strip()
                if len(text_content) > 20:
                    img_path = os.path.join(base_dir, f"{session_id}_summary.png")
                    el.screenshot(path=img_path)
                    print("‚úÖ Summary —Å–∫—Ä–∏–Ω—à–æ—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω")
                    return [img_path]
            
            print("‚ùå Summary –±–ª–æ–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return []
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–∫—Ä–∏–Ω—à–æ—Ç–∞ Summary: {e}")
            return []

    def screenshot_by_title(self, page, block_title, session_id, base_dir):
        """–°–∫—Ä–∏–Ω—à–æ—Ç –±–ª–æ–∫–∞ –ø–æ –∑–∞–≥–æ–ª–æ–≤–∫—É"""
        try:
            # –ü–æ–∏—Å–∫ —ç–ª–µ–º–µ–Ω—Ç–∞ –ø–æ —Ç–µ–∫—Å—Ç—É
            element = page.query_selector(f'text={block_title}')
            if element:
                # –ü–æ–∏—Å–∫ —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–æ–≥–æ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞
                parent = element
                for _ in range(5):
                    try:
                        parent = parent.evaluate_handle('el => el.parentElement').as_element()
                        if parent:
                            bbox = parent.bounding_box()
                            if bbox and bbox['height'] > 60 and bbox['width'] > 200:
                                img_path = os.path.join(base_dir, f"{session_id}_{block_title.lower()}.png")
                                parent.screenshot(path=img_path)
                                print(f"‚úÖ {block_title} —Å–∫—Ä–∏–Ω—à–æ—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω")
                                return img_path
                    except Exception:
                        break
            
            print(f"‚ö†Ô∏è {block_title} –±–ª–æ–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return None
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–∫—Ä–∏–Ω—à–æ—Ç–∞ {block_title}: {e}")
            return None

    def run(self):
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –∑–∞–ø—É—Å–∫–∞ (–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Ä–µ–∂–∏–º –¥–ª—è Render)"""
        print("üöÄ RENDER SCREENSHOT COLLECTOR")
        print("BigQuery ‚Üí Screenshots ‚Üí Google Drive")
        print("=" * 50)
        
        # –ü–æ–ª—É—á–∞–µ–º URL –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        urls_data = self.get_unprocessed_urls()
        if not urls_data:
            print("üéâ –í—Å–µ URL —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã!")
            return {
                "status": "success",
                "processed_urls": 0,
                "message": "No URLs to process"
            }
        
        print(f"üéØ –ë—É–¥–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {len(urls_data)} URL")
        print(f"üõ°Ô∏è –†–µ–∂–∏–º: {self.safety_settings['name']}")
        print(f"‚òÅÔ∏è Google Drive –ø–∞–ø–∫–∞: {self.gdrive_folder_id}")
        
        start_time = time.time()
        successful = 0
        failed = 0
        total_screenshots = 0
        
        # –ó–∞–ø—É—Å–∫ –±—Ä–∞—É–∑–µ—Ä–∞
        with sync_playwright() as p:
            # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –±—Ä–∞—É–∑–µ—Ä–∞ –¥–ª—è Render
            browser_args = [
                '--no-sandbox',
                '--disable-setuid-sandbox',
                '--disable-dev-shm-usage',
                '--disable-blink-features=AutomationControlled',
                '--disable-web-security',
                '--disable-features=VizDisplayCompositor',
                '--no-proxy-server',
                '--disable-proxy-config-service'
            ]
            
            browser = p.chromium.launch(headless=True, args=browser_args)
            
            try:
                for i, url_data in enumerate(urls_data, 1):
                    print(f"\n‚ñ∂Ô∏è [{i}/{len(urls_data)}] –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º URL...")
                    
                    # –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
                    user_agent = random.choice(USER_AGENTS)
                    context = browser.new_context(
                        user_agent=user_agent,
                        viewport={'width': 1366, 'height': 768},
                        locale='en-US',
                        timezone_id='America/New_York'
                    )
                    
                    # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ cookies
                    if self.cookies:
                        context.add_cookies(self.cookies)
                    
                    page = context.new_page()
                    
                    # –û–±—Ä–∞–±–æ—Ç–∫–∞ URL
                    success, screenshots_count = self.process_single_url(page, url_data)
                    
                    # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –≤ BigQuery
                    self.mark_url_as_processed(
                        url_data['url'], 
                        success, 
                        screenshots_count,
                        self.gdrive_folder_id if success else None
                    )
                    
                    if success:
                        successful += 1
                        total_screenshots += screenshots_count
                        print(f"‚úÖ URL —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω ({screenshots_count} —Å–∫—Ä–∏–Ω—à–æ—Ç–æ–≤)")
                    else:
                        failed += 1
                        print("‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ URL")
                    
                    # –ó–∞–∫—Ä—ã—Ç–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
                    page.close()
                    context.close()
                    
                    # –ü–∞—É–∑–∞ –º–µ–∂–¥—É URL
                    if i < len(urls_data):
                        delay = random.uniform(
                            self.safety_settings['min_delay'], 
                            self.safety_settings['max_delay']
                        )
                        print(f"‚è±Ô∏è –ü–∞—É–∑–∞ {delay:.1f} —Å–µ–∫...")
                        time.sleep(delay)
                    
                    # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –±–∞—Ç—á–∞–º–∏
                    if i % self.safety_settings['batch_size'] == 0 and i < len(urls_data):
                        batch_pause = random.uniform(
                            self.safety_settings['batch_pause_min'],
                            self.safety_settings['batch_pause_max']
                        )
                        print(f"\n‚è∏Ô∏è –ü–∞—É–∑–∞ –º–µ–∂–¥—É –±–∞—Ç—á–∞–º–∏: {batch_pause:.1f} —Å–µ–∫...")
                        time.sleep(batch_pause)
                
            finally:
                browser.close()
        
        # –§–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç
        total_time = time.time() - start_time
        
        result = {
            "status": "success",
            "processed_urls": len(urls_data),
            "successful": successful,
            "failed": failed,
            "total_screenshots": total_screenshots,
            "processing_time_minutes": round(total_time / 60, 1),
            "message": f"Processed {successful}/{len(urls_data)} URLs successfully"
        }
        
        print(f"\n" + "=" * 50)
        print(f"üéâ –û–ë–†–ê–ë–û–¢–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê!")
        print(f"üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {len(urls_data)} URL")
        print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ: {successful}")
        print(f"‚ùå –û—à–∏–±–æ–∫: {failed}")
        print(f"üì∏ –í—Å–µ–≥–æ —Å–∫—Ä–∏–Ω—à–æ—Ç–æ–≤: {total_screenshots}")
        print(f"‚è±Ô∏è –í—Ä–µ–º—è: {total_time / 60:.1f} –º–∏–Ω—É—Ç")
        print(f"‚òÅÔ∏è –í—Å–µ —Ñ–∞–π–ª—ã –∑–∞–≥—Ä—É–∂–µ–Ω—ã –≤ Google Drive")
        print(f"üíæ –°—Ç–∞—Ç—É—Å—ã –æ–±–Ω–æ–≤–ª–µ–Ω—ã –≤ BigQuery")
        
        return result


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è Render"""
    print("üöÄ –ó–ê–ü–£–°–ö –°–ë–û–†–©–ò–ö–ê –°–ö–†–ò–ù–®–û–¢–û–í –î–õ–Ø RENDER")
    print("=" * 50)
    
    try:
        collector = RenderScreenshotCollector()
        result = collector.run()
        
        print(f"\nüìã –ò—Ç–æ–≥–æ–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        return result
        
    except Exception as e:
        print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()
        
        return {
            "status": "error",
            "error": str(e),
            "traceback": traceback.format_exc()
        }


if __name__ == "__main__":
    result = main()
    print(f"\nüìã –§–∏–Ω–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {result}")

üîß –ù–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –¥–ª—è Render:
1. requirements.txt (–¥–æ–±–∞–≤–∏—Ç—å):
playwright==1.40.0
google-cloud-bigquery==3.13.0
google-api-python-client==2.108.0
google-auth==2.23.4
google-oauth2-tool==0.0.3

2. –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –≤ Render:
# –û—Å–Ω–æ–≤–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
BQ_PROJECT_ID=codellon-dwh
BQ_DATASET_ID=amplitude_session_replay
BQ_TABLE_URLS=session_replay_urls
GDRIVE_FOLDER_ID=1K8cbFU2gYpvP3PiHwOOHS1KREqdj6fQX

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏
PROCESSING_LIMIT=10
MIN_DURATION_SECONDS=20

# Cookies –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ (–∏–∑ —Ç–≤–æ–µ–≥–æ —Ñ–∞–π–ª–∞ cookies_new.json)
COOKIES=[{"name":"cookie_name","value":"cookie_value","domain":".amplitude.com"}]

3. Dockerfile –∏–ª–∏ Build Command:
# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ Playwright –±—Ä–∞—É–∑–µ—Ä–æ–≤
pip install playwright
playwright install chromium

4. –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≤ main.py:

–ó–∞–º–µ–Ω–∏ –ø—É—Å—Ç–æ–π 2_replay_ai_gbq.py –Ω–∞ —ç—Ç–æ—Ç –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–¥.

üéØ –ö–ª—é—á–µ–≤—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è:

‚úÖ –£–±—Ä–∞–ª –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –≤–≤–æ–¥ - –≤—Å–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —á–µ—Ä–µ–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è

‚úÖ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Ä–µ–∂–∏–º - –±–µ–∑ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –≤—ã–±–æ—Ä–∞

‚úÖ Headless –±—Ä–∞—É–∑–µ—Ä - –¥–ª—è —Ä–∞–±–æ—Ç—ã –≤ –æ–±–ª–∞–∫–µ

‚úÖ –í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã - –∏—Å–ø–æ–ª—å–∑—É–µ–º tempfile –≤–º–µ—Å—Ç–æ –ª–æ–∫–∞–ª—å–Ω—ã—Ö –ø–∞–ø–æ–∫

‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è API

‚úÖ –õ–∏–º–∏—Ç—ã - –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º—ã—Ö URL

‚úÖ Cookies –∏–∑ env - –∑–∞–≥—Ä—É–∂–∞–µ–º –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è

–•–æ—á–µ—à—å, —á—Ç–æ–±—ã —è —Å–æ–∑–¥–∞–ª –≥–æ—Ç–æ–≤—ã–π —Ñ–∞–π–ª 2_replay_ai_gbq.py —Å —ç—Ç–∏–º –∫–æ–¥–æ–º?