import io
import re
import zipfile
import pytesseract
from PIL import Image
from google.cloud import bigquery
from google.oauth2 import service_account
from googleapiclient.discovery import build
from googleapiclient.http import MediaIoBaseDownload
import pandas as pd
from datetime import datetime
import os
import sys
from typing import Callable, Optional

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –∫–æ—Ä–Ω—é –ø—Ä–æ–µ–∫—Ç–∞ –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞ config
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
try:
    from config.settings import settings
except ImportError:
    class MockSettings:
        GOOGLE_APPLICATION_CREDENTIALS = os.environ.get('GOOGLE_APPLICATION_CREDENTIALS', '/etc/secrets/bigquery-credentials.json')
        GDRIVE_FOLDER_ID = os.environ.get('GDRIVE_FOLDER_ID', '1K8cbFU2gYpvP3PiHwOOHS1KREqdj6fQX')
        BQ_PROJECT_ID = os.environ.get('BQ_PROJECT_ID', 'codellon-dwh')
        BQ_DATASET_ID = os.environ.get('BQ_DATASET_ID', 'amplitude_session_replay')
        BQ_SOURCE_TABLE = os.environ.get('BQ_SOURCE_TABLE', 'session_replay_urls')
        BQ_TARGET_TABLE = os.environ.get('BQ_TARGET_TABLE', 'replay_text_complete')
    settings = MockSettings()

class TextExtractionProcessor:
    def __init__(self, status_callback: Optional[Callable[[str, int], None]] = None):
        self.status_callback = status_callback
        self.credentials_path = settings.GOOGLE_APPLICATION_CREDENTIALS
        self.gdrive_folder_id = settings.GDRIVE_FOLDER_ID
        self.bq_project_id = settings.BQ_PROJECT_ID
        self.bq_dataset_id = settings.BQ_DATASET_ID
        self.bq_source_table = settings.BQ_SOURCE_TABLE
        self.bq_target_table = settings.BQ_TARGET_TABLE
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ä–∞–±–æ—Ç—ã
        self.start_time = None
        self.total_processed = 0
        self.total_successful = 0
        self.total_failed = 0
        
        self._update_status("üîê –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è...", 1)
        self._init_clients()

    def _update_status(self, details: str, progress: int):
        if self.status_callback: 
            self.status_callback(details, progress)
        if progress != -1: 
            print(f"[{progress}%] {details}")
        else:
            timestamp = datetime.now().strftime("%H:%M:%S")
            print(f"[{timestamp}] {details}")

    def _init_clients(self):
        try:
            credentials = service_account.Credentials.from_service_account_file(
                self.credentials_path,
                scopes=[
                    "https://www.googleapis.com/auth/bigquery",
                    "https://www.googleapis.com/auth/drive"
                ]
            )
            self.bq_client = bigquery.Client(credentials=credentials, project=self.bq_project_id)
            self.drive_service = build('drive', 'v3', credentials=credentials)
            self._update_status("‚úÖ Google Cloud –ø–æ–¥–∫–ª—é—á–µ–Ω", 5)
        except Exception as e:
            raise Exception(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Google Cloud: {e}")

    def get_processed_sessions(self):
        """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Å–µ—Å—Å–∏–π –∏–∑ BigQuery, –∫–æ—Ç–æ—Ä—ã–µ –µ—â–µ –ù–ï –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã OCR"""
        query = f"""
        SELECT 
            s.session_replay_url, 
            s.amplitude_id, 
            s.session_replay_id, 
            s.duration_seconds, 
            s.events_count, 
            s.record_date
        FROM `{self.bq_project_id}.{self.bq_dataset_id}.{self.bq_source_table}` s
        LEFT JOIN `{self.bq_project_id}.{self.bq_dataset_id}.{self.bq_target_table}` t 
            ON s.session_replay_id = t.session_id
        WHERE s.is_processed = TRUE 
            AND t.session_id IS NULL  -- –ò—Å–∫–ª—é—á–∞–µ–º —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ OCR
        """
        
        self._update_status("üîç –ü–æ–ª—É—á–∞–µ–º –Ω–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ —Å–µ—Å—Å–∏–∏ –∏–∑ BigQuery...", 10)
        
        try:
            result = self.bq_client.query(query).result()
            sessions = []
            for row in result:
                sessions.append({
                    'session_replay_url': row.session_replay_url,
                    'amplitude_id': row.amplitude_id,
                    'session_replay_id': row.session_replay_id,
                    'duration_seconds': row.duration_seconds,
                    'events_count': row.events_count,
                    'record_date': row.record_date.strftime('%Y-%m-%d')
                })
            self._update_status(f"üìä –ù–∞–π–¥–µ–Ω–æ –ù–ï–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö OCR —Å–µ—Å—Å–∏–π: {len(sessions)}", 15)
            return sessions
        except Exception as e:
            self._update_status(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å–µ—Å—Å–∏–π: {e}", -1)
            raise

    def find_zip_for_session(self, session_id):
        """–ù–∞–π—Ç–∏ ZIP-–∞—Ä—Ö–∏–≤ –¥–ª—è session_id –≤ –ø–∞–ø–∫–µ Google Drive"""
        query = f"'{self.gdrive_folder_id}' in parents and name contains '{session_id}' and name contains '.zip'"
        
        try:
            results = self.drive_service.files().list(
                q=query,
                fields="files(id, name)",
                pageSize=10
            ).execute()
            files = results.get('files', [])
            
            if files:
                self._update_status(f"  üîé –ù–∞–π–¥–µ–Ω –∞—Ä—Ö–∏–≤: {files[0]['name']}", -1)
                return files[0]
            
            self._update_status("  ‚ùå –ê—Ä—Ö–∏–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω!", -1)
            return None
        except Exception as e:
            self._update_status(f"  ‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –∞—Ä—Ö–∏–≤–∞: {e}", -1)
            return None

    def get_zipfile_from_drive(self, file_id):
        """–°–∫–∞—á–∞—Ç—å ZIP-–∞—Ä—Ö–∏–≤ —Å Google Drive –≤ –ø–∞–º—è—Ç—å"""
        try:
            request = self.drive_service.files().get_media(fileId=file_id)
            fh = io.BytesIO()
            downloader = MediaIoBaseDownload(fh, request)
            done = False
            while not done:
                status, done = downloader.next_chunk()
            fh.seek(0)
            return zipfile.ZipFile(fh)
        except Exception as e:
            self._update_status(f"‚ùå –û—à–∏–±–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –∞—Ä—Ö–∏–≤–∞: {e}", -1)
            raise

    def parse_userinfo_text(self, text):
        """–ü–∞—Ä—Å–∏–Ω–≥ userinfo –∏–∑ OCR —Ç–µ–∫—Å—Ç–∞"""
        res = {
            'user_id': '',
            'country': '',
            'session_length': '',
            'event_total': '',
            'device_type': ''
        }
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è user_id
        user_id_patterns = [
            r'\b([A-Z]{2}[0-9]{6})\b',
            r'\b([A-Z]{2,3}[0-9]{5,7})\b',
            r'\b([A-Z]{4}[0-9]{4,8})\b',
            r'\b([0-9]{10,15})\b',
            r'\b([A-Z]+[0-9]+)\b',
            r'^([A-Z0-9]{6,15})$',
        ]
        
        for pattern in user_id_patterns:
            matches = re.findall(pattern, text, re.MULTILINE)
            valid_matches = [m for m in matches if m.lower() not in ['android', 'session', 'length', 'total', 'event', 'device']]
            if valid_matches:
                res['user_id'] = valid_matches[0]
                break
        
        # Fallback –¥–ª—è user_id
        if not res['user_id']:
            lines = text.split('\n')
            for line in lines:
                line = line.strip()
                if (6 <= len(line) <= 15 and
                        re.match(r'^[A-Z0-9]+$', line) and
                        any(c.isdigit() for c in line) and
                        any(c.isalpha() for c in line)):
                    res['user_id'] = line
                    break
        
        # –ü–æ–∏—Å–∫ —Å—Ç—Ä–∞–Ω
        country_patterns = {
            'Spain': ['spain', 'espa√±a'],
            'Costa Rica': ['costa rica', 'costa'],
            'Russia': ['russia', 'russian', '—Ä—Ñ'],
            'Peru': ['peru', 'per√∫'],
            'Bolivia': ['bolivia'],
            'Ecuador': ['ecuador'],
            'Netherlands': ['netherlands', 'holland'],
            'Germany': ['germany', 'deutschland'],
            'France': ['france', 'francia']
        }
        
        combined_lower = text.lower()
        for country, patterns in country_patterns.items():
            for pattern in patterns:
                if pattern in combined_lower:
                    res['country'] = country
                    break
            if res['country']:
                break
        
        # –ü–æ–∏—Å–∫ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Å–µ—Å—Å–∏–∏
        session_patterns = [
            r'(\d+h\s*\d+m)',
            r'(\d+m\s*\d+s)',
            r'(\d+h)',
            r'(\d+m)',
            r'(\d+s)'
        ]
        for pattern in session_patterns:
            match = re.search(pattern, text)
            if match:
                res['session_length'] = match.group(1)
                break
        
        # –ü–æ–∏—Å–∫ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å–æ–±—ã—Ç–∏–π
        event_match = re.search(r'(?:event\s*total|total)\s*:?\s*(\d+)', text, re.IGNORECASE)
        if event_match:
            res['event_total'] = event_match.group(1)
        else:
            numbers = re.findall(r'\b(\d{1,2})\b', text)
            for num in numbers:
                if 0 < int(num) < 100:
                    res['event_total'] = num
                    break
        
        # –ü–æ–∏—Å–∫ —Ç–∏–ø–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞
        devices = ['android', 'iphone', 'ios', 'windows', 'mac', 'linux']
        for device in devices:
            if device in combined_lower:
                res['device_type'] = device.capitalize()
                break
        
        return res

    def process_zip_session(self, session, zip_file):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–π —Å–µ—Å—Å–∏–∏: OCR –≤—Å–µ—Ö PNG –≤ –∞—Ä—Ö–∏–≤–µ"""
        data = {
            'session_id': session['session_replay_id'],
            'amplitude_id': session['amplitude_id'],
            'session_replay_url': session['session_replay_url'],
            'duration_seconds': session['duration_seconds'],
            'events_count': session['events_count'],
            'record_date': session['record_date'],
            'user_id': '',
            'country': '',
            'session_length': '',
            'event_total': '',
            'device_type': '',
            'summary': '',
            'sentiment': '',
            'actions': ''
        }
        
        screenshots_count = 0
        
        try:
            for fname in zip_file.namelist():
                if fname.lower().endswith('.png'):
                    screenshots_count += 1
                    
                    with zip_file.open(fname) as file:
                        img = Image.open(file)
                        
                        # OCR —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫
                        try:
                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å tesseract
                            if not hasattr(pytesseract, '_tesseract_cmd_exists'):
                                try:
                                    pytesseract.get_tesseract_version()
                                    pytesseract._tesseract_cmd_exists = True
                                except:
                                    pytesseract._tesseract_cmd_exists = False
                            
                            if not pytesseract._tesseract_cmd_exists:
                                self._update_status("‚ö†Ô∏è Tesseract –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º OCR", -1)
                                continue
                                
                            if 'userinfo' in fname:
                                text = pytesseract.image_to_string(img, lang='eng')
                                userinfo = self.parse_userinfo_text(text)
                                data.update(userinfo)
                            elif 'summary' in fname:
                                data['summary'] = pytesseract.image_to_string(img, lang='eng')
                            elif 'sentiment' in fname:
                                data['sentiment'] = pytesseract.image_to_string(img, lang='eng')
                            elif 'actions' in fname:
                                data['actions'] = pytesseract.image_to_string(img, lang='eng')
                        except Exception as ocr_error:
                            self._update_status(f"‚ö†Ô∏è OCR –æ—à–∏–±–∫–∞ –¥–ª—è {fname}: {ocr_error}", -1)
                            continue
                            
        except Exception as e:
            self._update_status(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∞—Ä—Ö–∏–≤–∞: {e}", -1)
            raise
            
        return data, screenshots_count

    def update_session_status_in_bq(self, session_replay_url, processed_datetime, screenshots_count, drive_folder_id):
        """–û–±–Ω–æ–≤–∏—Ç—å —Å—Ç–∞—Ç—É—Å —Å–µ—Å—Å–∏–∏ –≤ BigQuery"""
        table_id = f"{self.bq_project_id}.{self.bq_dataset_id}.{self.bq_source_table}"
        update_query = f"""
        UPDATE `{table_id}`
        SET
            processed_datetime = @processed_datetime,
            screenshots_count = @screenshots_count,
            drive_folder_id = @drive_folder_id
        WHERE session_replay_url = @session_replay_url
        """
        
        try:
            job_config = bigquery.QueryJobConfig(
                query_parameters=[
                    bigquery.ScalarQueryParameter("processed_datetime", "STRING", processed_datetime),
                    bigquery.ScalarQueryParameter("screenshots_count", "INT64", screenshots_count),
                    bigquery.ScalarQueryParameter("drive_folder_id", "STRING", drive_folder_id),
                    bigquery.ScalarQueryParameter("session_replay_url", "STRING", session_replay_url)
                ]
            )
            self.bq_client.query(update_query, job_config=job_config).result()
            self._update_status(f"‚úÖ –û–±–Ω–æ–≤–ª–µ–Ω —Å—Ç–∞—Ç—É—Å –¥–ª—è {session_replay_url}", -1)
        except Exception as e:
            self._update_status(f"‚ùå –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å—Ç–∞—Ç—É—Å–∞: {e}", -1)

    def upload_to_bigquery(self, rows):
        """–ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –≤ —Ü–µ–ª–µ–≤—É—é —Ç–∞–±–ª–∏—Ü—É BigQuery"""
        if not rows:
            self._update_status("‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏", -1)
            return

        try:
            df = pd.DataFrame(rows)
            table_id = f"{self.bq_project_id}.{self.bq_dataset_id}.{self.bq_target_table}"
            
            job = self.bq_client.load_table_from_dataframe(df, table_id)
            job.result()
            self._update_status(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} —Å—Ç—Ä–æ–∫ –≤ {table_id}", -1)
        except Exception as e:
            self._update_status(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –≤ BigQuery: {e}", -1)
            raise

    def run(self):
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–∏ OCR"""
        self.start_time = datetime.now()
        
        self._update_status("üîÑ –ó–ê–ü–£–°–ö –û–ë–†–ê–ë–û–¢–ö–ò OCR –¢–ï–ö–°–¢–ê", 20)
        
        # –ü–æ–ª—É—á–∞–µ–º —Å–µ—Å—Å–∏–∏ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        sessions = self.get_processed_sessions()
        
        if not sessions:
            self._update_status("‚úÖ –í—Å–µ —Å–µ—Å—Å–∏–∏ —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã OCR!", 100)
            return {"status": "no_sessions", "message": "–ù–µ—Ç —Å–µ—Å—Å–∏–π –¥–ª—è OCR –æ–±—Ä–∞–±–æ—Ç–∫–∏"}

        self._update_status(f"üìã –ù–∞—á–∏–Ω–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É {len(sessions)} —Å–µ—Å—Å–∏–π", 25)
        
        all_data = []
        batch_size = 50
        
        try:
            for i, session in enumerate(sessions, 1):
                progress = 25 + int((i / len(sessions)) * 70)
                self._update_status(f"‚ñ∂Ô∏è [{i}/{len(sessions)}] –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–µ—Å—Å–∏—é: {session['session_replay_id']}", progress)

                # –ü–æ–∏—Å–∫ –∞—Ä—Ö–∏–≤–∞
                zip_file_info = self.find_zip_for_session(session['session_replay_id'])
                if not zip_file_info:
                    self.total_failed += 1
                    continue

                try:
                    # –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞
                    zip_file = self.get_zipfile_from_drive(zip_file_info['id'])
                    row, screenshots_count = self.process_zip_session(session, zip_file)
                    all_data.append(row)

                    # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –≤ –∏—Å—Ç–æ—á–Ω–∏–∫–µ
                    processed_datetime = datetime.utcnow().isoformat()
                    self.update_session_status_in_bq(
                        session['session_replay_url'],
                        processed_datetime,
                        screenshots_count,
                        zip_file_info['id']
                    )

                    self.total_successful += 1
                    self._update_status(f"‚úÖ –°–µ—Å—Å–∏—è {session['session_replay_id']} –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞ OCR", -1)

                    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –±–∞—Ç—á–∞–º–∏
                    if len(all_data) >= batch_size:
                        self.upload_to_bigquery(all_data)
                        self._update_status(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω –±–∞—Ç—á –∏–∑ {len(all_data)} —Å–µ—Å—Å–∏–π", -1)
                        all_data = []

                except Exception as e:
                    self.total_failed += 1
                    self._update_status(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–µ—Å—Å–∏–∏ {session['session_replay_id']}: {e}", -1)
                    continue
                
                self.total_processed += 1

            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Å—Ç–∞—Ç–∫–∞
            if all_data:
                self.upload_to_bigquery(all_data)
                self._update_status(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –±–∞—Ç—á –∏–∑ {len(all_data)} —Å–µ—Å—Å–∏–π", -1)

        except Exception as e:
            self._update_status(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ OCR –æ–±—Ä–∞–±–æ—Ç–∫–µ: {e}", -1)
            raise

        # –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        total_time = datetime.now() - self.start_time
        result = {
            "status": "completed",
            "total_processed": self.total_processed,
            "total_successful": self.total_successful,
            "total_failed": self.total_failed,
            "success_rate": f"{(self.total_successful/self.total_processed*100):.1f}%" if self.total_processed > 0 else "0%",
            "total_time_minutes": round(total_time.total_seconds() / 60, 1)
        }

        self._update_status(f"üèÅ OCR –û–ë–†–ê–ë–û–¢–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê!", 100)
        self._update_status(f"üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {self.total_processed}, –£—Å–ø–µ—à–Ω–æ: {self.total_successful}, –û—à–∏–±–æ–∫: {self.total_failed}", 100)
        
        return result


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ OCR –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
    try:
        def console_status_callback(details: str, progress: int):
            if progress != -1:
                print(f"[{progress}%] {details}")
            else:
                print(f"[INFO] {details}")

        processor = TextExtractionProcessor(status_callback=console_status_callback)
        result = processor.run()
        
        print(f"\nüèÅ –§–∏–Ω–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        return result

    except Exception as e:
        print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()
        return {"status": "error", "error": str(e)}


if __name__ == "__main__":
    main()