import json
import os
import time
import hashlib
import random
import sys
from datetime import datetime
from playwright.sync_api import sync_playwright, Error as PlaywrightError, TimeoutError as PlaywrightTimeoutError
import tempfile
import shutil
from typing import Callable, Optional

# --- –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∏ –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã ---
# –≠—Ç–æ—Ç –±–ª–æ–∫ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
try:
    from config.settings import settings
except ImportError:
    class MockSettings:
        GOOGLE_APPLICATION_CREDENTIALS = os.environ.get('GOOGLE_APPLICATION_CREDENTIALS', '/etc/secrets/bigquery-credentials.json')
        BQ_PROJECT_ID = os.environ.get('BQ_PROJECT_ID', 'codellon-dwh')
        BQ_DATASET_ID = os.environ.get('BQ_DATASET_ID', 'amplitude_session_replay')
        BQ_TABLE_URLS = os.environ.get('BQ_TABLE_URLS', 'session_replay_urls')
        GDRIVE_FOLDER_ID = os.environ.get('GDRIVE_FOLDER_ID', '1K8cbFU2gYpvP3PiHwOOHS1KREqdj6fQX')
        PROCESSING_LIMIT = int(os.environ.get('PROCESSING_LIMIT', '10'))
        MIN_DURATION_SECONDS = int(os.environ.get('MIN_DURATION_SECONDS', '20'))
    settings = MockSettings()
USER_AGENTS = ["Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"]

class RenderScreenshotCollector:
    def __init__(self, status_callback: Optional[Callable[[str, int], None]] = None):
        self.status_callback = status_callback
        self.credentials_path = settings.GOOGLE_APPLICATION_CREDENTIALS
        self.gdrive_folder_id = settings.GDRIVE_FOLDER_ID
        self._update_status("–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–π...", 1)
        self.cookies = self._load_cookies_from_secret_file()
        self._init_google_drive()

    def _update_status(self, details: str, progress: int):
        if self.status_callback:
            self.status_callback(details, progress)
        if progress != -1:
            print(f"[{progress}%] {details}")

    def _load_cookies_from_secret_file(self):
        secret_file_path = "/etc/secrets/cookies.json"
        self._update_status(f"–ü–æ–ø—ã—Ç–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ cookies –∏–∑ {secret_file_path}...", 2)
        if not os.path.exists(secret_file_path):
            self._update_status(f"‚ùå –§–∞–π–ª {secret_file_path} –Ω–µ –Ω–∞–π–¥–µ–Ω! –ê—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è –Ω–µ —É–¥–∞—Å—Ç—Å—è.", 2)
            return []
        try:
            with open(secret_file_path, 'r') as f:
                cookies = json.load(f)
            self._update_status(f"‚úÖ Cookies —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏–∑ Secret File ({len(cookies)} –∑–∞–ø–∏—Å–µ–π).", 2)
            return cookies
        except Exception as e:
            self._update_status(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å –∏–ª–∏ —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å {secret_file_path}: {e}", 2)
            return []

    def _init_google_drive(self):
        try:
            credentials = service_account.Credentials.from_service_account_file(self.credentials_path, scopes=['https://www.googleapis.com/auth/drive'])
            self.drive_service = build('drive', 'v3', credentials=credentials)
            self._update_status("Google Drive –ø–æ–¥–∫–ª—é—á–µ–Ω", 4)
        except Exception as e:
            raise Exception(f"–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Google Drive: {e}")

    def get_session_id_from_url(self, url):
        url_hash = hashlib.md5(url.encode()).hexdigest()[:8]
        if "sessionReplayId=" in url:
            parts = url.split("sessionReplayId=")[1].split("&")[0].split("/")
            return f"{parts[0]}_{parts[1] if len(parts) > 1 else 'unknown'}_{url_hash}"
        return f"no_session_id_{url_hash}"

    def create_and_upload_archive(self, session_dir, session_id, is_failure=False):
        archive_path = None
        try:
            prefix = "FAILURE" if is_failure else "session_replay"
            archive_name_base = f"{prefix}_{session_id}_{int(time.time())}"
            archive_path = shutil.make_archive(archive_name_base, 'zip', session_dir)
            self._update_status(f"üì¶ –°–æ–∑–¥–∞–Ω –∞—Ä—Ö–∏–≤: {os.path.basename(archive_path)}", -1)
            file_metadata = {'name': os.path.basename(archive_path), 'parents': [self.gdrive_folder_id]}
            media = MediaFileUpload(archive_path, resumable=True)
            uploaded_file = self.drive_service.files().create(body=file_metadata, media_body=media, fields='id, name').execute()
            self._update_status(f"‚òÅÔ∏è –ê—Ä—Ö–∏–≤ –∑–∞–≥—Ä—É–∂–µ–Ω –≤ Google Drive. ID: {uploaded_file.get('id')}", -1)
            return uploaded_file
        finally:
            if archive_path and os.path.exists(archive_path):
                os.remove(archive_path)

    def process_single_url(self, page, url_data):
        url = url_data['session_replay_url']
        session_id = self.get_session_id_from_url(url)
        session_dir = tempfile.mkdtemp(prefix=f"session_{session_id}_")
        
        try:
            # –£–õ–£–ß–®–ï–ù–ò–ï: –ñ–¥–µ–º –ø–æ–ª–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏ —Å–µ—Ç–∏, —Ç–∞–π–º–∞—É—Ç 90 —Å–µ–∫—É–Ω–¥
            self._update_status("–ü–µ—Ä–µ—Ö–æ–¥ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É –∏ –æ–∂–∏–¥–∞–Ω–∏–µ –ø–æ–ª–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏...", -1)
            page.goto(url, timeout=90000, wait_until='networkidle')

            # –£–õ–£–ß–®–ï–ù–ò–ï: –î–∞–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ –≤—Ä–µ–º—è –Ω–∞ —Ä–µ–Ω–¥–µ—Ä JS-—Ñ—Ä–µ–π–º–≤–æ—Ä–∫–æ–≤
            self._update_status("–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ –æ–∂–∏–¥–∞–Ω–∏–µ —Ä–µ–Ω–¥–µ—Ä–∞...", -1)
            time.sleep(5)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É –ª–æ–≥–∏–Ω–∞
            if page.locator('input[type="email"]').is_visible():
                raise PlaywrightError("–û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –≤—Ö–æ–¥–∞. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ COOKIES.")

            # –£–õ–£–ß–®–ï–ù–ò–ï: –ë–æ–ª–µ–µ –Ω–∞–¥–µ–∂–Ω—ã–π –∫–ª–∏–∫ —Å —É–≤–µ–ª–∏—á–µ–Ω–Ω—ã–º —Ç–∞–π–º–∞—É—Ç–æ–º
            summary_tab = page.locator("text=Summary").first
            self._update_status("–ü–æ–∏—Å–∫ –≤–∫–ª–∞–¥–∫–∏ 'Summary'...", -1)
            summary_tab.wait_for(state='visible', timeout=20000)
            summary_tab.click()
            self._update_status("–ö–ª–∏–∫ –Ω–∞ 'Summary', –æ–∂–∏–¥–∞–Ω–∏–µ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞...", -1)
            time.sleep(10) # –£–≤–µ–ª–∏—á–∏–º –æ–∂–∏–¥–∞–Ω–∏–µ –ø–æ—Å–ª–µ –∫–ª–∏–∫–∞

            screenshot_paths = []
            
            # –°–∫—Ä–∏–Ω—à–æ—Ç –±–ª–æ–∫–∞ —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
            userinfo_element = page.locator('.cerulean-cardbase').first
            userinfo_element.wait_for(state='visible', timeout=15000)
            userinfo_path = os.path.join(session_dir, f"{session_id}_userinfo.png")
            userinfo_element.screenshot(path=userinfo_path)
            screenshot_paths.append(userinfo_path)
            self._update_status("‚úÖ –°–∫—Ä–∏–Ω—à–æ—Ç 'User Info' —Å–¥–µ–ª–∞–Ω.", -1)

            # –°–∫—Ä–∏–Ω—à–æ—Ç –±–ª–æ–∫–∞ Summary
            summary_element = page.locator('p.ltext-_uoww22').first
            summary_element.wait_for(state='visible', timeout=30000) # –î–∞–µ–º 30 —Å–µ–∫—É–Ω–¥
            summary_path = os.path.join(session_dir, f"{session_id}_summary.png")
            summary_element.screenshot(path=summary_path)
            screenshot_paths.append(summary_path)
            self._update_status("‚úÖ –°–∫—Ä–∏–Ω—à–æ—Ç 'Summary' —Å–¥–µ–ª–∞–Ω.", -1)
            
            if not screenshot_paths:
                 raise PlaywrightError("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–¥–µ–ª–∞—Ç—å –Ω–∏ –æ–¥–Ω–æ–≥–æ —Å–∫—Ä–∏–Ω—à–æ—Ç–∞.")

            metadata = {"session_id": session_id, **url_data, "processed_at": datetime.now().isoformat()}
            with open(os.path.join(session_dir, "metadata.json"), 'w', encoding='utf-8') as f:
                json.dump(metadata, f, indent=2, default=str)
            
            if not self.create_and_upload_archive(session_dir, session_id):
                raise PlaywrightError("–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∞—Ä—Ö–∏–≤–∞ –≤ Google Drive.")
            
            return True, len(screenshot_paths)

        except (PlaywrightError, PlaywrightTimeoutError) as e:
            self._update_status(f"‚ùå –û—à–∏–±–∫–∞ Playwright: {e}", -1)
            failure_path = os.path.join(session_dir, f"FAILURE_screenshot_{session_id}.png")
            try:
                page.screenshot(path=failure_path, full_page=True, timeout=15000)
                self._update_status(f"üì∏ –°–¥–µ–ª–∞–Ω –æ—Ç–ª–∞–¥–æ—á–Ω—ã–π —Å–∫—Ä–∏–Ω—à–æ—Ç.", -1)
            except Exception as screenshot_error:
                self._update_status(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–¥–µ–ª–∞—Ç—å –¥–∞–∂–µ –æ—Ç–ª–∞–¥–æ—á–Ω—ã–π —Å–∫—Ä–∏–Ω—à–æ—Ç: {screenshot_error}", -1)
            
            self.create_and_upload_archive(session_dir, session_id, is_failure=True)
            return False, 0
        finally:
             shutil.rmtree(session_dir, ignore_errors=True)

    def run(self):
        # –†–µ–∂–∏–º –æ—Ç–ª–∞–¥–∫–∏ –Ω–∞ 3 —Å—Å—ã–ª–∫–∞—Ö
        self._update_status("‚ö°Ô∏è –†–ï–ñ–ò–ú –û–¢–õ–ê–î–ö–ò: –ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è 3 —Ç–µ—Å—Ç–æ–≤—ã–µ —Å—Å—ã–ª–∫–∏.", 5)
        urls_to_process = [
            {'session_replay_url': 'https://app.amplitude.com/analytics/rn/session-replay/project/258068/search/amplitude_id%3D1247117195850?sessionReplayId=b04f4dad-3dea-4249-b9fe-78b689c822a5/1749812689447&sessionStartTime=1749812689447'},
            {'session_replay_url': 'https://app.amplitude.com/analytics/rn/session-replay/project/258068/search/amplitude_id%3D1247144093674?sessionReplayId=09d7d9ec-9d2f-453b-83f5-5b403e45c202/1749823352686&sessionStartTime=1749823352686'},
            {'session_replay_url': 'https://app.amplitude.com/analytics/rn/session-replay/project/258068/search/amplitude_id%3D868026320025?sessionReplayId=03e5a484-6f63-4fb2-8964-2893e062ea27/1749825242509&sessionStartTime=1749825242509'}
        ]

        total_urls = len(urls_to_process)
        self._update_status(f"üéØ –ù–∞–π–¥–µ–Ω–æ {total_urls} URL –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏.", 10)
        
        successful, failed = 0, 0
        
        with sync_playwright() as p:
            browser = p.chromium.launch(headless=True, args=['--no-sandbox', '--disable-setuid-sandbox', '--disable-dev-shm-usage'])
            try:
                for i, url_data in enumerate(urls_to_process, 1):
                    progress = 10 + int((i / total_urls) * 85)
                    self._update_status(f"‚ñ∂Ô∏è [{i}/{total_urls}] URL: {url_data['session_replay_url'][:70]}...", progress)
                    
                    context = browser.new_context(user_agent=random.choice(USER_AGENTS), viewport={'width': 1440, 'height': 900})
                    if self.cookies: context.add_cookies(self.cookies)
                    page = context.new_page()

                    is_success, _ = self.process_single_url(page, url_data)
                    
                    if is_success: successful += 1
                    else: failed += 1
                    
                    page.close()
                    context.close()
            finally:
                browser.close()
        
        result = {"status": "completed", "processed": total_urls, "successful": successful, "failed": failed}
        self._update_status(f"üèÅ –û—Ç–ª–∞–¥–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –£—Å–ø–µ—à–Ω–æ: {successful}, –û—à–∏–±–∫–∏: {failed}", 100)
        return result

if __name__ == "__main__":
    collector = RenderScreenshotCollector()
    collector.run()
