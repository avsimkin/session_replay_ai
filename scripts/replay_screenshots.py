import json
import os
import time
import hashlib
import random
import sys
from datetime import datetime
from playwright.sync_api import sync_playwright
from google.cloud import bigquery
from google.oauth2 import service_account
from googleapiclient.discovery import build
from googleapiclient.http import MediaFileUpload
import zipfile
import tempfile
import shutil
from typing import Callable, Optional

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –∫–æ—Ä–Ω—é –ø—Ä–æ–µ–∫—Ç–∞ –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞ config (–Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π)
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

try:
    from config.settings import settings
except ImportError:
    # –ó–∞–≥–ª—É—à–∫–∞, –µ—Å–ª–∏ —Ñ–∞–π–ª –Ω–∞—Å—Ç—Ä–æ–µ–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω
    class MockSettings:
        GOOGLE_APPLICATION_CREDENTIALS = os.environ.get('GOOGLE_APPLICATION_CREDENTIALS', '/etc/secrets/bigquery-credentials.json')
        BQ_PROJECT_ID = os.environ.get('BQ_PROJECT_ID', 'codellon-dwh')
        BQ_DATASET_ID = os.environ.get('BQ_DATASET_ID', 'amplitude_session_replay')
        BQ_TABLE_URLS = os.environ.get('BQ_TABLE_URLS', 'session_replay_urls')
        GDRIVE_FOLDER_ID = os.environ.get('GDRIVE_FOLDER_ID', '1K8cbFU2gYpvP3PiHwOOHS1KREqdj6fQX')
        COOKIES = os.environ.get('COOKIES', '[]')
        PROCESSING_LIMIT = int(os.environ.get('PROCESSING_LIMIT', '20')) # –£–≤–µ–ª–∏—á–∏–º –ª–∏–º–∏—Ç –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        MIN_DURATION_SECONDS = int(os.environ.get('MIN_DURATION_SECONDS', '20'))
    settings = MockSettings()

USER_AGENTS = [
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.0 Safari/605.1.15",
]

class RenderScreenshotCollector:
    def __init__(self, status_callback: Optional[Callable[[str, int], None]] = None):
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º callback –≤ —Å–∞–º–æ–º –Ω–∞—á–∞–ª–µ
        self.status_callback = status_callback
        
        self.credentials_path = settings.GOOGLE_APPLICATION_CREDENTIALS
        self.bq_project_id = settings.BQ_PROJECT_ID
        self.bq_dataset_id = settings.BQ_DATASET_ID
        self.bq_table_id = settings.BQ_TABLE_URLS
        self.gdrive_folder_id = settings.GDRIVE_FOLDER_ID
        self.processing_limit = settings.PROCESSING_LIMIT
        self.min_duration = settings.MIN_DURATION_SECONDS
        self.full_table_name = f"`{self.bq_project_id}.{self.bq_dataset_id}.{self.bq_table_id}`"
        
        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Ä–µ–∂–∏–º –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –¥–ª—è —Å–µ—Ä–≤–µ—Ä–∞
        self.safety_settings = {
            'min_delay': 2, 'max_delay': 5, 'batch_size': 20,
            'batch_pause_min': 30, 'batch_pause_max': 60, 'name': '–û–ë–´–ß–ù–´–ô (–ê–í–¢–û)'
        }
        
        self._update_status("–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–π...", 1)
        self.cookies = self._load_cookies_from_env()
        self._init_bigquery()
        self._init_google_drive()

    def _update_status(self, details: str, progress: int):
        if self.status_callback:
            self.status_callback(details, progress)
        print(f"[{progress}%] {details}")

    def _load_cookies_from_env(self):
        try:
            cookies = json.loads(settings.COOKIES)
            self._update_status(f"Cookies –∑–∞–≥—Ä—É–∂–µ–Ω—ã ({len(cookies)} –∑–∞–ø–∏—Å–µ–π)", 2)
            return cookies
        except Exception as e:
            self._update_status(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ cookies: {e}", 2)
            return []

    def _init_bigquery(self):
        try:
            credentials = service_account.Credentials.from_service_account_file(self.credentials_path, scopes=["https://www.googleapis.com/auth/bigquery"])
            self.bq_client = bigquery.Client(credentials=credentials, project=self.bq_project_id)
            self._update_status("BigQuery –ø–æ–¥–∫–ª—é—á–µ–Ω", 3)
        except Exception as e:
            raise Exception(f"–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ BigQuery: {e}")

    def _init_google_drive(self):
        try:
            credentials = service_account.Credentials.from_service_account_file(self.credentials_path, scopes=['https://www.googleapis.com/auth/drive'])
            self.drive_service = build('drive', 'v3', credentials=credentials)
            self._update_status("Google Drive –ø–æ–¥–∫–ª—é—á–µ–Ω", 4)
        except Exception as e:
            raise Exception(f"–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Google Drive: {e}")

    def get_unprocessed_urls(self):
        # –ú–µ—Ç–æ–¥ –æ—Å—Ç–∞–µ—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π
        query = f"""
        SELECT session_replay_url, amplitude_id, session_replay_id, duration_seconds, events_count, record_date
        FROM {self.full_table_name}
        WHERE is_processed = FALSE AND duration_seconds >= {self.min_duration}
        ORDER BY record_date DESC LIMIT {self.processing_limit}
        """
        try:
            result = self.bq_client.query(query).result()
            return [dict(row) for row in result]
        except Exception as e:
            self._update_status(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è URL: {e}", 10)
            raise

    def mark_url_as_processed(self, url, screenshots_count=0, drive_folder_id=None, success=True):
        # –ú–µ—Ç–æ–¥ –æ—Å—Ç–∞–µ—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π
        status_text = "—É—Å–ø–µ—à–Ω–æ" if success else "—Å –æ—à–∏–±–∫–æ–π"
        self._update_status(f"–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ URL ({status_text})", -1) # -1 progress to hide from main flow
        try:
            update_query = f"""
            UPDATE {self.full_table_name}
            SET is_processed = TRUE, processed_datetime = CURRENT_TIMESTAMP(),
                screenshots_count = @screenshots_count, drive_folder_id = @drive_folder_id
            WHERE session_replay_url = @url
            """
            job_config = bigquery.QueryJobConfig(
                query_parameters=[
                    bigquery.ScalarQueryParameter("url", "STRING", url),
                    bigquery.ScalarQueryParameter("screenshots_count", "INTEGER", screenshots_count),
                    bigquery.ScalarQueryParameter("drive_folder_id", "STRING", drive_folder_id)
                ]
            )
            self.bq_client.query(update_query, job_config=job_config).result()
        except Exception as e:
            self._update_status(f"‚ùå –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å—Ç–∞—Ç—É—Å–∞ URL: {e}", -1)

    # --- –ù–ê–ß–ê–õ–û: –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≤–∞—à–µ–π –ª–æ–∫–∞–ª—å–Ω–æ–π —Ä–∞–±–æ—á–µ–π –ª–æ–≥–∏–∫–∏ ---

    def get_session_id_from_url(self, url):
        url_hash = hashlib.md5(url.encode()).hexdigest()[:8]
        if "sessionReplayId=" in url:
            parts = url.split("sessionReplayId=")[1].split("&")[0].split("/")
            session_replay_id = parts[0]
            session_start_time = parts[1] if len(parts) > 1 else "unknown"
            return f"{session_replay_id}_{session_start_time}_{url_hash}"
        return f"no_session_id_{url_hash}"

    def wait_for_content(self, page, selector, timeout=10):
        self._update_status(f"–û–∂–∏–¥–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ (—Å–µ–ª–µ–∫—Ç–æ—Ä: {selector}, —Ç–∞–π–º–∞—É—Ç: {timeout}—Å)", -1)
        try:
            element = page.wait_for_selector(selector, state='visible', timeout=timeout*1000)
            self._update_status("–ö–æ–Ω—Ç–µ–Ω—Ç –∑–∞–≥—Ä—É–∂–µ–Ω", -1)
            return element
        except Exception:
            self._update_status(f"–ö–æ–Ω—Ç–µ–Ω—Ç –Ω–µ –∑–∞–≥—Ä—É–∑–∏–ª—Å—è –∑–∞ {timeout}—Å", -1)
            return None

    def simulate_human_behavior(self, page):
        try:
            for _ in range(random.randint(1, 2)):
                page.mouse.move(random.randint(200, 1000), random.randint(200, 600), steps=random.randint(5, 10))
                time.sleep(random.uniform(0.1, 0.2))
            if random.random() < 0.3:
                page.evaluate("window.scrollBy(0, 200)")
                time.sleep(random.uniform(0.5, 1.0))
        except Exception:
            pass

    def screenshot_by_title(self, page, block_title, session_id, base_dir):
        self._update_status(f"–ü–æ–∏—Å–∫ –±–ª–æ–∫–∞ '{block_title}'...", -1)
        try:
            element = page.locator(f'h4:has-text("{block_title}")')
            parent = element.locator('..') # –†–æ–¥–∏—Ç–µ–ª—å—Å–∫–∏–π —ç–ª–µ–º–µ–Ω—Ç
            img_path = os.path.join(base_dir, f"{session_id}_{block_title.lower()}.png")
            parent.screenshot(path=img_path)
            self._update_status(f"‚úÖ –°–∫—Ä–∏–Ω—à–æ—Ç '{block_title}' —Å–æ—Ö—Ä–∞–Ω—ë–Ω", -1)
            return img_path
        except Exception as e:
            self._update_status(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–¥–µ–ª–∞—Ç—å —Å–∫—Ä–∏–Ω—à–æ—Ç '{block_title}': {e}", -1)
            return None

    def screenshot_userinfo_block(self, page, session_id, base_dir):
        self._update_status("–ü–æ–∏—Å–∫ –±–ª–æ–∫–∞ 'User Info'...", -1)
        try:
            element = page.locator('.cerulean-cardbase.cerulean-alpha-general-card').first
            img_path = os.path.join(base_dir, f"{session_id}_userinfo.png")
            element.screenshot(path=img_path)
            self._update_status("‚úÖ –°–∫—Ä–∏–Ω—à–æ—Ç 'User Info' —Å–æ—Ö—Ä–∞–Ω—ë–Ω", -1)
            return img_path
        except Exception as e:
            self._update_status(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–¥–µ–ª–∞—Ç—å —Å–∫—Ä–∏–Ω—à–æ—Ç 'User Info': {e}", -1)
            return None
            
    def create_and_upload_session_archive(self, session_dir, session_id):
        archive_path = None
        try:
            archive_name = f"session_replay_{session_id}_{int(time.time())}"
            archive_path = shutil.make_archive(archive_name, 'zip', session_dir)
            
            self._update_status(f"üì¶ –°–æ–∑–¥–∞–Ω –∞—Ä—Ö–∏–≤: {os.path.basename(archive_path)}", -1)
            
            file_metadata = {'name': os.path.basename(archive_path), 'parents': [self.gdrive_folder_id]}
            media = MediaFileUpload(archive_path, resumable=True)
            uploaded_file = self.drive_service.files().create(body=file_metadata, media_body=media, fields='id, name, webViewLink').execute()
            
            self._update_status(f"‚òÅÔ∏è –ê—Ä—Ö–∏–≤ –∑–∞–≥—Ä—É–∂–µ–Ω –≤ Google Drive. ID: {uploaded_file.get('id')}", -1)
            return uploaded_file
        except Exception as e:
            self._update_status(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –∏–ª–∏ –∑–∞–≥—Ä—É–∑–∫–∏ –∞—Ä—Ö–∏–≤–∞: {e}", -1)
            return None
        finally:
            if archive_path and os.path.exists(archive_path):
                os.remove(archive_path)

    def process_single_url(self, page, url_data):
        url = url_data['url']
        session_id = self.get_session_id_from_url(url)
        
        screenshot_paths = []
        session_dir = tempfile.mkdtemp(prefix=f"session_{session_id}_")

        try:
            self.simulate_human_behavior(page)
            page.goto(url, timeout=45000, wait_until='domcontentloaded') # –£–≤–µ–ª–∏—á–∏–º —Ç–∞–π–º–∞—É—Ç
            time.sleep(random.uniform(3, 6))

            summary_tab = page.locator("text=Summary").first
            summary_tab.click()
            self._update_status("–ö–ª–∏–∫ –Ω–∞ –≤–∫–ª–∞–¥–∫—É 'Summary'", -1)
            time.sleep(random.uniform(4, 7))

            # –î–µ–ª–∞–µ–º —Å–∫—Ä–∏–Ω—à–æ—Ç—ã
            userinfo_path = self.screenshot_userinfo_block(page, session_id, session_dir)
            if userinfo_path: screenshot_paths.append(userinfo_path)

            summary_element = self.wait_for_content(page, 'p.ltext-_uoww22', timeout=15)
            if summary_element:
                summary_path = os.path.join(session_dir, f"{session_id}_summary.png")
                summary_element.screenshot(path=summary_path)
                screenshot_paths.append(summary_path)
                self._update_status("‚úÖ –°–∫—Ä–∏–Ω—à–æ—Ç 'Summary' —Å–æ—Ö—Ä–∞–Ω—ë–Ω", -1)

            sentiment_path = self.screenshot_by_title(page, "Sentiment", session_id, session_dir)
            if sentiment_path: screenshot_paths.append(sentiment_path)
            
            actions_path = self.screenshot_by_title(page, "Actions", session_id, session_dir)
            if actions_path: screenshot_paths.append(actions_path)

            if len(screenshot_paths) < 2: # –ü—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∫—Ä–∏–Ω—à–æ—Ç–æ–≤
                 raise Exception(f"–°–¥–µ–ª–∞–Ω–æ –º–µ–Ω—å—à–µ 2 —Å–∫—Ä–∏–Ω—à–æ—Ç–æ–≤ ({len(screenshot_paths)}), —Å–µ—Å—Å–∏—è —Å—á–∏—Ç–∞–µ—Ç—Å—è –Ω–µ—É–¥–∞—á–Ω–æ–π.")
            
            # –°–æ–∑–¥–∞–µ–º metadata.json
            metadata = {"session_id": session_id, "url": url, **url_data, "processed_at": datetime.now().isoformat()}
            metadata_path = os.path.join(session_dir, "metadata.json")
            with open(metadata_path, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, indent=2, default=str)
            
            # –ê—Ä—Ö–∏–≤–∏—Ä—É–µ–º –∏ –∑–∞–≥—Ä—É–∂–∞–µ–º
            uploaded_file = self.create_and_upload_session_archive(session_dir, session_id)
            if not uploaded_file:
                raise Exception("–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∞—Ä—Ö–∏–≤–∞ –≤ Google Drive.")

            return True, len(screenshot_paths)

        except Exception as e:
            self._update_status(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Å–µ—Å—Å–∏–∏ {session_id}: {e}", -1)
            return False, 0
        finally:
             shutil.rmtree(session_dir, ignore_errors=True) # –û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω–æ–π –ø–∞–ø–∫–∏

    # --- –ö–û–ù–ï–¶: –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≤–∞—à–µ–π –ª–æ–∫–∞–ª—å–Ω–æ–π —Ä–∞–±–æ—á–µ–π –ª–æ–≥–∏–∫–∏ ---

    def run(self):
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –∑–∞–ø—É—Å–∫–∞, –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –¥–ª—è —Å–µ—Ä–≤–µ—Ä–∞."""
        self._update_status("üöÄ –ó–∞–ø—É—Å–∫ —Å–±–æ—Ä—â–∏–∫–∞ —Å–∫—Ä–∏–Ω—à–æ—Ç–æ–≤", 0)
        self._update_status(f"üîç –ü–æ–ª—É—á–µ–Ω–∏–µ –Ω–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö URL (–ª–∏–º–∏—Ç: {self.processing_limit})", 5)
        
        urls_to_process = self.get_unprocessed_urls()
        
        if not urls_to_process:
            self._update_status("üéâ –í—Å–µ –ø–æ–¥—Ö–æ–¥—è—â–∏–µ URL —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã.", 100)
            return {"status": "success", "message": "No new URLs to process."}

        total_urls = len(urls_to_process)
        self._update_status(f"üéØ –ù–∞–π–¥–µ–Ω–æ {total_urls} URL –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏. –†–µ–∂–∏–º: {self.safety_settings['name']}", 10)
        
        successful, failed, total_screenshots = 0, 0, 0
        start_time = time.time()
        
        with sync_playwright() as p:
            browser_args = ['--no-sandbox', '--disable-setuid-sandbox', '--disable-dev-shm-usage']
            browser = p.chromium.launch(headless=True, args=browser_args)
            
            try:
                for i, url_data in enumerate(urls_to_process, 1):
                    progress = 10 + int((i / total_urls) * 85)
                    url = url_data.get('session_replay_url', 'N/A')
                    self._update_status(f"‚ñ∂Ô∏è [{i}/{total_urls}] –û–±—Ä–∞–±–æ—Ç–∫–∞ URL: {url[:60]}...", progress)
                    
                    context = browser.new_context(user_agent=random.choice(USER_AGENTS), viewport={'width': 1440, 'height': 900})
                    if self.cookies:
                        context.add_cookies(self.cookies)
                    page = context.new_page()

                    is_success, screenshots_count = self.process_single_url(page, url_data)
                    
                    self.mark_url_as_processed(url, screenshots_count, self.gdrive_folder_id if is_success else None, success=is_success)
                    
                    if is_success:
                        successful += 1
                        total_screenshots += screenshots_count
                    else:
                        failed += 1
                    
                    page.close()
                    context.close()
                    if i < total_urls:
                         time.sleep(random.uniform(self.safety_settings['min_delay'], self.safety_settings['max_delay']))

            finally:
                browser.close()
        
        total_time = time.time() - start_time
        result = {
            "status": "completed", "processed_urls": total_urls, "successful": successful,
            "failed": failed, "total_screenshots": total_screenshots,
            "processing_time_minutes": round(total_time / 60, 1)
        }
        self._update_status(f"üèÅ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –£—Å–ø–µ—à–Ω–æ: {successful}, –û—à–∏–±–∫–∏: {failed}", 100)
        return result

if __name__ == "__main__":
    print("--- –ó–∞–ø—É—Å–∫ –≤ —Ä–µ–∂–∏–º–µ –æ—Ç–ª–∞–¥–∫–∏ (–±–µ–∑ API) ---")
    collector = RenderScreenshotCollector()
    collector.run()

