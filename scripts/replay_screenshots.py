import json
import os
import time
import hashlib
import random
import sys
from datetime import datetime, timedelta
from playwright.sync_api import sync_playwright, Error as PlaywrightError, TimeoutError as PlaywrightTimeoutError
import tempfile
import shutil
from typing import Callable, Optional
import zipfile

# –ò–º–ø–æ—Ä—Ç—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Google API
from google.oauth2 import service_account
from googleapiclient.discovery import build
from googleapiclient.http import MediaFileUpload
from google.cloud import bigquery

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –∫–æ—Ä–Ω—é –ø—Ä–æ–µ–∫—Ç–∞ –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞ config
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
try:
    from config.settings import settings
except ImportError:
    class MockSettings:
        GOOGLE_APPLICATION_CREDENTIALS = os.environ.get('GOOGLE_APPLICATION_CREDENTIALS', '/etc/secrets/bigquery-credentials.json')
        GDRIVE_FOLDER_ID = os.environ.get('GDRIVE_FOLDER_ID', '1K8cbFU2gYpvP3PiHwOOHS1KREqdj6fQX')
        BQ_PROJECT_ID = os.environ.get('BQ_PROJECT_ID', 'codellon-dwh')
        BQ_DATASET_ID = os.environ.get('BQ_DATASET_ID', 'amplitude_session_replay')
        BQ_TABLE_ID = os.environ.get('BQ_TABLE_ID', 'session_replay_urls')
    settings = MockSettings()

USER_AGENTS = [
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.0 Safari/605.1.15",
    "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:120.0) Gecko/20100101 Firefox/120.0"
]

class RenderScreenshotCollector:
    def __init__(self, status_callback: Optional[Callable[[str, int], None]] = None):
        self.status_callback = status_callback
        self.credentials_path = settings.GOOGLE_APPLICATION_CREDENTIALS
        self.gdrive_folder_id = settings.GDRIVE_FOLDER_ID
        
        # BigQuery –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
        self.bq_project_id = settings.BQ_PROJECT_ID
        self.bq_dataset_id = settings.BQ_DATASET_ID
        self.bq_table_id = settings.BQ_TABLE_ID
        self.full_table_name = f"`{self.bq_project_id}.{self.bq_dataset_id}.{self.bq_table_id}`"
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–π —Ä–∞–±–æ—Ç—ã
        self.batch_size = int(os.environ.get('BATCH_SIZE', '50'))
        self.pause_between_batches = int(os.environ.get('PAUSE_BETWEEN_BATCHES', '300'))  # 5 –º–∏–Ω—É—Ç
        self.max_runtime_hours = int(os.environ.get('MAX_RUNTIME_HOURS', '18'))  # 18 —á–∞—Å–æ–≤
        self.min_duration_seconds = int(os.environ.get('MIN_DURATION_SECONDS', '20'))
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ä–∞–±–æ—Ç—ã
        self.start_time = None
        self.total_processed = 0
        self.total_successful = 0
        self.total_failed = 0
        self.batches_completed = 0
        
        self._update_status("üîê –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è...", 1)
        self.cookies = self._load_cookies_from_secret_file()
        self._init_bigquery()
        self._init_google_drive()

    def _update_status(self, details: str, progress: int):
        if self.status_callback: 
            self.status_callback(details, progress)
        if progress != -1: 
            print(f"[{progress}%] {details}")
        else:
            timestamp = datetime.now().strftime("%H:%M:%S")
            print(f"[{timestamp}] {details}")

    def _load_cookies_from_secret_file(self):
        secret_file_path = "/etc/secrets/cookies.json"
        self._update_status(f"–ó–∞–≥—Ä—É–∑–∫–∞ cookies –∏–∑ {secret_file_path}...", 2)
        if not os.path.exists(secret_file_path):
            self._update_status(f"‚ùå –§–∞–π–ª cookies –Ω–µ –Ω–∞–π–¥–µ–Ω!", 2)
            return []
        try:
            with open(secret_file_path, 'r') as f: 
                cookies = json.load(f)
            self._update_status(f"‚úÖ Cookies –∑–∞–≥—Ä—É–∂–µ–Ω—ã ({len(cookies)} —à—Ç).", 3)
            return cookies
        except Exception as e:
            self._update_status(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è cookies: {e}", 3)
            return []

    def _init_bigquery(self):
        try:
            credentials = service_account.Credentials.from_service_account_file(
                self.credentials_path,
                scopes=["https://www.googleapis.com/auth/bigquery"]
            )
            self.bq_client = bigquery.Client(credentials=credentials, project=self.bq_project_id)
            self._update_status("‚úÖ BigQuery –ø–æ–¥–∫–ª—é—á–µ–Ω", 4)
        except Exception as e:
            raise Exception(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ BigQuery: {e}")

    def _init_google_drive(self):
        try:
            credentials = service_account.Credentials.from_service_account_file(
                self.credentials_path, 
                scopes=['https://www.googleapis.com/auth/drive']
            )
            self.drive_service = build('drive', 'v3', credentials=credentials)
            self._update_status("‚úÖ Google Drive –ø–æ–¥–∫–ª—é—á–µ–Ω", 5)
        except Exception as e:
            raise Exception(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Google Drive: {e}")

    def get_unprocessed_urls(self, limit=None):
        query = f"""
        SELECT 
            session_replay_url,
            amplitude_id,
            session_replay_id,
            duration_seconds,
            events_count,
            record_date
        FROM {self.full_table_name}
        WHERE is_processed = FALSE
        AND duration_seconds >= {self.min_duration_seconds}
        ORDER BY record_date DESC
        """
        if limit:
            query += f"\nLIMIT {limit}"

        try:
            result = self.bq_client.query(query).result()
            urls_data = []
            for row in result:
                urls_data.append({
                    'url': row.session_replay_url,
                    'amplitude_id': row.amplitude_id,
                    'session_replay_id': row.session_replay_id,
                    'duration_seconds': row.duration_seconds,
                    'events_count': row.events_count,
                    'record_date': row.record_date.strftime('%Y-%m-%d')
                })
            return urls_data
        except Exception as e:
            self._update_status(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è URL: {e}", -1)
            raise

    def mark_url_as_processed(self, url, success=True):
        try:
            update_query = f"""
            UPDATE {self.full_table_name}
            SET is_processed = TRUE
            WHERE session_replay_url = @url
            """
            job_config = bigquery.QueryJobConfig(
                query_parameters=[
                    bigquery.ScalarQueryParameter("url", "STRING", url)
                ]
            )
            self.bq_client.query(update_query, job_config=job_config).result()
            if success:
                self._update_status("‚úÖ URL –æ—Ç–º–µ—á–µ–Ω –∫–∞–∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π", -1)
            else:
                self._update_status("‚ö†Ô∏è URL –æ—Ç–º–µ—á–µ–Ω –∫–∞–∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π (—Å –æ—à–∏–±–∫–æ–π)", -1)
        except Exception as e:
            self._update_status(f"‚ùå –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å—Ç–∞—Ç—É—Å–∞ URL: {e}", -1)

    def get_session_id_from_url(self, url):
        url_hash = hashlib.md5(url.encode()).hexdigest()[:8]
        if "sessionReplayId=" in url:
            parts = url.split("sessionReplayId=")[1].split("&")[0].split("/")
            session_replay_id = parts[0]
            session_start_time = parts[1] if len(parts) > 1 else "unknown"
            return f"{session_replay_id}_{session_start_time}_{url_hash}"
        return f"no_session_id_{url_hash}"

    def wait_for_content(self, page, selector, bad_texts=("Loading", "Loading summary"), timeout=10, min_text_length=10):
        start = time.time()
        while True:
            el = page.query_selector(selector)
            if el:
                txt = el.inner_text().strip()
                if txt and all(bad not in txt for bad in bad_texts) and len(txt) >= min_text_length:
                    return el
            if time.time() - start > timeout:
                return None
            time.sleep(0.5)

    def simulate_human_behavior(self, page):
        try:
            for _ in range(random.randint(2, 4)):
                x = random.randint(200, 1200)
                y = random.randint(200, 700)
                page.mouse.move(x, y, steps=random.randint(5, 15))
                time.sleep(random.uniform(0.1, 0.3))
            if random.random() < 0.4:
                scroll_amount = random.randint(100, 500)
                direction = random.choice([1, -1])
                page.evaluate(f"window.scrollBy(0, {scroll_amount * direction})")
                time.sleep(random.uniform(0.5, 1.5))
            if random.random() < 0.2:
                safe_x = random.randint(50, 1300)
                safe_y = random.randint(50, 150)
                page.mouse.click(safe_x, safe_y)
                time.sleep(random.uniform(0.3, 0.8))
            if random.random() < 0.3:
                page.keyboard.press('Tab')
                time.sleep(random.uniform(0.2, 0.5))
        except Exception:
            pass

    def screenshot_summary_flexible(self, page, session_id, base_dir, summary_el=None):
        self._update_status("üìÑ –ò—â–µ–º Summary –±–ª–æ–∫...", -1)

        el = summary_el
        if not el:
            el = self.wait_for_content(page, 'p.ltext-_uoww22', timeout=3)

        if el:
            text_content = el.inner_text().strip()
            if len(text_content) > 20:
                self._update_status(f"‚úÖ Summary –∑–∞–≥—Ä—É–∂–µ–Ω (–¥–ª–∏–Ω–∞: {len(text_content)} —Å–∏–º–≤–æ–ª–æ–≤)", -1)
            else:
                self._update_status(f"‚ö†Ô∏è Summary —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π ({len(text_content)} —Å–∏–º–≤–æ–ª–æ–≤), –ø—Ä–æ–±—É–µ–º fallback", -1)
                el = None
        if not el:
            self._update_status("‚ö†Ô∏è –ü—Ä–æ–±—É–µ–º fallback —Å–µ–ª–µ–∫—Ç–æ—Ä—ã –¥–ª—è Summary...", -1)
            fallback_selectors = [
                'div[style*="min-width: 460px"]',
                '.ltext-_uoww22',
                'div:has-text("Summary")',
                'p:has-text("The user")',
                'p:has-text("session")'
            ]
            for selector in fallback_selectors:
                try:
                    el = page.query_selector(selector)
                    if el:
                        text = el.inner_text().strip()
                        if text and len(text) > 20 and "Loading" not in text:
                            self._update_status(f"‚úÖ Fallback —Å—Ä–∞–±–æ—Ç–∞–ª —Å —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–º: {selector}", -1)
                            break
                        else:
                            el = None
                except Exception:
                    continue
            if not el:
                self._update_status("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ Summary –±–ª–æ–∫ –Ω–∏ –æ–¥–Ω–∏–º —Å–ø–æ—Å–æ–±–æ–º", -1)
                return []
        try:
            img_name = os.path.join(base_dir, f"{session_id}_summary.png")
            el.screenshot(path=img_name)
            self._update_status("‚úÖ Summary —Å–∫—Ä–∏–Ω—à–æ—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω", -1)
            return [img_name]
        except Exception as e:
            self._update_status(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Å–∫—Ä–∏–Ω—à–æ—Ç–∞ Summary: {e}", -1)
            return []

    def screenshot_by_title(self, page, block_title, session_id, base_dir):
        self._update_status(f"üîç –ò—â–µ–º –±–ª–æ–∫ '{block_title}'...", -1)
        el = None
        search_selectors = [
            f'h4:has-text("{block_title}")',
            f'div:has-text("{block_title}")',
            f'span:has-text("{block_title}")',
            f'h3:has-text("{block_title}")',
            f'h5:has-text("{block_title}")',
            f'[title="{block_title}"]',
            f'[aria-label="{block_title}"]'
        ]
        for selector in search_selectors:
            try:
                maybe = page.query_selector(selector)
                if maybe:
                    self._update_status(f"üìç –ù–∞–π–¥–µ–Ω —ç–ª–µ–º–µ–Ω—Ç —Å '{block_title}' —á–µ—Ä–µ–∑ —Å–µ–ª–µ–∫—Ç–æ—Ä: {selector}", -1)
                    parent = maybe
                    for level in range(6):
                        try:
                            bbox = parent.bounding_box()
                            if bbox and bbox['height'] > 60 and bbox['width'] > 200:
                                text_content = parent.inner_text().strip()
                                if text_content and len(text_content) > 10:
                                    el = parent
                                    self._update_status(f"‚úÖ –ù–∞–π–¥–µ–Ω –ø–æ–¥—Ö–æ–¥—è—â–∏–π –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä –Ω–∞ —É—Ä–æ–≤–Ω–µ {level}", -1)
                                    break
                        except Exception:
                            pass
                        try:
                            parent = parent.evaluate_handle('el => el.parentElement').as_element()
                            if not parent:
                                break
                        except Exception:
                            break
                    if el:
                        break
            except Exception as e:
                continue
        if not el:
            self._update_status(f"üîÑ –ü—Ä–æ–±—É–µ–º –ø–æ–∏—Å–∫ –ø–æ —á–∞—Å—Ç–∏—á–Ω–æ–º—É —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É '{block_title}'...", -1)
            try:
                all_elements = page.query_selector_all('div, span, h1, h2, h3, h4, h5, h6')
                for element in all_elements:
                    try:
                        text = element.inner_text().strip()
                        if block_title.lower() in text.lower() and len(text) < 100:
                            parent = element
                            for _ in range(4):
                                try:
                                    parent = parent.evaluate_handle('el => el.parentElement').as_element()
                                    if parent:
                                        bbox = parent.bounding_box()
                                        parent_text = parent.inner_text().strip()
                                        if (bbox and bbox['height'] > 60 and
                                                len(parent_text) > len(text) and len(parent_text) < 1000):
                                            el = parent
                                            self._update_status(f"‚úÖ –ù–∞–π–¥–µ–Ω —á–µ—Ä–µ–∑ –ø–æ–∏—Å–∫ –ø–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É", -1)
                                            break
                                except Exception:
                                    break
                            if el:
                                break
                    except Exception:
                        continue
            except Exception:
                pass
        if el:
            content_loaded = False
            self._update_status(f"‚è≥ –ñ–¥–µ–º –∑–∞–≥—Ä—É–∑–∫—É –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –±–ª–æ–∫–∞ '{block_title}'...", -1)
            for attempt in range(30):
                try:
                    txt = el.inner_text().strip()
                    if txt and "Loading" not in txt and len(txt) > 10:
                        content_loaded = True
                        self._update_status(f"‚úÖ –ö–æ–Ω—Ç–µ–Ω—Ç –±–ª–æ–∫–∞ '{block_title}' –∑–∞–≥—Ä—É–∂–µ–Ω", -1)
                        break
                except Exception:
                    pass
                time.sleep(0.5)
            if not content_loaded:
                self._update_status(f"‚ö†Ô∏è {block_title} ‚Äî –ù–µ –¥–æ–∂–¥–∞–ª–∏—Å—å –ø–æ–ª–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏, —Å–∫—Ä–∏–Ω—é –∫–∞–∫ –µ—Å—Ç—å", -1)
        else:
            self._update_status(f"‚ùå –ë–ª–æ–∫ '{block_title}' –Ω–µ –Ω–∞–π–¥–µ–Ω!", -1)
            return None
        try:
            img_path = os.path.join(base_dir, f"{session_id}_{block_title.lower()}.png")
            el.screenshot(path=img_path)
            self._update_status(f"‚úÖ {block_title} —Å–∫—Ä–∏–Ω—à–æ—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω", -1)
            return img_path
        except Exception as e:
            self._update_status(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Å–∫—Ä–∏–Ω—à–æ—Ç–∞ {block_title}: {e}", -1)
            return None

    def screenshot_userinfo_block(self, page, session_id, base_dir):
        self._update_status("üîç –ò—â–µ–º –±–ª–æ–∫ User Info...", -1)
        userinfo_div = None
        try:
            css_selector = '.cerulean-cardbase.cerulean-alpha-general-card'
            elements = page.query_selector_all(css_selector)
            for element in elements:
                try:
                    text = element.inner_text().strip()
                    bbox = element.bounding_box()
                    if (bbox and
                            bbox['y'] < 400 and
                            text and
                            len(text) > 10 and len(text) < 500 and
                            (any(char.isdigit() for char in text) or
                             any(country in text for country in
                                 ["Spain", "Peru", "Bolivia", "Ecuador", "Netherlands", "Costa Rica", "Russia"]))):
                        userinfo_div = element
                        break
                except Exception:
                    continue
        except Exception:
            pass
        if not userinfo_div:
            try:
                session_selectors = [
                    'text=Session Length',
                    'text=Event Total',
                    'text=Device Type'
                ]
                for selector in session_selectors:
                    element = page.query_selector(selector)
                    if element:
                        parent = element
                        for _ in range(5):
                            try:
                                parent = parent.evaluate_handle('el => el.parentElement').as_element()
                                if parent:
                                    bbox = parent.bounding_box()
                                    text = parent.inner_text().strip()
                                    if (bbox and bbox['y'] < 400 and
                                            bbox['width'] > 200 and bbox['height'] > 80 and
                                            len(text) > 20 and len(text) < 500):
                                        userinfo_div = parent
                                        break
                            except Exception:
                                break
                        if userinfo_div:
                            break
            except Exception:
                pass
        if not userinfo_div:
            self._update_status("‚ö†Ô∏è User info –Ω–µ –Ω–∞–π–¥–µ–Ω", -1)
            return None
        try:
            img_path = os.path.join(base_dir, f"{session_id}_userinfo.png")
            userinfo_div.screenshot(path=img_path)
            self._update_status("‚úÖ User info —Å–æ—Ö—Ä–∞–Ω—ë–Ω", -1)
            return img_path
        except Exception:
            self._update_status("‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Å–∫—Ä–∏–Ω—à–æ—Ç–∞ user info", -1)
            return None

    def create_session_folder_structure(self, session_id, screenshots, url_data):
        session_dir = tempfile.mkdtemp(prefix=f"session_folder_{session_id}_")
        session_screenshots = []
        for screenshot_path in screenshots:
            if screenshot_path and os.path.exists(screenshot_path):
                filename = os.path.basename(screenshot_path)
                new_path = os.path.join(session_dir, filename)
                shutil.copy2(screenshot_path, new_path)
                session_screenshots.append(new_path)
        
        metadata = {
            "session_id": session_id,
            "url": url_data['url'],
            "amplitude_id": url_data['amplitude_id'],
            "session_replay_id": url_data['session_replay_id'],
            "duration_seconds": url_data['duration_seconds'],
            "events_count": url_data['events_count'],
            "record_date": url_data['record_date'],
            "processed_at": datetime.now().isoformat(),
            "screenshots": [os.path.basename(path) for path in session_screenshots]
        }
        metadata_path = os.path.join(session_dir, "metadata.json")
        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)
        return session_dir, session_screenshots + [metadata_path]

    def upload_to_google_drive(self, file_path, filename, folder_id):
        try:
            file_metadata = {
                'name': filename,
                'parents': [folder_id]
            }
            media = MediaFileUpload(file_path, resumable=True)
            file = self.drive_service.files().create(
                body=file_metadata,
                media_body=media,
                fields='id, name, webViewLink'
            ).execute()
            return file
        except Exception as e:
            self._update_status(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –≤ Google Drive: {e}", -1)
            return None

    def create_and_upload_session_archive(self, session_dir, session_id, is_failure=False):
        try:
            prefix = "FAILURE" if is_failure else "session_replay"
            archive_name = f"{prefix}_{session_id}_{int(time.time())}.zip"
            archive_path = archive_name
            with zipfile.ZipFile(archive_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
                for root, dirs, files in os.walk(session_dir):
                    for file in files:
                        file_path = os.path.join(root, file)
                        arcname = os.path.relpath(file_path, session_dir)
                        zipf.write(file_path, arcname)
            self._update_status(f"üì¶ –°–æ–∑–¥–∞–Ω –∞—Ä—Ö–∏–≤: {archive_name}", -1)
            uploaded_file = self.upload_to_google_drive(
                archive_path,
                archive_name,
                self.gdrive_folder_id
            )
            if uploaded_file:
                self._update_status(f"‚òÅÔ∏è –ê—Ä—Ö–∏–≤ –∑–∞–≥—Ä—É–∂–µ–Ω –≤ Google Drive", -1)
                shutil.rmtree(session_dir, ignore_errors=True)
                os.remove(archive_path)
                return uploaded_file
            else:
                self._update_status("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∞—Ä—Ö–∏–≤", -1)
                return None
        except Exception as e:
            self._update_status(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –∞—Ä—Ö–∏–≤–∞: {e}", -1)
            return None

    def process_single_url(self, page, url_data, safety_settings):
        url = url_data['url']
        session_id = self.get_session_id_from_url(url)
        temp_screenshots_dir = tempfile.mkdtemp(prefix=f"screenshots_{session_id}_")
        REQUIRED_BLOCKS = ['userinfo', 'summary', 'sentiment']
        OPTIONAL_BLOCKS = ['actions']
        try:
            self.simulate_human_behavior(page)
            page.goto(url, timeout=30000)
            time.sleep(random.uniform(2, 5))
            summary_tab = page.query_selector("text=Summary")
            if summary_tab:
                self.simulate_human_behavior(page)
                summary_tab.click()
                self._update_status("üñ±Ô∏è –ö–ª–∏–∫–Ω—É–ª–∏ –Ω–∞ Summary", -1)
                time.sleep(random.uniform(3, 6))
                summary_el = self.wait_for_content(page, 'p.ltext-_uoww22', timeout=10)
            else:
                self._update_status("‚ùå –í–∫–ª–∞–¥–∫–∞ Summary –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!", -1)
                return False, []
            screenshot_results = {}
            self._update_status("üì∏ –ù–∞—á–∏–Ω–∞–µ–º —Å–æ–∑–¥–∞–Ω–∏–µ —Å–∫—Ä–∏–Ω—à–æ—Ç–æ–≤...", -1)
            userinfo_path = self.screenshot_userinfo_block(page, session_id, temp_screenshots_dir)
            screenshot_results['userinfo'] = userinfo_path is not None
            screenshot_paths = [userinfo_path] if userinfo_path else []
            time.sleep(random.uniform(1, 2))
            summary_paths = self.screenshot_summary_flexible(page, session_id, temp_screenshots_dir, summary_el=summary_el)
            screenshot_results['summary'] = len(summary_paths) > 0
            if summary_paths:
                screenshot_paths += summary_paths
            time.sleep(random.uniform(1, 2))
            sentiment_path = self.screenshot_by_title(page, "Sentiment", session_id, temp_screenshots_dir)
            screenshot_results['sentiment'] = sentiment_path is not None
            if sentiment_path:
                screenshot_paths.append(sentiment_path)
            time.sleep(random.uniform(1, 2))
            actions_path = self.screenshot_by_title(page, "Actions", session_id, temp_screenshots_dir)
            screenshot_results['actions'] = actions_path is not None
            if actions_path:
                screenshot_paths.append(actions_path)
            all_success = all(screenshot_results.get(block, False) for block in REQUIRED_BLOCKS)
            total_blocks = len([path for path in screenshot_paths if path and os.path.exists(path)])
            if not all_success:
                self._update_status("‚ùå –ù–µ –ø–æ–ª—É—á–µ–Ω—ã –≤—Å–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –±–ª–æ–∫–∏", -1)
                return False, screenshot_paths
            if total_blocks < 3:
                self._update_status("‚ùå –ü–æ–ª—É—á–µ–Ω–æ –º–µ–Ω—å—à–µ 3 —Å–∫—Ä–∏–Ω—à–æ—Ç–æ–≤", -1)
                return False, screenshot_paths
            session_dir, all_files = self.create_session_folder_structure(
                session_id, screenshot_paths, url_data
            )
            quality_info = {
                "screenshot_results": screenshot_results,
                "total_screenshots": total_blocks,
                "required_blocks_success": all_success,
                "success_rate_percent": 100.0,
                "processing_quality": "high"
            }
            metadata_path = os.path.join(session_dir, "metadata.json")
            if os.path.exists(metadata_path):
                with open(metadata_path, 'r', encoding='utf-8') as f:
                    metadata = json.load(f)
                metadata['quality_analysis'] = quality_info
                with open(metadata_path, 'w', encoding='utf-8') as f:
                    json.dump(metadata, f, ensure_ascii=False, indent=2)
            uploaded_file = self.create_and_upload_session_archive(session_dir, session_id)
            if uploaded_file:
                for path in screenshot_paths:
                    if path and os.path.exists(path):
                        os.remove(path)
                return True, screenshot_paths
            else:
                self._update_status("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –≤ Google Drive", -1)
                return False, screenshot_paths
        except Exception as e:
            self._update_status(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ URL: {e}", -1)
            failure_path = os.path.join(temp_screenshots_dir, f"FAILURE_screenshot.png")
            try: 
                page.screenshot(path=failure_path, full_page=True, timeout=15000)
            except: 
                pass
            self.create_and_upload_session_archive(temp_screenshots_dir, session_id, is_failure=True)
            return False, []
        finally:
            shutil.rmtree(temp_screenshots_dir, ignore_errors=True)

    def get_safety_settings(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è"""
        safety_mode = os.environ.get('SAFETY_MODE', 'normal').lower()
        
        if safety_mode == 'slow':
            return {
                'min_delay': 3, 'max_delay': 8, 'batch_size': 10,
                'batch_pause_min': 60, 'batch_pause_max': 120, 'name': '–ú–ï–î–õ–ï–ù–ù–´–ô'
            }
        elif safety_mode == 'fast':
            return {
                'min_delay': 1, 'max_delay': 3, 'batch_size': 30,
                'batch_pause_min': 15, 'batch_pause_max': 30, 'name': '–ë–´–°–¢–†–´–ô'
            }
        else:  # normal
            return {
                'min_delay': 2, 'max_delay': 5, 'batch_size': 20,
                'batch_pause_min': 30, 'batch_pause_max': 60, 'name': '–û–ë–´–ß–ù–´–ô'
            }

    def print_overall_stats(self):
        """–í—ã–≤–æ–¥–∏—Ç –æ–±—â—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Ä–∞–±–æ—Ç—ã"""
        if self.start_time:
            elapsed = time.time() - self.start_time
            elapsed_hours = elapsed / 3600
            success_rate = (self.total_successful / self.total_processed * 100) if self.total_processed > 0 else 0
            
            self._update_status("=" * 60, -1)
            self._update_status(f"üìä –û–ë–©–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê –†–ê–ë–û–¢–´", -1)
            self._update_status(f"‚è±Ô∏è  –í—Ä–µ–º—è —Ä–∞–±–æ—Ç—ã: {elapsed_hours:.1f} —á–∞—Å–æ–≤", -1)
            self._update_status(f"üîÑ –ë–∞—Ç—á–µ–π –∑–∞–≤–µ—Ä—à–µ–Ω–æ: {self.batches_completed}", -1)
            self._update_status(f"üìà –í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {self.total_processed} URL", -1)
            self._update_status(f"‚úÖ –£—Å–ø–µ—à–Ω–æ: {self.total_successful}", -1)
            self._update_status(f"‚ùå –û—à–∏–±–æ–∫: {self.total_failed}", -1)
            self._update_status(f"üìä –ü—Ä–æ—Ü–µ–Ω—Ç —É—Å–ø–µ—Ö–∞: {success_rate:.1f}%", -1)
            if self.total_processed > 0:
                avg_time_per_url = elapsed / self.total_processed
                self._update_status(f"‚ö° –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –Ω–∞ URL: {avg_time_per_url:.1f} —Å–µ–∫", -1)
            self._update_status("=" * 60, -1)

    def check_runtime_limit(self):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –Ω–µ –ø—Ä–µ–≤—ã—à–µ–Ω –ª–∏ –ª–∏–º–∏—Ç –≤—Ä–µ–º–µ–Ω–∏ —Ä–∞–±–æ—Ç—ã"""
        if self.start_time:
            elapsed_hours = (time.time() - self.start_time) / 3600
            if elapsed_hours >= self.max_runtime_hours:
                self._update_status(f"‚è∞ –î–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç –≤—Ä–µ–º–µ–Ω–∏ —Ä–∞–±–æ—Ç—ã ({self.max_runtime_hours}—á)", -1)
                return True
        return False
        
    def process_batch(self, urls_batch, safety_settings):
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ–¥–∏–Ω –±–∞—Ç—á URL"""
        batch_start_time = time.time()
        batch_successful = 0
        batch_failed = 0
        
        self._update_status(f"üöÄ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –±–∞—Ç—á–∞ –∏–∑ {len(urls_batch)} URL", -1)
        
        with sync_playwright() as p:
            browser_args = [
                '--no-proxy-server',
                '--disable-proxy-config-service',
                '--no-sandbox',
                '--disable-setuid-sandbox',
                '--disable-blink-features=AutomationControlled',
                '--disable-dev-shm-usage',
                '--disable-web-security',
                '--disable-features=VizDisplayCompositor'
            ]
            browser = p.chromium.launch(headless=True, args=browser_args)
            
            try:
                for i, url_data in enumerate(urls_batch, 1):
                    user_agent = random.choice(USER_AGENTS)
                    context = browser.new_context(
                        user_agent=user_agent,
                        viewport={'width': 1366, 'height': 768},
                        locale='en-US',
                        timezone_id='America/New_York'
                    )
                    context.add_init_script("""
                        Object.defineProperty(navigator, 'webdriver', {get: () => undefined});
                        window.navigator.chrome = { runtime: {} };
                        Object.defineProperty(navigator, 'languages', {get: () => ['en-US', 'en']});
                        Object.defineProperty(navigator, 'plugins', {get: () => [1, 2, 3, 4, 5]});
                    """)
                    context.add_cookies(self.cookies)
                    page = context.new_page()

                    self._update_status(f"‚ñ∂Ô∏è [{i}/{len(urls_batch)}] –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º URL –∏–∑ –±–∞—Ç—á–∞...", -1)
                    success, screenshots = self.process_single_url(page, url_data, safety_settings)

                    # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –≤ BigQuery
                    self.mark_url_as_processed(url_data['url'], success)

                    if success:
                        batch_successful += 1
                        self.total_successful += 1
                        self._update_status("‚úÖ URL —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω", -1)
                    else:
                        batch_failed += 1
                        self.total_failed += 1
                        self._update_status("‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ URL", -1)
                    
                    self.total_processed += 1

                    # –ü–∞—É–∑–∞ –º–µ–∂–¥—É URL –≤ –±–∞—Ç—á–µ
                    if i < len(urls_batch):
                        delay = random.uniform(safety_settings['min_delay'], safety_settings['max_delay'])
                        self._update_status(f"‚è±Ô∏è –ü–∞—É–∑–∞ {delay:.1f} —Å–µ–∫...", -1)
                        time.sleep(delay)

                    page.close()
                    context.close()
                    
            finally:
                browser.close()

        batch_time = time.time() - batch_start_time
        self.batches_completed += 1
        
        self._update_status(f"üì¶ –ë–∞—Ç—á #{self.batches_completed} –∑–∞–≤–µ—Ä—à–µ–Ω –∑–∞ {batch_time/60:.1f} –º–∏–Ω", -1)
        self._update_status(f"   ‚úÖ –£—Å–ø–µ—à–Ω–æ: {batch_successful} | ‚ùå –û—à–∏–±–æ–∫: {batch_failed}", -1)
        
        return batch_successful, batch_failed
        
    def run(self):
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ - —Ä–∞–±–æ—Ç–∞–µ—Ç –ø–æ–∫–∞ –µ—Å—Ç—å URL"""
        self.start_time = time.time()
        
        self._update_status("üîÑ –ó–ê–ü–£–°–ö –ù–ï–ü–†–ï–†–´–í–ù–û–ô –û–ë–†–ê–ë–û–¢–ö–ò –°–ö–†–ò–ù–®–û–¢–û–í", 10)
        self._update_status("=" * 60, 10)
        self._update_status(f"‚öôÔ∏è  –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞: {self.batch_size} URL", 15)
        self._update_status(f"‚è±Ô∏è  –ü–∞—É–∑–∞ –º–µ–∂–¥—É –±–∞—Ç—á–∞–º–∏: {self.pause_between_batches} —Å–µ–∫", 15)
        self._update_status(f"üïê –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è —Ä–∞–±–æ—Ç—ã: {self.max_runtime_hours} —á–∞—Å–æ–≤", 15)
        self._update_status(f"üìè –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–µ—Å—Å–∏–π: {self.min_duration_seconds} —Å–µ–∫", 15)
        
        # –ü–æ–ª—É—á–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
        safety_settings = self.get_safety_settings()
        self._update_status(f"üõ°Ô∏è  –†–µ–∂–∏–º –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏: {safety_settings['name']}", 20)
        
        cycle_number = 0
        
        try:
            while True:
                cycle_number += 1
                cycle_start_time = time.time()
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–∏–º–∏—Ç –≤—Ä–µ–º–µ–Ω–∏ —Ä–∞–±–æ—Ç—ã
                if self.check_runtime_limit():
                    self._update_status("üõë –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ä–∞–±–æ—Ç—É –ø–æ –ª–∏–º–∏—Ç—É –≤—Ä–µ–º–µ–Ω–∏", -1)
                    break
                
                self._update_status(f"\nüîç –¶–ò–ö–õ #{cycle_number}: –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –Ω–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö URL...", -1)
                
                # –ü–æ–ª—É—á–∞–µ–º —Å–ª–µ–¥—É—é—â—É—é –ø–æ—Ä—Ü–∏—é URL
                urls_batch = self.get_unprocessed_urls(limit=self.batch_size)
                
                if not urls_batch:
                    self._update_status("üéâ –ù–µ—Ç –Ω–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö URL! –†–∞–±–æ—Ç–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞.", -1)
                    break
                
                self._update_status(f"üìã –ù–∞–π–¥–µ–Ω–æ {len(urls_batch)} URL –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏", -1)
                
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á
                batch_successful, batch_failed = self.process_batch(urls_batch, safety_settings)
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
                cycle_time = time.time() - cycle_start_time
                self._update_status(f"‚è±Ô∏è  –¶–∏–∫–ª #{cycle_number} –∑–∞–≤–µ—Ä—à–µ–Ω –∑–∞ {cycle_time/60:.1f} –º–∏–Ω", -1)
                
                # –í—ã–≤–æ–¥–∏–º –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∫–∞–∂–¥—ã–µ 5 —Ü–∏–∫–ª–æ–≤
                if cycle_number % 5 == 0:
                    self.print_overall_stats()
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –µ—â–µ URL –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–≥–æ —Ü–∏–∫–ª–∞
                remaining_urls = self.get_unprocessed_urls(limit=1)
                if not remaining_urls:
                    self._update_status("üéØ –í—Å–µ URL –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã! –ó–∞–≤–µ—Ä—à–∞–µ–º —Ä–∞–±–æ—Ç—É.", -1)
                    break
                
                # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –±–∞—Ç—á–∞–º–∏
                if remaining_urls:  # –¢–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å –µ—â–µ URL –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
                    pause_time = random.uniform(
                        self.pause_between_batches,
                        self.pause_between_batches + 60  # +1 –º–∏–Ω—É—Ç–∞ —Ä–∞–∑–±—Ä–æ—Å–∞
                    )
                    self._update_status(f"‚è∏Ô∏è  –ü–∞—É–∑–∞ –º–µ–∂–¥—É –±–∞—Ç—á–∞–º–∏: {pause_time:.1f} —Å–µ–∫...", -1)
                    time.sleep(pause_time)
                
        except KeyboardInterrupt:
            self._update_status("‚ö†Ô∏è –ü–æ–ª—É—á–µ–Ω —Å–∏–≥–Ω–∞–ª –æ—Å—Ç–∞–Ω–æ–≤–∫–∏", -1)
        except Exception as e:
            self._update_status(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ –æ—Å–Ω–æ–≤–Ω–æ–º —Ü–∏–∫–ª–µ: {e}", -1)
            import traceback
            traceback.print_exc()
        
        # –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.print_overall_stats()
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        total_time = time.time() - self.start_time
        result = {
            "status": "completed",
            "cycles_completed": cycle_number,
            "batches_completed": self.batches_completed,
            "total_processed": self.total_processed,
            "total_successful": self.total_successful,
            "total_failed": self.total_failed,
            "success_rate": f"{(self.total_successful/self.total_processed*100):.1f}%" if self.total_processed > 0 else "0%",
            "total_runtime_hours": round(total_time / 3600, 2),
            "reason_for_stop": "no_more_urls" if not self.get_unprocessed_urls(limit=1) else "time_limit_reached"
        }
        
        self._update_status(f"üèÅ –ù–ï–ü–†–ï–†–´–í–ù–ê–Ø –û–ë–†–ê–ë–û–¢–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê!", 100)
        self._update_status(f"üìä –ü—Ä–∏—á–∏–Ω–∞ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏: {result['reason_for_stop']}", 100)
        
        return result


def main():
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –≤ Render
    """
    try:
        def console_status_callback(details: str, progress: int):
            """Callback –¥–ª—è –≤—ã–≤–æ–¥–∞ –≤ –∫–æ–Ω—Å–æ–ª—å"""
            if progress != -1:
                print(f"[{progress}%] {details}")
            else:
                print(f"[INFO] {details}")

        collector = BigQueryScreenshotCollector(status_callback=console_status_callback)
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É
        print("ü§ñ RENDER MODE: –ó–∞–ø—É—Å–∫ –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏")
        print(f"‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏:")
        print(f"   üì¶ –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞: {collector.batch_size}")
        print(f"   ‚è±Ô∏è –ü–∞—É–∑–∞ –º–µ–∂–¥—É –±–∞—Ç—á–∞–º–∏: {collector.pause_between_batches} —Å–µ–∫")
        print(f"   üïê –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è —Ä–∞–±–æ—Ç—ã: {collector.max_runtime_hours} —á")
        print(f"   üìè –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {collector.min_duration_seconds} —Å–µ–∫")
        
        result = collector.run()

        print(f"\nüèÅ –§–∏–Ω–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        return result

    except Exception as e:
        print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()
        return {"status": "error", "error": str(e)}


if __name__ == "__main__":
    main()