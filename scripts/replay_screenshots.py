import json
import os
import time
import hashlib
import random
import sys
from datetime import datetime
from playwright.sync_api import sync_playwright, Error as PlaywrightError, TimeoutError as PlaywrightTimeoutError
import tempfile
import shutil
from typing import Callable, Optional
import zipfile
import multiprocessing
import queue

# –ò–º–ø–æ—Ä—Ç—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Google API
from google.oauth2 import service_account
from googleapiclient.discovery import build
from googleapiclient.http import MediaFileUpload
from google.cloud import bigquery

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –∫–æ—Ä–Ω—é –ø—Ä–æ–µ–∫—Ç–∞ –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞ config
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
try:
    from config.settings import settings
except ImportError:
    class MockSettings:
        GOOGLE_APPLICATION_CREDENTIALS = os.environ.get('GOOGLE_APPLICATION_CREDENTIALS', '/etc/secrets/bigquery-credentials.json')
        GDRIVE_FOLDER_ID = os.environ.get('GDRIVE_FOLDER_ID', '1K8cbFU2gYpvP3PiHwOOHS1KREqdj6fQX')
        BQ_PROJECT_ID = os.environ.get('BQ_PROJECT_ID', 'codellon-dwh')
        BQ_DATASET_ID = os.environ.get('BQ_DATASET_ID', 'amplitude_session_replay')
        BQ_TABLE_ID = os.environ.get('BQ_TABLE_ID', 'session_replay_urls')
    settings = MockSettings()

PROCESS_TIMEOUT_PER_URL = 240

USER_AGENTS = [
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.0 Safari/605.1.15",
    "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:120.0) Gecko/20100101 Firefox/120.0"
]

def sanitize_cookies(cookies):
    if not cookies:
        return []
    valid_same_site_values = {"Strict", "Lax", "None"}
    sanitized_cookies = []
    for cookie in cookies:
        if cookie.get('sameSite') not in valid_same_site_values:
            original_value = cookie.get('sameSite', '–ö–õ–Æ–ß –û–¢–°–£–¢–°–¢–í–û–í–ê–õ')
            print(f"‚ö†Ô∏è –ò—Å–ø—Ä–∞–≤–ª—è—é –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–π/–æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–π sameSite='{original_value}' –Ω–∞ 'Lax' –¥–ª—è –∫—É–∫–∏: {cookie.get('name')}")
            cookie['sameSite'] = 'Lax'
        sanitized_cookies.append(cookie)
    return sanitized_cookies

def worker_process_url(collector_config: dict, url_data: dict, result_queue: multiprocessing.Queue):
    try:
        collector = RenderScreenshotCollector(config_override=collector_config)
        sanitized_cookies = sanitize_cookies(collector.cookies)

        with sync_playwright() as p:
            browser_args = [
                '--no-proxy-server', '--disable-proxy-config-service', '--no-sandbox',
                '--disable-setuid-sandbox', '--disable-blink-features=AutomationControlled',
                '--disable-dev-shm-usage', '--disable-web-security',
                '--disable-features=VizDisplayCompositor'
            ]
            browser = p.chromium.launch(headless=True, args=browser_args)
            
            user_agent = random.choice(USER_AGENTS)
            context = browser.new_context(
                user_agent=user_agent, viewport={'width': 1366, 'height': 768},
                locale='en-US', timezone_id='America/New_York'
            )
            context.add_init_script("""
                Object.defineProperty(navigator, 'webdriver', {get: () => undefined});
                window.navigator.chrome = { runtime: {} };
                Object.defineProperty(navigator, 'languages', {get: () => ['en-US', 'en']});
                Object.defineProperty(navigator, 'plugins', {get: () => [1, 2, 3, 4, 5]});
            """)
            context.add_cookies(sanitized_cookies)
            page = context.new_page()

            success, _ = collector.process_single_url(page, url_data)
            collector.mark_url_as_processed(url_data['url'], success)
            result_queue.put(success)

            page.close()
            context.close()
            browser.close()
    except Exception as e:
        print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ –¥–æ—á–µ—Ä–Ω–µ–º –ø—Ä–æ—Ü–µ—Å—Å–µ –¥–ª—è URL {url_data.get('url')}: {e}")
        import traceback
        traceback.print_exc()
        result_queue.put(False)

class RenderScreenshotCollector:
    def __init__(self, status_callback: Optional[Callable[[str, int], None]] = None, config_override: Optional[dict] = None):
        if config_override:
            self.credentials_path = config_override["credentials_path"]
            self.gdrive_folder_id = config_override["gdrive_folder_id"]
            self.bq_project_id = config_override["bq_project_id"]
            self.bq_dataset_id = config_override["bq_dataset_id"]
            self.bq_table_id = config_override["bq_table_id"]
            self.min_duration_seconds = config_override["min_duration_seconds"]
            self.cookies_path = config_override["cookies_path"]
            self.status_callback = None
            self.cookies = self._load_cookies_from_secret_file(verbose=False)
        else:
            self.status_callback = status_callback
            self.cookies_path = "/etc/secrets/cookies.json"
            self.credentials_path = settings.GOOGLE_APPLICATION_CREDENTIALS
            self.gdrive_folder_id = settings.GDRIVE_FOLDER_ID
            self.bq_project_id = settings.BQ_PROJECT_ID
            self.bq_dataset_id = settings.BQ_DATASET_ID
            self.bq_table_id = settings.BQ_TABLE_ID
            self.batch_size = int(os.environ.get('BATCH_SIZE', '50'))
            self.pause_between_batches = int(os.environ.get('PAUSE_BETWEEN_BATCHES', '300'))
            self.max_runtime_hours = int(os.environ.get('MAX_RUNTIME_HOURS', '18'))
            self.min_duration_seconds = int(os.environ.get('MIN_DURATION_SECONDS', '20'))
            self.start_time = None
            self.total_processed, self.total_successful, self.total_failed, self.total_timeouts, self.batches_completed = 0, 0, 0, 0, 0
            self._update_status("üîê –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è...", 1)
            self.cookies = self._load_cookies_from_secret_file()
        
        self.full_table_name = f"`{self.bq_project_id}.{self.bq_dataset_id}.{self.bq_table_id}`"
        self._init_bigquery()
        self._init_google_drive()

    def _update_status(self, details: str, progress: int):
        if self.status_callback: self.status_callback(details, progress)
        timestamp = datetime.now().strftime("%H:%M:%S")
        print(f"[{timestamp}] {details}")

    def _load_cookies_from_secret_file(self, verbose=True):
        if verbose: self._update_status(f"–ó–∞–≥—Ä—É–∑–∫–∞ cookies –∏–∑ {self.cookies_path}...", 2)
        if not os.path.exists(self.cookies_path):
            if verbose: self._update_status(f"‚ùå –§–∞–π–ª cookies –Ω–µ –Ω–∞–π–¥–µ–Ω!", 2)
            return []
        try:
            with open(self.cookies_path, 'r') as f: cookies = json.load(f)
            if verbose: self._update_status(f"‚úÖ Cookies –∑–∞–≥—Ä—É–∂–µ–Ω—ã ({len(cookies)} —à—Ç).", 3)
            return cookies
        except Exception as e:
            if verbose: self._update_status(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è cookies: {e}", 3)
            return []

    def _init_bigquery(self):
        try:
            credentials = service_account.Credentials.from_service_account_file(
                self.credentials_path, scopes=["https://www.googleapis.com/auth/bigquery"])
            self.bq_client = bigquery.Client(credentials=credentials, project=self.bq_project_id)
        except Exception as e:
            raise Exception(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ BigQuery: {e}")

    def _init_google_drive(self):
        try:
            credentials = service_account.Credentials.from_service_account_file(
                self.credentials_path, scopes=['https://www.googleapis.com/auth/drive'])
            self.drive_service = build('drive', 'v3', credentials=credentials)
        except Exception as e:
            raise Exception(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Google Drive: {e}")

    def get_unprocessed_urls(self, limit=None):
        query = f"SELECT session_replay_url, amplitude_id, session_replay_id, duration_seconds, events_count, record_date FROM {self.full_table_name} WHERE is_processed = FALSE AND duration_seconds >= {self.min_duration_seconds} ORDER BY record_date DESC"
        if limit: query += f"\nLIMIT {limit}"
        try:
            result = self.bq_client.query(query).result()
            urls_data = []
            for row in result:
                urls_data.append({
                    'url': row.session_replay_url, 'amplitude_id': row.amplitude_id,
                    'session_replay_id': row.session_replay_id, 'duration_seconds': row.duration_seconds,
                    'events_count': row.events_count,
                    'record_date': row.record_date.strftime('%Y-%m-%d') if hasattr(row.record_date, 'strftime') else str(row.record_date)
                })
            return urls_data
        except Exception as e:
            self._update_status(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è URL: {e}", -1)
            raise

    def mark_url_as_processed(self, url, success=True):
        try:
            update_query = f"UPDATE {self.full_table_name} SET is_processed = TRUE WHERE session_replay_url = @url"
            job_config = bigquery.QueryJobConfig(query_parameters=[bigquery.ScalarQueryParameter("url", "STRING", url)])
            self.bq_client.query(update_query, job_config=job_config).result()
        except Exception as e:
            print(f"[{datetime.now().strftime('%H:%M:%S')}] ‚ùå –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å—Ç–∞—Ç—É—Å–∞ URL {url}: {e}")

    def get_session_id_from_url(self, url):
        url_hash = hashlib.md5(url.encode()).hexdigest()[:8]
        if "sessionReplayId=" in url:
            parts = url.split("sessionReplayId=")[1].split("&")[0].split("/")
            session_replay_id = parts[0]
            session_start_time = parts[1] if len(parts) > 1 else "unknown"
            return f"{session_replay_id}_{session_start_time}_{url_hash}"
        return f"no_session_id_{url_hash}"

    def login_and_update_cookies(self, page):
        print("‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –≤—Ö–æ–¥–∞. –ü–æ–ø—ã—Ç–∫–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏...")
        login = os.environ.get('AMPLITUDE_LOGIN')
        password = os.environ.get('AMPLITUDE_PASSWORD')
        if not login or not password:
            print("‚ùå –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è AMPLITUDE_LOGIN –∏/–∏–ª–∏ AMPLITUDE_PASSWORD –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã!")
            return False
        try:
            page.goto("https://app.amplitude.com/login", timeout=60000)
            print(f"    –í–≤–æ–¥–∏–º –ª–æ–≥–∏–Ω...")
            page.fill('input[name="username"]', login)
            page.click('button[type="submit"]')
            print("    –í–≤–æ–¥–∏–º –ø–∞—Ä–æ–ª—å...")
            password_input = page.wait_for_selector('input[name="password"]', timeout=15000)
            password_input.fill(password)
            page.click('button[type="submit"]')
            print("    –û–∂–∏–¥–∞–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ–≥–æ –≤—Ö–æ–¥–∞...")
            page.wait_for_url(lambda url: "login" not in url, timeout=60000)
            page.wait_for_selector("nav", timeout=30000)
            print("‚úÖ –ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –ø—Ä–æ—à–ª–∞ —É—Å–ø–µ—à–Ω–æ!")
            print("    –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–æ–≤—ã–µ cookies...")
            new_cookies = page.context.cookies()
            with open(self.cookies_path, 'w') as f:
                json.dump(new_cookies, f)
            print("‚úÖ Cookies —É—Å–ø–µ—à–Ω–æ –æ–±–Ω–æ–≤–ª–µ–Ω—ã!")
            self.cookies = new_cookies
            return True
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –≤–æ –≤—Ä–µ–º—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏: {e}")
            try:
                page.screenshot(path="login_error_screenshot.png", full_page=True)
                print("    –°–∫—Ä–∏–Ω—à–æ—Ç –æ—à–∏–±–∫–∏ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ login_error_screenshot.png")
            except: pass
            return False

    def simulate_human_behavior(self, page):
        """–ò–º–∏—Ç–∞—Ü–∏—è —á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–≥–æ –ø–æ–≤–µ–¥–µ–Ω–∏—è –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –¥–µ—Ç–µ–∫—Ü–∏–∏"""
        try:
            for _ in range(random.randint(2, 4)):
                x = random.randint(200, 1200)
                y = random.randint(200, 700)
                page.mouse.move(x, y, steps=random.randint(5, 15))
                time.sleep(random.uniform(0.1, 0.3))
            if random.random() < 0.4:
                scroll_amount = random.randint(100, 500)
                direction = random.choice([1, -1])
                page.evaluate(f"window.scrollBy(0, {scroll_amount * direction})")
                time.sleep(random.uniform(0.5, 1.5))
        except Exception:
            pass

    def wait_for_content(self, page, selector, bad_texts=("Loading", "Loading summary"), timeout=10, min_text_length=10):
        """–£–ª—É—á—à–µ–Ω–Ω–æ–µ –æ–∂–∏–¥–∞–Ω–∏–µ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""
        print(f"‚è≥ –ñ–¥–µ–º –∑–∞–≥—Ä—É–∑–∫—É –∫–æ–Ω—Ç–µ–Ω—Ç–∞ (—Ç–∞–π–º–∞—É—Ç {timeout} —Å–µ–∫)...")
        start = time.time()
        last_log = 0
        while True:
            el = page.query_selector(selector)
            if el:
                txt = el.inner_text().strip()
                if txt and all(bad not in txt for bad in bad_texts) and len(txt) >= min_text_length:
                    print(f"‚úÖ –ö–æ–Ω—Ç–µ–Ω—Ç –∑–∞–≥—Ä—É–∂–µ–Ω –∑–∞ {time.time() - start:.1f} —Å–µ–∫")
                    return el
            elapsed = time.time() - start
            if elapsed - last_log >= 3:
                print(f"‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ... {elapsed:.1f}/{timeout} —Å–µ–∫")
                last_log = elapsed
            if elapsed > timeout:
                print(f"‚ö†Ô∏è –ö–æ–Ω—Ç–µ–Ω—Ç –Ω–µ –∑–∞–≥—Ä—É–∑–∏–ª—Å—è –∑–∞ {timeout} —Å–µ–∫")
                return None
            time.sleep(0.5)

    def screenshot_userinfo_block(self, page, session_id, base_dir):
        """–°–∫—Ä–∏–Ω—à–æ—Ç –±–ª–æ–∫–∞ —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ"""
        os.makedirs(base_dir, exist_ok=True)
        userinfo_div = None
        try:
            css_selector = '.cerulean-cardbase.cerulean-alpha-general-card'
            elements = page.query_selector_all(css_selector)
            for element in elements:
                try:
                    text = element.inner_text().strip()
                    bbox = element.bounding_box()
                    if (bbox and
                            bbox['y'] < 400 and
                            text and
                            len(text) > 10 and len(text) < 500 and
                            (any(char.isdigit() for char in text) or
                             any(country in text for country in
                                 ["Spain", "Peru", "Bolivia", "Ecuador", "Netherlands", "Costa Rica", "Russia"]))):
                        userinfo_div = element
                        break
                except Exception:
                    continue
        except Exception:
            pass

        if not userinfo_div:
            try:
                session_selectors = [
                    'text=Session Length',
                    'text=Event Total',
                    'text=Device Type'
                ]
                for selector in session_selectors:
                    element = page.query_selector(selector)
                    if element:
                        parent = element
                        for _ in range(5):
                            try:
                                parent = parent.evaluate_handle('el => el.parentElement').as_element()
                                if parent:
                                    bbox = parent.bounding_box()
                                    text = parent.inner_text().strip()
                                    if (bbox and bbox['y'] < 400 and
                                            bbox['width'] > 200 and bbox['height'] > 80 and
                                            len(text) > 20 and len(text) < 500):
                                        userinfo_div = parent
                                        break
                            except Exception:
                                break
                        if userinfo_div:
                            break
            except Exception:
                pass

        if not userinfo_div:
            print("‚ö†Ô∏è User info –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return None

        try:
            img_path = os.path.join(base_dir, f"{session_id}_userinfo.png")
            userinfo_div.screenshot(path=img_path)
            print("‚úÖ User info —Å–æ—Ö—Ä–∞–Ω—ë–Ω")
            return img_path
        except Exception:
            print("‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Å–∫—Ä–∏–Ω—à–æ—Ç–∞ user info")
            return None

    def screenshot_summary_flexible(self, page, session_id, base_dir, summary_el=None):
        """–ì–∏–±–∫–∏–π —Å–∫—Ä–∏–Ω—à–æ—Ç –±–ª–æ–∫–∞ Summary —Å fallback —Å—Ç—Ä–∞—Ç–µ–≥–∏—è–º–∏"""
        os.makedirs(base_dir, exist_ok=True)
        print("üìÑ –ò—â–µ–º Summary –±–ª–æ–∫...")

        el = summary_el
        if not el:
            el = self.wait_for_content(page, 'p.ltext-_uoww22', timeout=3)

        if el:
            text_content = el.inner_text().strip()
            if len(text_content) > 20:
                print(f"‚úÖ Summary –∑–∞–≥—Ä—É–∂–µ–Ω (–¥–ª–∏–Ω–∞: {len(text_content)} —Å–∏–º–≤–æ–ª–æ–≤)")
            else:
                print(f"‚ö†Ô∏è Summary —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π ({len(text_content)} —Å–∏–º–≤–æ–ª–æ–≤), –ø—Ä–æ–±—É–µ–º fallback")
                el = None

        if not el:
            print("‚ö†Ô∏è –ü—Ä–æ–±—É–µ–º fallback —Å–µ–ª–µ–∫—Ç–æ—Ä—ã –¥–ª—è Summary...")
            fallback_selectors = [
                'div[style*="min-width: 460px"]',
                '.ltext-_uoww22',
                'div:has-text("Summary")',
                'p:has-text("The user")',
                'p:has-text("session")',
                '[data-testid*="summary"]',
                'div[class*="summary"] p'
            ]
            for selector in fallback_selectors:
                try:
                    el = page.query_selector(selector)
                    if el:
                        text = el.inner_text().strip()
                        if text and len(text) > 20 and "Loading" not in text:
                            print(f"‚úÖ Fallback —Å—Ä–∞–±–æ—Ç–∞–ª —Å —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–º: {selector}")
                            break
                        else:
                            el = None
                except Exception:
                    continue

            if not el:
                print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ Summary –±–ª–æ–∫ –Ω–∏ –æ–¥–Ω–∏–º —Å–ø–æ—Å–æ–±–æ–º")
                return []

        try:
            img_name = os.path.join(base_dir, f"{session_id}_summary.png")
            el.screenshot(path=img_name)
            print("‚úÖ Summary —Å–∫—Ä–∏–Ω—à–æ—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω")
            return [img_name]
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Å–∫—Ä–∏–Ω—à–æ—Ç–∞ Summary: {e}")
            return []

    def screenshot_by_title(self, page, block_title, session_id, base_dir):
        """–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π —Å–∫—Ä–∏–Ω—à–æ—Ç –±–ª–æ–∫–∞ –ø–æ –∑–∞–≥–æ–ª–æ–≤–∫—É"""
        os.makedirs(base_dir, exist_ok=True)
        print(f"üîç –ò—â–µ–º –±–ª–æ–∫ '{block_title}'...")
        el = None
        
        search_selectors = [
            f'h4:has-text("{block_title}")',
            f'h3:has-text("{block_title}")',
            f'h2:has-text("{block_title}")',
            f'div:has-text("{block_title}")',
            f'span:has-text("{block_title}")',
            f'h5:has-text("{block_title}")',
            f'[title="{block_title}"]',
            f'[aria-label="{block_title}"]',
            f'[data-testid*="{block_title.lower()}"]'
        ]
        
        for selector in search_selectors:
            try:
                maybe = page.query_selector(selector)
                if maybe:
                    print(f"üìç –ù–∞–π–¥–µ–Ω —ç–ª–µ–º–µ–Ω—Ç —Å '{block_title}' —á–µ—Ä–µ–∑ —Å–µ–ª–µ–∫—Ç–æ—Ä: {selector}")
                    parent = maybe
                    for level in range(6):
                        try:
                            bbox = parent.bounding_box()
                            if bbox and bbox['height'] > 60 and bbox['width'] > 200:
                                text_content = parent.inner_text().strip()
                                if text_content and len(text_content) > 10:
                                    el = parent
                                    print(f"‚úÖ –ù–∞–π–¥–µ–Ω –ø–æ–¥—Ö–æ–¥—è—â–∏–π –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä –Ω–∞ —É—Ä–æ–≤–Ω–µ {level}")
                                    break
                        except Exception:
                            pass
                        try:
                            parent = parent.evaluate_handle('el => el.parentElement').as_element()
                            if not parent:
                                break
                        except Exception:
                            break
                    if el:
                        break
            except Exception:
                continue

        if not el:
            print(f"üîÑ –ü—Ä–æ–±—É–µ–º –ø–æ–∏—Å–∫ –ø–æ —á–∞—Å—Ç–∏—á–Ω–æ–º—É —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É '{block_title}'...")
            try:
                all_elements = page.query_selector_all('div, span, h1, h2, h3, h4, h5, h6')
                for element in all_elements:
                    try:
                        text = element.inner_text().strip()
                        if block_title.lower() in text.lower() and len(text) < 100:
                            parent = element
                            for _ in range(4):
                                try:
                                    parent = parent.evaluate_handle('el => el.parentElement').as_element()
                                    if parent:
                                        bbox = parent.bounding_box()
                                        parent_text = parent.inner_text().strip()
                                        if (bbox and bbox['height'] > 60 and
                                                len(parent_text) > len(text) and len(parent_text) < 1000):
                                            el = parent
                                            print(f"‚úÖ –ù–∞–π–¥–µ–Ω —á–µ—Ä–µ–∑ –ø–æ–∏—Å–∫ –ø–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É")
                                            break
                                except Exception:
                                    break
                            if el:
                                break
                    except Exception:
                        continue
            except Exception:
                pass

        if el:
            content_loaded = False
            print(f"‚è≥ –ñ–¥–µ–º –∑–∞–≥—Ä—É–∑–∫—É –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –±–ª–æ–∫–∞ '{block_title}'...")
            for attempt in range(30):
                try:
                    txt = el.inner_text().strip()
                    if txt and "Loading" not in txt and len(txt) > 10:
                        content_loaded = True
                        print(f"‚úÖ –ö–æ–Ω—Ç–µ–Ω—Ç –±–ª–æ–∫–∞ '{block_title}' –∑–∞–≥—Ä—É–∂–µ–Ω")
                        break
                except Exception:
                    pass
                time.sleep(0.5)

            if not content_loaded:
                print(f"‚ö†Ô∏è {block_title} ‚Äî –ù–µ –¥–æ–∂–¥–∞–ª–∏—Å—å –ø–æ–ª–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏, —Å–∫—Ä–∏–Ω—é –∫–∞–∫ –µ—Å—Ç—å")
        else:
            print(f"‚ùå –ë–ª–æ–∫ '{block_title}' –Ω–µ –Ω–∞–π–¥–µ–Ω!")
            return None

        try:
            img_path = os.path.join(base_dir, f"{session_id}_{block_title.lower()}.png")
            el.screenshot(path=img_path)
            print(f"‚úÖ {block_title} —Å–∫—Ä–∏–Ω—à–æ—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω")
            return img_path
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Å–∫—Ä–∏–Ω—à–æ—Ç–∞ {block_title}: {e}")
            return None

    def create_session_folder_structure(self, session_id, screenshots, url_data):
        session_dir = tempfile.mkdtemp(prefix=f"session_folder_{session_id}_")
        for screenshot_path in screenshots:
            if screenshot_path and os.path.exists(screenshot_path):
                shutil.copy2(screenshot_path, session_dir)
        metadata = {
            "session_id": session_id, "url": url_data['url'], "amplitude_id": url_data['amplitude_id'],
            "session_replay_id": url_data['session_replay_id'], "duration_seconds": url_data['duration_seconds'],
            "events_count": url_data['events_count'], "record_date": url_data.get('record_date', ''),
            "processed_at": datetime.now().isoformat(),
            "screenshots": [os.path.basename(path) for path in screenshots if path]
        }
        with open(os.path.join(session_dir, "metadata.json"), 'w') as f:
            json.dump(metadata, f, indent=2)
        return session_dir

    def upload_to_google_drive(self, file_path, filename, folder_id):
        try:
            file_metadata = {'name': filename, 'parents': [folder_id]}
            media = MediaFileUpload(file_path, resumable=True)
            file = self.drive_service.files().create(body=file_metadata, media_body=media, fields='id, name, webViewLink').execute()
            return file
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –≤ Google Drive: {e}")
            return None

    def create_and_upload_session_archive(self, session_dir, session_id, is_failure=False):
        try:
            prefix = "FAILURE" if is_failure else "session_replay"
            archive_name = f"{prefix}_{session_id}_{int(time.time())}.zip"
            archive_path_base = os.path.join(tempfile.gettempdir(), archive_name.replace('.zip',''))
            archive_path = shutil.make_archive(archive_path_base, 'zip', session_dir)
            
            print(f"üì¶ –°–æ–∑–¥–∞–Ω –∞—Ä—Ö–∏–≤: {archive_path}")
            uploaded_file = self.upload_to_google_drive(archive_path, os.path.basename(archive_path), self.gdrive_folder_id)
            if uploaded_file: print(f"‚òÅÔ∏è –ê—Ä—Ö–∏–≤ –∑–∞–≥—Ä—É–∂–µ–Ω –≤ Google Drive")
            return uploaded_file
        finally:
            if 'session_dir' in locals() and os.path.exists(session_dir):
                shutil.rmtree(session_dir, ignore_errors=True)
            if 'archive_path' in locals() and os.path.exists(archive_path):
                os.remove(archive_path)

    def process_single_url(self, page, url_data):
        url = url_data['url']
        session_id = self.get_session_id_from_url(url)
        temp_screenshots_dir = tempfile.mkdtemp(prefix=f"screenshots_{session_id}_")
        REQUIRED_BLOCKS = ['userinfo', 'summary', 'sentiment']
        screenshot_paths = []
        
        try:
            print(f"‚ñ∂Ô∏è –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–µ—Å—Å–∏—é: {session_id}")
            
            # –ò–º–∏—Ç–∞—Ü–∏—è —á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–≥–æ –ø–æ–≤–µ–¥–µ–Ω–∏—è
            self.simulate_human_behavior(page)
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É —Å —É–≤–µ–ª–∏—á–µ–Ω–Ω—ã–º —Ç–∞–π–º–∞—É—Ç–æ–º
            page.goto(url, timeout=60000, wait_until='domcontentloaded')
            time.sleep(random.uniform(2, 5))

            if "/login" in page.url:
                login_successful = self.login_and_update_cookies(page)
                if not login_successful: return False, []
                print(f"    –í–æ–∑–≤—Ä–∞—â–∞–µ–º—Å—è –∫ –∏—Å—Ö–æ–¥–Ω–æ–π —Å—Å—ã–ª–∫–µ...")
                page.goto(url, timeout=60000, wait_until='domcontentloaded')
                time.sleep(random.uniform(2, 5))

            # –ò—â–µ–º –∏ –∫–ª–∏–∫–∞–µ–º –Ω–∞ Summary —Å –±–æ–ª–µ–µ –Ω–∞–¥–µ–∂–Ω–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–µ–π
            summary_tab = page.query_selector("text=Summary")
            if summary_tab:
                try:
                    self.simulate_human_behavior(page)
                    summary_tab.click()
                    print("üñ±Ô∏è –ö–ª–∏–∫–Ω—É–ª–∏ –Ω–∞ Summary")
                    time.sleep(random.uniform(3, 6))
                    summary_el = self.wait_for_content(page, 'p.ltext-_uoww22', timeout=20)
                except PlaywrightError as e:
                    print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∫–ª–∏–∫–∞ –Ω–∞ Summary: {e}")
                    # –ü—Ä–æ–±—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ —Å–ø–æ—Å–æ–±—ã
                    try:
                        summary_tab = page.wait_for_selector("text=Summary", timeout=5000)
                        summary_tab.click(force=True)
                        print("üñ±Ô∏è –ö–ª–∏–∫–Ω—É–ª–∏ –Ω–∞ Summary (force)")
                        time.sleep(random.uniform(3, 6))
                        summary_el = self.wait_for_content(page, 'p.ltext-_uoww22', timeout=20)
                    except Exception as e2:
                        print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∫–ª–∏–∫–Ω—É—Ç—å –Ω–∞ Summary: {e2}")
                        return False, []
            else:
                print("‚ùå –í–∫–ª–∞–¥–∫–∞ Summary –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!")
                return False, []

            screenshot_results = {}
            print("\nüì∏ –ù–∞—á–∏–Ω–∞–µ–º —Å–æ–∑–¥–∞–Ω–∏–µ —Å–∫—Ä–∏–Ω—à–æ—Ç–æ–≤...")

            # 1. User Info –±–ª–æ–∫
            print("\n1Ô∏è‚É£ User Info –±–ª–æ–∫:")
            userinfo_path = self.screenshot_userinfo_block(page, session_id, temp_screenshots_dir)
            screenshot_results['userinfo'] = userinfo_path is not None
            if userinfo_path:
                screenshot_paths.append(userinfo_path)
            time.sleep(random.uniform(1, 2))

            # 2. Summary –±–ª–æ–∫
            print("\n2Ô∏è‚É£ Summary –±–ª–æ–∫:")
            summary_paths = self.screenshot_summary_flexible(page, session_id, temp_screenshots_dir, summary_el=summary_el)
            screenshot_results['summary'] = len(summary_paths) > 0
            if summary_paths:
                screenshot_paths.extend(summary_paths)
            time.sleep(random.uniform(1, 2))

            # 3. Sentiment –±–ª–æ–∫
            print("\n3Ô∏è‚É£ Sentiment –±–ª–æ–∫:")
            sentiment_path = self.screenshot_by_title(page, "Sentiment", session_id, temp_screenshots_dir)
            screenshot_results['sentiment'] = sentiment_path is not None
            if sentiment_path:
                screenshot_paths.append(sentiment_path)
            time.sleep(random.uniform(1, 2))

            # 4. Actions –±–ª–æ–∫ (–¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π)
            print("\n4Ô∏è‚É£ Actions –±–ª–æ–∫:")
            actions_path = self.screenshot_by_title(page, "Actions", session_id, temp_screenshots_dir)
            screenshot_results['actions'] = actions_path is not None
            if actions_path:
                screenshot_paths.append(actions_path)

            print(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–∫—Ä–∏–Ω—à–æ—Ç–æ–≤:")
            for block, success in screenshot_results.items():
                status = "‚úÖ" if success else "‚ùå"
                print(f"   {status} {block.capitalize()}")

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –≤—Å–µ—Ö –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –±–ª–æ–∫–æ–≤
            all_required_success = all(screenshot_results.get(block, False) for block in REQUIRED_BLOCKS)
            total_blocks = len([path for path in screenshot_paths if path and os.path.exists(path)])

            print(f"\nüéØ –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞:")
            print(f"   üìã –í—Å–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –±–ª–æ–∫–∏: {'‚úÖ' if all_required_success else '‚ùå'}")
            print(f"   üì∏ –í—Å–µ–≥–æ —Å–∫—Ä–∏–Ω—à–æ—Ç–æ–≤: {total_blocks}")

            # –í Render —Ä–µ–∂–∏–º–µ –ø—Ä–∏–Ω–∏–º–∞–µ–º –¥–∞–∂–µ —á–∞—Å—Ç–∏—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            if total_blocks < 2:
                print(f"‚ùå –ü–æ–ª—É—á–µ–Ω–æ –º–µ–Ω—å—à–µ 2 —Å–∫—Ä–∏–Ω—à–æ—Ç–æ–≤ ({total_blocks}). –†–µ–∑—É–ª—å—Ç–∞—Ç –Ω–µ –±—É–¥–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω.")
                return False, screenshot_paths

            # –°–æ–∑–¥–∞–µ–º –∏ –∑–∞–≥—Ä—É–∂–∞–µ–º –∞—Ä—Ö–∏–≤
            session_dir = self.create_session_folder_structure(session_id, screenshot_paths, url_data)
            uploaded_file = self.create_and_upload_session_archive(session_dir, session_id)

            if uploaded_file:
                # –û—á–∏—â–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
                for path in screenshot_paths:
                    if path and os.path.exists(path):
                        os.remove(path)
                return True, screenshot_paths
            else:
                print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∞—Ä—Ö–∏–≤ –≤ Google Drive")
                return False, screenshot_paths

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ URL {url}: {e}")
            import traceback
            traceback.print_exc()
            
            # –°–æ–∑–¥–∞–µ–º failure –∞—Ä—Ö–∏–≤
            failure_path = os.path.join(temp_screenshots_dir, f"FAILURE_screenshot.png")
            try:
                page.screenshot(path=failure_path, full_page=True, timeout=15000)
                print(f"    –°–∫—Ä–∏–Ω—à–æ—Ç –æ—à–∏–±–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω.")
                screenshot_paths.append(failure_path)
            except Exception as e_scr:
                print(f"    –ù–µ —É–¥–∞–ª–æ—Å—å —Å–¥–µ–ª–∞—Ç—å —Å–∫—Ä–∏–Ω—à–æ—Ç –æ—à–∏–±–∫–∏: {e_scr}")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º HTML –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
            try:
                html_path = os.path.join(temp_screenshots_dir, f"FAILURE_page_content.html")
                with open(html_path, 'w', encoding='utf-8') as f:
                    f.write(page.content())
                print(f"    HTML –∫–æ–Ω—Ç–µ–Ω—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏.")
            except Exception as e_html:
                print(f"    –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å HTML: {e_html}")
            
            self.create_and_upload_session_archive(temp_screenshots_dir, session_id, is_failure=True)
            return False, screenshot_paths
        finally:
            if 'temp_screenshots_dir' in locals() and os.path.exists(temp_screenshots_dir):
                shutil.rmtree(temp_screenshots_dir, ignore_errors=True)
    
    def process_batch(self, urls_batch):
        batch_start_time = time.time()
        batch_successful, batch_failed, batch_timeouts = 0, 0, 0
        self._update_status(f"üöÄ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –±–∞—Ç—á–∞ –∏–∑ {len(urls_batch)} URL...", -1)
        result_queue = multiprocessing.Queue()
        collector_config = {
            "credentials_path": self.credentials_path, "gdrive_folder_id": self.gdrive_folder_id,
            "bq_project_id": self.bq_project_id, "bq_dataset_id": self.bq_dataset_id,
            "bq_table_id": self.bq_table_id, "min_duration_seconds": self.min_duration_seconds,
            "cookies_path": self.cookies_path 
        }
        safety_settings = self.get_safety_settings()
        
        for i, url_data in enumerate(urls_batch, 1):
            self._update_status(f"‚ñ∂Ô∏è [{i}/{len(urls_batch)}] –ó–∞–ø—É—Å–∫–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å –¥–ª—è URL ...{url_data['url'][-40:]}", -1)
            process = multiprocessing.Process(target=worker_process_url, args=(collector_config, url_data, result_queue))
            process.start()
            process.join(timeout=PROCESS_TIMEOUT_PER_URL)
            
            if process.is_alive():
                try:
                    self._update_status(f"‚ùó –¢–ê–ô–ú–ê–£–¢! –ü—Ä–æ—Ü–µ—Å—Å –¥–ª—è URL ...{url_data['url'][-40:]} –∑–∞–≤–∏—Å. –ó–∞–≤–µ—Ä—à–∞–µ–º.", -1)
                    process.terminate()
                    process.join(timeout=5)
                    if process.is_alive(): 
                        process.kill()
                        process.join(timeout=5)
                    batch_timeouts += 1
                    batch_failed += 1
                    self.mark_url_as_processed(url_data['url'], success=False)
                except Exception as e:
                    self._update_status(f"‚ùå –û–®–ò–ë–ö–ê –≤–æ –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–∞–π–º–∞—É—Ç–∞! {e}", -1)
                    batch_failed += 1
                    batch_timeouts += 1
            else:
                try:
                    success = result_queue.get_nowait()
                    if success: 
                        batch_successful += 1
                    else: 
                        batch_failed += 1
                except queue.Empty:
                    batch_failed += 1
                    self.mark_url_as_processed(url_data['url'], success=False)
            
            if i < len(urls_batch):
                time.sleep(random.uniform(safety_settings['min_delay'], safety_settings['max_delay']))
        
        self.total_processed += len(urls_batch)
        self.total_successful += batch_successful
        self.total_failed += batch_failed
        self.total_timeouts += batch_timeouts
        self.batches_completed += 1
        batch_time = time.time() - batch_start_time
        self._update_status(f"üì¶ –ë–∞—Ç—á #{self.batches_completed} –∑–∞–≤–µ—Ä—à–µ–Ω –∑–∞ {batch_time/60:.1f} –º–∏–Ω. [–£—Å–ø–µ—à–Ω–æ: {batch_successful}, –û—à–∏–±–æ–∫: {batch_failed}, –ó–∞–≤–∏—Å–∞–Ω–∏–π: {batch_timeouts}]", -1)
        
    def run(self):
        self.start_time = time.time()
        self._update_status("üîÑ –ó–ê–ü–£–°–ö –ù–ï–ü–†–ï–†–´–í–ù–û–ô –û–ë–†–ê–ë–û–¢–ö–ò", 10)
        cycle_number = 0
        try:
            while True:
                cycle_number += 1
                if self.check_runtime_limit(): break
                self._update_status(f"\nüîç –¶–ò–ö–õ #{cycle_number}: –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ URL...", -1)
                urls_batch = self.get_unprocessed_urls(limit=self.batch_size)
                if not urls_batch:
                    self._update_status("üéâ –í—Å–µ URL –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã!", -1)
                    break
                self._update_status(f"üìã –ù–∞–π–¥–µ–Ω–æ {len(urls_batch)} URL –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏", -1)
                self.process_batch(urls_batch)
                if not self.get_unprocessed_urls(limit=1):
                    self._update_status("üéØ –í—Å–µ URL –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã!", -1)
                    break
                pause_time = random.uniform(self.pause_between_batches, self.pause_between_batches + 60)
                self._update_status(f"‚è∏Ô∏è –ü–∞—É–∑–∞ –º–µ–∂–¥—É –±–∞—Ç—á–∞–º–∏: {pause_time:.1f} —Å–µ–∫...", -1)
                time.sleep(pause_time)
        except KeyboardInterrupt:
            self._update_status("‚ö†Ô∏è –ü–æ–ª—É—á–µ–Ω —Å–∏–≥–Ω–∞–ª –æ—Å—Ç–∞–Ω–æ–≤–∫–∏.", -1)
        except Exception as e:
            self._update_status(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}", -1)
            import traceback
            traceback.print_exc()
        self.print_overall_stats()

    def get_safety_settings(self):
        safety_mode = os.environ.get('SAFETY_MODE', 'normal').lower()
        if safety_mode == 'slow': 
            return {'min_delay': 3, 'max_delay': 8, 'name': '–ú–ï–î–õ–ï–ù–ù–´–ô'}
        if safety_mode == 'fast': 
            return {'min_delay': 1, 'max_delay': 3, 'name': '–ë–´–°–¢–†–´–ô'}
        return {'min_delay': 2, 'max_delay': 5, 'name': '–û–ë–´–ß–ù–´–ô'}
        
    def print_overall_stats(self):
        if self.start_time:
            elapsed = time.time() - self.start_time
            elapsed_hours = elapsed / 3600
            success_rate = (self.total_successful / self.total_processed * 100) if self.total_processed > 0 else 0
            self._update_status("=" * 60, -1)
            self._update_status(f"üìä –û–ë–©–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê –†–ê–ë–û–¢–´", -1)
            self._update_status(f"‚è±Ô∏è  –í—Ä–µ–º—è —Ä–∞–±–æ—Ç—ã: {elapsed_hours:.1f} —á–∞—Å–æ–≤", -1)
            self._update_status(f"üîÑ –ë–∞—Ç—á–µ–π –∑–∞–≤–µ—Ä—à–µ–Ω–æ: {self.batches_completed}", -1)
            self._update_status(f"üìà –í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {self.total_processed} URL", -1)
            self._update_status(f"‚úÖ –£—Å–ø–µ—à–Ω–æ: {self.total_successful}", -1)
            self._update_status(f"‚ùå –û—à–∏–±–æ–∫: {self.total_failed}", -1)
            self._update_status(f"‚ùó –ó–∞–≤–∏—Å–∞–Ω–∏–π (Timeout): {self.total_timeouts}", -1)
            self._update_status(f"üìä –ü—Ä–æ—Ü–µ–Ω—Ç —É—Å–ø–µ—Ö–∞: {success_rate:.1f}%", -1)
            if self.total_processed > 0:
                avg_time_per_url = elapsed / self.total_processed
                self._update_status(f"‚ö° –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –Ω–∞ URL: {avg_time_per_url:.1f} —Å–µ–∫", -1)
            self._update_status("=" * 60, -1)

    def check_runtime_limit(self):
        if self.start_time:
            elapsed_hours = (time.time() - self.start_time) / 3600
            if elapsed_hours >= self.max_runtime_hours:
                self._update_status(f"‚è∞ –î–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç –≤—Ä–µ–º–µ–Ω–∏ —Ä–∞–±–æ—Ç—ã ({self.max_runtime_hours}—á)", -1)
                return True
        return False

def main():
    if sys.platform != 'win32':
        multiprocessing.set_start_method('spawn', force=True)
    multiprocessing.freeze_support()
    try:
        collector = RenderScreenshotCollector()
        collector.run()
    except Exception as e:
        print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()