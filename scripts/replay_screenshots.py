import json
import os
import time
import hashlib
import random
import sys
from datetime import datetime
from playwright.sync_api import sync_playwright, Error as PlaywrightError, TimeoutError as PlaywrightTimeoutError
import tempfile
import shutil
from typing import Callable, Optional
import zipfile
import multiprocessing
import queue
import io
import psutil

# –ò–º–ø–æ—Ä—Ç—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Google API
from google.oauth2.credentials import Credentials
from google.auth.transport.requests import Request
from googleapiclient.discovery import build
from googleapiclient.http import MediaIoBaseUpload
from google.cloud import bigquery
from google.oauth2 import service_account

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø—É—Ç–∏ –∫ –∫–æ—Ä–Ω—é –ø—Ä–æ–µ–∫—Ç–∞ –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞ –Ω–∞—Å—Ç—Ä–æ–µ–∫
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
try:
    from config.settings import settings
except ImportError:
    class MockSettings:
        GOOGLE_APPLICATION_CREDENTIALS = os.environ.get('GOOGLE_APPLICATION_CREDENTIALS', '/etc/secrets/bigquery-credentials.json')
        GDRIVE_FOLDER_ID = os.environ.get('GDRIVE_FOLDER_ID', '1K8cbFU2gYpvP3PiHwOOHS1KREqdj6fQX')
        BQ_PROJECT_ID = os.environ.get('BQ_PROJECT_ID', 'codellon-dwh')
        BQ_DATASET_ID = os.environ.get('BQ_DATASET_ID', 'amplitude_session_replay')
        BQ_TABLE_ID = os.environ.get('BQ_TABLE_ID', 'session_replay_urls')
    settings = MockSettings()

# –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã
PROCESS_TIMEOUT_PER_URL = 180  # –°–Ω–∏–∂–µ–Ω–æ –¥–æ 180 —Å–µ–∫—É–Ω–¥, –∫–∞–∫ –≤ –ª–æ–∫–∞–ª—å–Ω–æ–º –∫–æ–¥–µ
USER_AGENTS = [
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.0 Safari/605.1.15",
    "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:120.0) Gecko/20100101 Firefox/120.0"
]

class DriveOAuthClient:
    """–ö–ª–∏–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Google Drive —á–µ—Ä–µ–∑ OAuth"""
    
    def __init__(self):
        self.service = None
        self.scopes = ['https://www.googleapis.com/auth/drive.file']
        
    def authenticate(self):
        """–ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è —á–µ—Ä–µ–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã"""
        try:
            refresh_token = os.environ.get('GOOGLE_REFRESH_TOKEN')
            client_id = os.environ.get('GOOGLE_CLIENT_ID')
            client_secret = os.environ.get('GOOGLE_CLIENT_SECRET')
            
            if not all([refresh_token, client_id, client_secret]):
                raise ValueError("–ù–µ –≤—Å–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –Ω–∞—Å—Ç—Ä–æ–µ–Ω—ã")
            
            creds = Credentials(
                token=None,
                refresh_token=refresh_token,
                token_uri='https://oauth2.googleapis.com/token',
                client_id=client_id,
                client_secret=client_secret,
                scopes=self.scopes
            )
            
            creds.refresh(Request())
            self.service = build('drive', 'v3', credentials=creds)
            print("‚úÖ OAuth –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –≤ Google Drive —É—Å–ø–µ—à–Ω–∞")
            return True
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ OAuth –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏: {e}")
            return False
    
    def upload_file(self, file_path, file_name=None, folder_id=None):
        """–ó–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª –≤ Google Drive"""
        try:
            if not self.service:
                if not self.authenticate():
                    return None
            
            if not file_name:
                file_name = os.path.basename(file_path)
            
            file_metadata = {'name': file_name}
            if folder_id:
                file_metadata['parents'] = [folder_id]
            
            with open(file_path, 'rb') as file_data:
                media = MediaIoBaseUpload(
                    io.BytesIO(file_data.read()),
                    mimetype='application/octet-stream',
                    resumable=True
                )
            
            file = self.service.files().create(
                body=file_metadata,
                media_body=media,
                fields='id,name,webViewLink'
            ).execute()
            
            print(f"‚úÖ –§–∞–π–ª –∑–∞–≥—Ä—É–∂–µ–Ω: {file.get('name')}")
            print(f"üîó –°—Å—ã–ª–∫–∞: {file.get('webViewLink')}")
            
            return {
                'id': file.get('id'),
                'name': file.get('name'),
                'webViewLink': file.get('webViewLink')
            }
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞: {e}")
            return None

def sanitize_cookies(cookies):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∏ –∏—Å–ø—Ä–∞–≤–ª—è–µ—Ç cookies –¥–ª—è —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è —Ñ–æ—Ä–º–∞—Ç—É Playwright"""
    if not cookies:
        return []
    valid_same_site_values = {"Strict", "Lax", "None"}
    sanitized_cookies = []
    for cookie in cookies:
        if cookie.get('sameSite') not in valid_same_site_values:
            original_value = cookie.get('sameSite', '–ö–õ–Æ–ß –û–¢–°–£–¢–°–¢–í–û–í–ê–õ')
            print(f"‚ö†Ô∏è –ò—Å–ø—Ä–∞–≤–ª—è—é sameSite='{original_value}' –Ω–∞ 'Lax' –¥–ª—è –∫—É–∫–∏: {cookie.get('name')}")
            cookie['sameSite'] = 'Lax'
        sanitized_cookies.append(cookie)
    return sanitized_cookies

def worker_process_url(collector_config: dict, url_data: dict, result_queue: multiprocessing.Queue):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ URL –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø—Ä–æ—Ü–µ—Å—Å–µ"""
    try:
        collector = RenderScreenshotCollector(config_override=collector_config)
        sanitized_cookies = sanitize_cookies(collector.cookies)

        with sync_playwright() as p:
            browser_args = [
                '--no-proxy-server', '--disable-proxy-config-service', '--no-sandbox',
                '--disable-setuid-sandbox', '--disable-blink-features=AutomationControlled',
                '--disable-dev-shm-usage', '--disable-web-security',
                '--disable-features=VizDisplayCompositor'
            ]
            browser = p.chromium.launch(headless=True, args=browser_args)
            user_agent = random.choice(USER_AGENTS)
            context = browser.new_context(
                user_agent=user_agent, viewport={'width': 1366, 'height': 768},
                locale='en-US', timezone_id='America/New_York'
            )
            context.add_init_script("""
                Object.defineProperty(navigator, 'webdriver', {get: () => undefined});
                window.navigator.chrome = { runtime: {} };
                Object.defineProperty(navigator, 'languages', {get: () => ['en-US', 'en']});
                Object.defineProperty(navigator, 'plugins', {get: () => [1, 2, 3, 4, 5]});
            """)
            context.add_cookies(sanitized_cookies)
            page = context.new_page()

            success, _ = collector.process_single_url(page, url_data)
            collector.mark_url_as_processed(url_data['url'], success)
            result_queue.put(success)

            page.close()
            context.close()
            browser.close()
    except Exception as e:
        print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ –¥–æ—á–µ—Ä–Ω–µ–º –ø—Ä–æ—Ü–µ—Å—Å–µ –¥–ª—è URL {url_data.get('url')}: {e}")
        import traceback
        traceback.print_exc()
        result_queue.put(False)

class RenderScreenshotCollector:
    def __init__(self, status_callback: Optional[Callable[[str, int], None]] = None, config_override: Optional[dict] = None):
        if config_override:
            self.credentials_path = config_override["credentials_path"]
            self.gdrive_folder_id = config_override["gdrive_folder_id"]
            self.bq_project_id = config_override["bq_project_id"]
            self.bq_dataset_id = config_override["bq_dataset_id"]
            self.bq_table_id = config_override["bq_table_id"]
            self.min_duration_seconds = config_override["min_duration_seconds"]
            self.cookies_path = config_override["cookies_path"]
            self.status_callback = None
            self.cookies = self._load_cookies_from_secret_file(verbose=False)
        else:
            self.status_callback = status_callback
            self.cookies_path = "/etc/secrets/cookies.json"
            self.credentials_path = settings.GOOGLE_APPLICATION_CREDENTIALS
            self.gdrive_folder_id = settings.GDRIVE_FOLDER_ID
            self.bq_project_id = settings.BQ_PROJECT_ID
            self.bq_dataset_id = settings.BQ_DATASET_ID
            self.bq_table_id = settings.BQ_TABLE_ID
            self.min_duration_seconds = int(os.environ.get('MIN_DURATION_SECONDS', '20'))
            self.start_time = None
            self.total_processed, self.total_successful, self.total_failed, self.total_timeouts = 0, 0, 0, 0
            self._update_status("üîê –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è...", 1)
            self.cookies = self._load_cookies_from_secret_file()
        
        self.full_table_name = f"`{self.bq_project_id}.{self.bq_dataset_id}.{self.bq_table_id}`"
        self._init_bigquery()
        self._init_google_drive_oauth()

    def _update_status(self, details: str, progress: int):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ —Å —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –≤—ã–≤–æ–¥–æ–º"""
        if self.status_callback:
            self.status_callback(details, progress)
        timestamp = datetime.now().strftime("%H:%M:%S")
        print(f"\n{'=' * 20} [{timestamp}] {'=' * 20}\n{details}\n{'=' * 50}")

    def _load_cookies_from_secret_file(self, verbose=True):
        """–ó–∞–≥—Ä—É–∑–∫–∞ cookies –∏–∑ —Ñ–∞–π–ª–∞"""
        if verbose:
            self._update_status(f"–ó–∞–≥—Ä—É–∑–∫–∞ cookies –∏–∑ {self.cookies_path}...", 2)
        if not os.path.exists(self.cookies_path):
            if verbose:
                self._update_status(f"‚ùå –§–∞–π–ª cookies –Ω–µ –Ω–∞–π–¥–µ–Ω!", 2)
            return []
        try:
            with open(self.cookies_path, 'r') as f:
                cookies = json.load(f)
            if verbose:
                self._update_status(f"‚úÖ Cookies –∑–∞–≥—Ä—É–∂–µ–Ω—ã ({len(cookies)} —à—Ç).", 3)
            return cookies
        except Exception as e:
            if verbose:
                self._update_status(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è cookies: {e}", 3)
            return []

    def _init_bigquery(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è BigQuery"""
        try:
            credentials = service_account.Credentials.from_service_account_file(
                self.credentials_path, scopes=["https://www.googleapis.com/auth/bigquery"])
            self.bq_client = bigquery.Client(credentials=credentials, project=self.bq_project_id)
            self._update_status("‚úÖ BigQuery –ø–æ–¥–∫–ª—é—á–µ–Ω", 4)
        except Exception as e:
            raise Exception(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ BigQuery: {e}")

    def _init_google_drive_oauth(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Google Drive —á–µ—Ä–µ–∑ OAuth"""
        try:
            self.drive_client = DriveOAuthClient()
            if not self.drive_client.authenticate():
                raise Exception("–ù–µ —É–¥–∞–ª–æ—Å—å –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞—Ç—å—Å—è –≤ Google Drive")
            self._update_status("‚úÖ Google Drive OAuth –ø–æ–¥–∫–ª—é—á–µ–Ω", 5)
        except Exception as e:
            raise Exception(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Google Drive: {e}")

    def get_unprocessed_urls(self, limit=None):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –Ω–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö URL –∏–∑ BigQuery"""
        query = f"""
        SELECT session_replay_url, amplitude_id, session_replay_id, duration_seconds, events_count, record_date 
        FROM {self.full_table_name} 
        WHERE is_processed = FALSE AND duration_seconds >= {self.min_duration_seconds} 
        ORDER BY record_date DESC
        """
        if limit:
            query += f"\nLIMIT {limit}"
        try:
            result = self.bq_client.query(query).result()
            urls_data = []
            for row in result:
                urls_data.append({
                    'url': row.session_replay_url,
                    'amplitude_id': row.amplitude_id,
                    'session_replay_id': row.session_replay_id,
                    'duration_seconds': row.duration_seconds,
                    'events_count': row.events_count,
                    'record_date': row.record_date.strftime('%Y-%m-%d') if hasattr(row.record_date, 'strftime') else str(row.record_date)
                })
            self._update_status(f"üìä –ù–∞–π–¥–µ–Ω–æ {len(urls_data)} –Ω–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö URL", -1)
            return urls_data
        except Exception as e:
            self._update_status(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è URL: {e}", -1)
            raise

    def mark_url_as_processed(self, url, success=True):
        """–û—Ç–º–µ—Ç–∫–∞ URL –∫–∞–∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–≥–æ –≤ BigQuery"""
        try:
            update_query = f"""
            UPDATE {self.full_table_name} 
            SET is_processed = TRUE 
            WHERE session_replay_url = @url
            """
            job_config = bigquery.QueryJobConfig(
                query_parameters=[bigquery.ScalarQueryParameter("url", "STRING", url)]
            )
            self.bq_client.query(update_query, job_config=job_config).result()
            status = "‚úÖ" if success else "‚ùå"
            self._update_status(f"{status} URL –æ—Ç–º–µ—á–µ–Ω –∫–∞–∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π", -1)
        except Exception as e:
            self._update_status(f"‚ùå –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å—Ç–∞—Ç—É—Å–∞ URL {url}: {e}", -1)

    def get_session_id_from_url(self, url):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ ID —Å–µ—Å—Å–∏–∏ –∏–∑ URL"""
        url_hash = hashlib.md5(url.encode()).hexdigest()[:8]
        if "sessionReplayId=" in url:
            parts = url.split("sessionReplayId=")[1].split("&")[0].split("/")
            session_replay_id = parts[0]
            session_start_time = parts[1] if len(parts) > 1 else "unknown"
            return f"{session_replay_id}_{session_start_time}_{url_hash}"
        return f"no_session_id_{url_hash}"

    def login_and_update_cookies(self, page, max_retries=3):
        """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è —Å –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏"""
        login = os.environ.get('AMPLITUDE_LOGIN')
        password = os.environ.get('AMPLITUDE_PASSWORD')
        if not login or not password:
            self._update_status("‚ùå –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ AMPLITUDE_LOGIN –∏/–∏–ª–∏ AMPLITUDE_PASSWORD –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã!", -1)
            return False
        for attempt in range(max_retries):
            self._update_status(f"‚ö†Ô∏è –ü–æ–ø—ã—Ç–∫–∞ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ {attempt + 1}/{max_retries}...", -1)
            try:
                page.goto("https://app.amplitude.com/login", timeout=60000)
                self._update_status("    –í–≤–æ–¥–∏–º –ª–æ–≥–∏–Ω...", -1)
                page.fill('input[name="username"]', login)
                page.click('button[type="submit"]')
                self._update_status("    –í–≤–æ–¥–∏–º –ø–∞—Ä–æ–ª—å...", -1)
                password_input = page.wait_for_selector('input[name="password"]', timeout=15000)
                password_input.fill(password)
                page.click('button[type="submit"]')
                self._update_status("    –û–∂–∏–¥–∞–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ–≥–æ –≤—Ö–æ–¥–∞...", -1)
                page.wait_for_url(lambda url: "login" not in url, timeout=60000)
                page.wait_for_selector("nav", timeout=30000)
                self._update_status("‚úÖ –ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –ø—Ä–æ—à–ª–∞ —É—Å–ø–µ—à–Ω–æ!", -1)
                self._update_status("    –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–æ–≤—ã–µ cookies...", -1)
                new_cookies = page.context.cookies()
                with open(self.cookies_path, 'w') as f:
                    json.dump(new_cookies, f)
                self.cookies = new_cookies
                return True
            except Exception as e:
                self._update_status(f"‚ùå –û—à–∏–±–∫–∞ –≤–æ –≤—Ä–µ–º—è –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏: {e}", -1)
                try:
                    page.screenshot(path="login_error_screenshot.png", full_page=True)
                    self._update_status("    –°–∫—Ä–∏–Ω—à–æ—Ç –æ—à–∏–±–∫–∏ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω", -1)
                except:
                    pass
                if attempt < max_retries - 1:
                    time.sleep(random.uniform(5, 10))
        self._update_status("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞—Ç—å—Å—è –ø–æ—Å–ª–µ –≤—Å–µ—Ö –ø–æ–ø—ã—Ç–æ–∫", -1)
        return False

    def simulate_human_behavior(self, page):
        """–ò–º–∏—Ç–∞—Ü–∏—è —á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–≥–æ –ø–æ–≤–µ–¥–µ–Ω–∏—è"""
        try:
            for _ in range(random.randint(2, 4)):
                x = random.randint(200, 1200)
                y = random.randint(200, 700)
                page.mouse.move(x, y, steps=random.randint(5, 15))
                time.sleep(random.uniform(0.1, 0.3))
            if random.random() < 0.4:
                scroll_amount = random.randint(100, 500)
                direction = random.choice([1, -1])
                page.evaluate(f"window.scrollBy(0, {scroll_amount * direction})")
                time.sleep(random.uniform(0.5, 1.5))
        except Exception:
            pass

    def wait_for_content(self, page, selector, bad_texts=("Loading", "Loading summary"), timeout=10, min_text_length=10):
        """–û–∂–∏–¥–∞–Ω–∏–µ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""
        self._update_status(f"‚è≥ –ñ–¥–µ–º –∑–∞–≥—Ä—É–∑–∫—É –∫–æ–Ω—Ç–µ–Ω—Ç–∞ (—Ç–∞–π–º–∞—É—Ç {timeout} —Å–µ–∫)...", -1)
        start = time.time()
        last_log = 0
        while True:
            el = page.query_selector(selector)
            if el:
                txt = el.inner_text().strip()
                if txt and all(bad not in txt for bad in bad_texts) and len(txt) >= min_text_length:
                    self._update_status(f"‚úÖ –ö–æ–Ω—Ç–µ–Ω—Ç –∑–∞–≥—Ä—É–∂–µ–Ω –∑–∞ {time.time() - start:.1f} —Å–µ–∫", -1)
                    return el
            elapsed = time.time() - start
            if elapsed - last_log >= 3:
                self._update_status(f"‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ... {elapsed:.1f}/{timeout} —Å–µ–∫", -1)
                last_log = elapsed
            if elapsed > timeout:
                self._update_status(f"‚ö†Ô∏è –ö–æ–Ω—Ç–µ–Ω—Ç –Ω–µ –∑–∞–≥—Ä—É–∑–∏–ª—Å—è –∑–∞ {timeout} —Å–µ–∫", -1)
                return None
            time.sleep(0.5)

    def screenshot_userinfo_block(self, page, session_id, base_dir):
        """–°–∫—Ä–∏–Ω—à–æ—Ç –±–ª–æ–∫–∞ —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ"""
        os.makedirs(base_dir, exist_ok=True)
        userinfo_div = None
        try:
            css_selector = '.cerulean-cardbase.cerulean-alpha-general-card'
            elements = page.query_selector_all(css_selector)
            for element in elements:
                try:
                    text = element.inner_text().strip()
                    bbox = element.bounding_box()
                    if (bbox and
                            bbox['y'] < 400 and
                            text and
                            len(text) > 10 and len(text) < 500 and
                            (any(char.isdigit() for char in text) or
                             any(country in text for country in
                                 ["Spain", "Peru", "Bolivia", "Ecuador", "Netherlands", "Costa Rica", "Russia"]))):
                        userinfo_div = element
                        break
                except Exception:
                    continue
        except Exception:
            pass

        if not userinfo_div:
            try:
                session_selectors = [
                    'text=Session Length',
                    'text=Event Total',
                    'text=Device Type'
                ]
                for selector in session_selectors:
                    element = page.query_selector(selector)
                    if element:
                        parent = element
                        for _ in range(5):
                            try:
                                parent = parent.evaluate_handle('el => el.parentElement').as_element()
                                if parent:
                                    bbox = parent.bounding_box()
                                    text = parent.inner_text().strip()
                                    if (bbox and bbox['y'] < 400 and
                                            bbox['width'] > 200 and bbox['height'] > 80 and
                                            len(text) > 20 and len(text) < 500):
                                        userinfo_div = parent
                                        break
                            except Exception:
                                break
                        if userinfo_div:
                            break
            except Exception:
                pass

        if not userinfo_div:
            self._update_status("‚ö†Ô∏è User info –Ω–µ –Ω–∞–π–¥–µ–Ω", -1)
            return None

        try:
            img_path = os.path.join(base_dir, f"{session_id}_userinfo.png")
            userinfo_div.screenshot(path=img_path)
            self._update_status("‚úÖ User info —Å–æ—Ö—Ä–∞–Ω—ë–Ω", -1)
            return img_path
        except Exception:
            self._update_status("‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Å–∫—Ä–∏–Ω—à–æ—Ç–∞ user info", -1)
            return None

    def screenshot_summary_flexible(self, page, session_id, base_dir, summary_el=None):
        """–ì–∏–±–∫–∏–π —Å–∫—Ä–∏–Ω—à–æ—Ç –±–ª–æ–∫–∞ Summary"""
        os.makedirs(base_dir, exist_ok=True)
        self._update_status("üìÑ –ò—â–µ–º Summary –±–ª–æ–∫...", -1)

        el = summary_el
        if not el:
            el = self.wait_for_content(page, 'p.ltext-_uoww22', timeout=3)

        if el:
            text_content = el.inner_text().strip()
            if len(text_content) > 20:
                self._update_status(f"‚úÖ Summary –∑–∞–≥—Ä—É–∂–µ–Ω (–¥–ª–∏–Ω–∞: {len(text_content)} —Å–∏–º–≤–æ–ª–æ–≤)", -1)
            else:
                self._update_status(f"‚ö†Ô∏è Summary —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π ({len(text_content)} —Å–∏–º–≤–æ–ª–æ–≤), –ø—Ä–æ–±—É–µ–º fallback", -1)
                el = None

        if not el:
            self._update_status("‚ö†Ô∏è –ü—Ä–æ–±—É–µ–º fallback —Å–µ–ª–µ–∫—Ç–æ—Ä—ã –¥–ª—è Summary...", -1)
            fallback_selectors = [
                'div[style*="min-width: 460px"]',
                '.ltext-_uoww22',
                'div:has-text("Summary")',
                'p:has-text("The user")',
                'p:has-text("session")',
                '[data-testid*="summary"]',
                'div[class*="summary"] p'
            ]
            for selector in fallback_selectors:
                try:
                    el = page.query_selector(selector)
                    if el:
                        text = el.inner_text().strip()
                        if text and len(text) > 20 and "Loading" not in text:
                            self._update_status(f"‚úÖ Fallback —Å—Ä–∞–±–æ—Ç–∞–ª —Å —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–º: {selector}", -1)
                            break
                        else:
                            el = None
                except Exception:
                    continue

            if not el:
                self._update_status("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ Summary –±–ª–æ–∫ –Ω–∏ –æ–¥–Ω–∏–º —Å–ø–æ—Å–æ–±–æ–º", -1)
                return []

        try:
            img_name = os.path.join(base_dir, f"{session_id}_summary.png")
            el.screenshot(path=img_name)
            self._update_status("‚úÖ Summary —Å–∫—Ä–∏–Ω—à–æ—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω", -1)
            return [img_name]
        except Exception as e:
            self._update_status(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Å–∫—Ä–∏–Ω—à–æ—Ç–∞ Summary: {e}", -1)
            return []

    def screenshot_by_title(self, page, block_title, session_id, base_dir):
        """–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π —Å–∫—Ä–∏–Ω—à–æ—Ç –±–ª–æ–∫–∞ –ø–æ –∑–∞–≥–æ–ª–æ–≤–∫—É"""
        os.makedirs(base_dir, exist_ok=True)
        self._update_status(f"üîç –ò—â–µ–º –±–ª–æ–∫ '{block_title}'...", -1)
        el = None
        
        search_selectors = [
            f'h4:has-text("{block_title}")',
            f'h3:has-text("{block_title}")',
            f'h2:has-text("{block_title}")',
            f'div:has-text("{block_title}")',
            f'span:has-text("{block_title}")',
            f'h5:has-text("{block_title}")',
            f'[title="{block_title}"]',
            f'[aria-label="{block_title}"]',
            f'[data-testid*="{block_title.lower()}"]'
        ]
        
        for selector in search_selectors:
            try:
                maybe = page.query_selector(selector)
                if maybe:
                    self._update_status(f"üìç –ù–∞–π–¥–µ–Ω —ç–ª–µ–º–µ–Ω—Ç —Å '{block_title}' —á–µ—Ä–µ–∑ —Å–µ–ª–µ–∫—Ç–æ—Ä: {selector}", -1)
                    parent = maybe
                    for level in range(6):
                        try:
                            bbox = parent.bounding_box()
                            if bbox and bbox['height'] > 60 and bbox['width'] > 200:
                                text_content = parent.inner_text().strip()
                                if text_content and len(text_content) > 10:
                                    el = parent
                                    self._update_status(f"‚úÖ –ù–∞–π–¥–µ–Ω –ø–æ–¥—Ö–æ–¥—è—â–∏–π –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä –Ω–∞ —É—Ä–æ–≤–Ω–µ {level}", -1)
                                    break
                        except Exception:
                            pass
                        try:
                            parent = parent.evaluate_handle('el => el.parentElement').as_element()
                            if not parent:
                                break
                        except Exception:
                            break
                    if el:
                        break
            except Exception:
                continue

        if not el:
            self._update_status(f"üîÑ –ü—Ä–æ–±—É–µ–º –ø–æ–∏—Å–∫ –ø–æ —á–∞—Å—Ç–∏—á–Ω–æ–º—É —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É '{block_title}'...", -1)
            try:
                all_elements = page.query_selector_all('div, span, h1, h2, h3, h4, h5, h6')
                for element in all_elements:
                    try:
                        text = element.inner_text().strip()
                        if block_title.lower() in text.lower() and len(text) < 100:
                            parent = element
                            for _ in range(4):
                                try:
                                    parent = parent.evaluate_handle('el => el.parentElement').as_element()
                                    if parent:
                                        bbox = parent.bounding_box()
                                        parent_text = parent.inner_text().strip()
                                        if (bbox and bbox['height'] > 60 and
                                                len(parent_text) > len(text) and len(parent_text) < 1000):
                                            el = parent
                                            self._update_status(f"‚úÖ –ù–∞–π–¥–µ–Ω —á–µ—Ä–µ–∑ –ø–æ–∏—Å–∫ –ø–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É", -1)
                                            break
                                except Exception:
                                    break
                            if el:
                                break
                    except Exception:
                        continue
            except Exception:
                pass

        if el:
            content_loaded = False
            self._update_status(f"‚è≥ –ñ–¥–µ–º –∑–∞–≥—Ä—É–∑–∫—É –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –±–ª–æ–∫–∞ '{block_title}'...", -1)
            for attempt in range(30):
                try:
                    txt = el.inner_text().strip()
                    if txt and "Loading" not in txt and len(txt) > 10:
                        content_loaded = True
                        self._update_status(f"‚úÖ –ö–æ–Ω—Ç–µ–Ω—Ç –±–ª–æ–∫–∞ '{block_title}' –∑–∞–≥—Ä—É–∂–µ–Ω", -1)
                        break
                except Exception:
                    pass
                time.sleep(0.5)

            if not content_loaded:
                self._update_status(f"‚ö†Ô∏è {block_title} ‚Äî –ù–µ –¥–æ–∂–¥–∞–ª–∏—Å—å –ø–æ–ª–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏, —Å–∫—Ä–∏–Ω—é –∫–∞–∫ –µ—Å—Ç—å", -1)
        else:
            self._update_status(f"‚ùå –ë–ª–æ–∫ '{block_title}' –Ω–µ –Ω–∞–π–¥–µ–Ω!", -1)
            return None

        try:
            img_path = os.path.join(base_dir, f"{session_id}_{block_title.lower()}.png")
            el.screenshot(path=img_path)
            self._update_status(f"‚úÖ {block_title} —Å–∫—Ä–∏–Ω—à–æ—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω", -1)
            return img_path
        except Exception as e:
            self._update_status(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Å–∫—Ä–∏–Ω—à–æ—Ç–∞ {block_title}: {e}", -1)
            return None

    def create_session_folder_structure(self, session_id, screenshots, url_data):
        """–°–æ–∑–¥–∞–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –ø–∞–ø–∫–∏ —Å–µ—Å—Å–∏–∏"""
        session_dir = tempfile.mkdtemp(prefix=f"session_folder_{session_id}_")
        for screenshot_path in screenshots:
            if screenshot_path and os.path.exists(screenshot_path):
                shutil.copy2(screenshot_path, session_dir)
        metadata = {
            "session_id": session_id,
            "url": url_data['url'],
            "amplitude_id": url_data['amplitude_id'],
            "session_replay_id": url_data['session_replay_id'],
            "duration_seconds": url_data['duration_seconds'],
            "events_count": url_data['events_count'],
            "record_date": url_data.get('record_date', ''),
            "processed_at": datetime.now().isoformat(),
            "screenshots": [os.path.basename(path) for path in screenshots if path]
        }
        with open(os.path.join(session_dir, "metadata.json"), 'w') as f:
            json.dump(metadata, f, indent=2)
        return session_dir

    def upload_to_google_drive(self, file_path, filename, folder_id):
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞ –≤ Google Drive"""
        try:
            return self.drive_client.upload_file(file_path, filename, folder_id)
        except Exception as e:
            self._update_status(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –≤ Google Drive: {e}", -1)
            return None

    def create_and_upload_session_archive(self, session_dir, session_id, is_failure=False):
        """–°–æ–∑–¥–∞–Ω–∏–µ –∏ –∑–∞–≥—Ä—É–∑–∫–∞ –∞—Ä—Ö–∏–≤–∞ —Å–µ—Å—Å–∏–∏"""
        try:
            prefix = "FAILURE" if is_failure else "session_replay"
            archive_name = f"{prefix}_{session_id}_{int(time.time())}.zip"
            archive_path_base = os.path.join(tempfile.gettempdir(), archive_name.replace('.zip',''))
            archive_path = shutil.make_archive(archive_path_base, 'zip', session_dir)
            
            self._update_status(f"üì¶ –°–æ–∑–¥–∞–Ω –∞—Ä—Ö–∏–≤: {archive_name}", -1)
            uploaded_file = self.upload_to_google_drive(archive_path, archive_name, self.gdrive_folder_id)
            if uploaded_file:
                self._update_status(f"‚òÅÔ∏è –ê—Ä—Ö–∏–≤ –∑–∞–≥—Ä—É–∂–µ–Ω –≤ Google Drive", -1)
                self._update_status(f"üîó –°—Å—ã–ª–∫–∞: {uploaded_file.get('webViewLink', 'N/A')}", -1)
            return uploaded_file
        except Exception as e:
            self._update_status(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è/–∑–∞–≥—Ä—É–∑–∫–∏ –∞—Ä—Ö–∏–≤–∞: {e}", -1)
            return None
        finally:
            if 'session_dir' in locals() and os.path.exists(session_dir):
                shutil.rmtree(session_dir, ignore_errors=True)
            if 'archive_path' in locals() and os.path.exists(archive_path):
                os.remove(archive_path)

    def process_single_url(self, page, url_data):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ URL"""
        url = url_data['url']
        session_id = self.get_session_id_from_url(url)
        temp_screenshots_dir = tempfile.mkdtemp(prefix=f"screenshots_{session_id}_")
        REQUIRED_BLOCKS = ['userinfo', 'summary', 'sentiment']
        screenshot_paths = []
        
        try:
            self._update_status(f"‚ñ∂Ô∏è –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–µ—Å—Å–∏—é: {session_id}", -1)
            self.simulate_human_behavior(page)
            
            page.goto(url, timeout=60000, wait_until='domcontentloaded')
            time.sleep(random.uniform(2, 5))

            if "/login" in page.url:
                login_successful = self.login_and_update_cookies(page)
                if not login_successful:
                    return False, []
                self._update_status("    –í–æ–∑–≤—Ä–∞—â–∞–µ–º—Å—è –∫ –∏—Å—Ö–æ–¥–Ω–æ–π —Å—Å—ã–ª–∫–µ...", -1)
                page.goto(url, timeout=60000, wait_until='domcontentloaded')
                time.sleep(random.uniform(2, 5))

            summary_tab = page.query_selector("text=Summary")
            if summary_tab:
                try:
                    self.simulate_human_behavior(page)
                    summary_tab.click()
                    self._update_status("üñ±Ô∏è –ö–ª–∏–∫–Ω—É–ª–∏ –Ω–∞ Summary", -1)
                    time.sleep(random.uniform(3, 6))
                    summary_el = self.wait_for_content(page, 'p.ltext-_uoww22', timeout=20)
                except PlaywrightError as e:
                    self._update_status(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∫–ª–∏–∫–∞ –Ω–∞ Summary: {e}", -1)
                    try:
                        summary_tab = page.wait_for_selector("text=Summary", timeout=5000)
                        summary_tab.click(force=True)
                        self._update_status("üñ±Ô∏è –ö–ª–∏–∫–Ω—É–ª–∏ –Ω–∞ Summary (force)", -1)
                        time.sleep(random.uniform(3, 6))
                        summary_el = self.wait_for_content(page, 'p.ltext-_uoww22', timeout=20)
                    except Exception as e2:
                        self._update_status(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∫–ª–∏–∫–Ω—É—Ç—å –Ω–∞ Summary: {e2}", -1)
                        return False, []
            else:
                self._update_status("‚ùå –í–∫–ª–∞–¥–∫–∞ Summary –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!", -1)
                return False, []

            screenshot_results = {}
            self._update_status("\nüì∏ –ù–∞—á–∏–Ω–∞–µ–º —Å–æ–∑–¥–∞–Ω–∏–µ —Å–∫—Ä–∏–Ω—à–æ—Ç–æ–≤...", -1)

            self._update_status("\n1Ô∏è‚É£ User Info –±–ª–æ–∫:", -1)
            userinfo_path = self.screenshot_userinfo_block(page, session_id, temp_screenshots_dir)
            screenshot_results['userinfo'] = userinfo_path is not None
            if userinfo_path:
                screenshot_paths.append(userinfo_path)
            time.sleep(random.uniform(1, 2))

            self._update_status("\n2Ô∏è‚É£ Summary –±–ª–æ–∫:", -1)
            summary_paths = self.screenshot_summary_flexible(page, session_id, temp_screenshots_dir, summary_el=summary_el)
            screenshot_results['summary'] = len(summary_paths) > 0
            if summary_paths:
                screenshot_paths.extend(summary_paths)
            time.sleep(random.uniform(1, 2))

            self._update_status("\n3Ô∏è‚É£ Sentiment –±–ª–æ–∫:", -1)
            sentiment_path = self.screenshot_by_title(page, "Sentiment", session_id, temp_screenshots_dir)
            screenshot_results['sentiment'] = sentiment_path is not None
            if sentiment_path:
                screenshot_paths.append(sentiment_path)
            time.sleep(random.uniform(1, 2))

            self._update_status("\n4Ô∏è‚É£ Actions –±–ª–æ–∫:", -1)
            actions_path = self.screenshot_by_title(page, "Actions", session_id, temp_screenshots_dir)
            screenshot_results['actions'] = actions_path is not None
            if actions_path:
                screenshot_paths.append(actions_path)

            self._update_status("\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–∫—Ä–∏–Ω—à–æ—Ç–æ–≤:", -1)
            for block, success in screenshot_results.items():
                status = "‚úÖ" if success else "‚ùå"
                self._update_status(f"   {status} {block.capitalize()}", -1)

            all_required_success = all(screenshot_results.get(block, False) for block in REQUIRED_BLOCKS)
            total_blocks = len([path for path in screenshot_paths if path and os.path.exists(path)])

            self._update_status("\nüéØ –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞:", -1)
            self._update_status(f"   üìã –í—Å–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –±–ª–æ–∫–∏: {'‚úÖ' if all_required_success else '‚ùå'}", -1)
            self._update_status(f"   üì∏ –í—Å–µ–≥–æ —Å–∫—Ä–∏–Ω—à–æ—Ç–æ–≤: {total_blocks}", -1)

            if not all_required_success or total_blocks < 3:
                self._update_status(f"‚ùå –ù–µ –ø–æ–ª—É—á–µ–Ω—ã –≤—Å–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –±–ª–æ–∫–∏ –∏–ª–∏ –º–µ–Ω—å—à–µ 3 —Å–∫—Ä–∏–Ω—à–æ—Ç–æ–≤ ({total_blocks}).", -1)
                return False, screenshot_paths

            session_dir = self.create_session_folder_structure(session_id, screenshot_paths, url_data)
            uploaded_file = self.create_and_upload_session_archive(session_dir, session_id)

            if uploaded_file:
                for path in screenshot_paths:
                    if path and os.path.exists(path):
                        os.remove(path)
                return True, screenshot_paths
            else:
                self._update_status("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∞—Ä—Ö–∏–≤", -1)
                return False, screenshot_paths

        except Exception as e:
            self._update_status(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ URL {url}: {e}", -1)
            import traceback
            traceback.print_exc()
            
            failure_path = os.path.join(temp_screenshots_dir, f"FAILURE_screenshot.png")
            try:
                page.screenshot(path=failure_path, full_page=True, timeout=15000)
                self._update_status("    –°–∫—Ä–∏–Ω—à–æ—Ç –æ—à–∏–±–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω.", -1)
                screenshot_paths.append(failure_path)
            except Exception as e_scr:
                self._update_status(f"    –ù–µ —É–¥–∞–ª–æ—Å—å —Å–¥–µ–ª–∞—Ç—å —Å–∫—Ä–∏–Ω—à–æ—Ç –æ—à–∏–±–∫–∏: {e_scr}", -1)
            
            try:
                html_path = os.path.join(temp_screenshots_dir, f"FAILURE_page_content.html")
                with open(html_path, 'w', encoding='utf-8') as f:
                    f.write(page.content())
                self._update_status("    HTML –∫–æ–Ω—Ç–µ–Ω—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏.", -1)
            except Exception as e_html:
                self._update_status(f"    –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å HTML: {e_html}", -1)
            
            self.create_and_upload_session_archive(temp_screenshots_dir, session_id, is_failure=True)
            return False, screenshot_paths
        finally:
            if 'temp_screenshots_dir' in locals() and os.path.exists(temp_screenshots_dir):
                shutil.rmtree(temp_screenshots_dir, ignore_errors=True)
            if 'session_dir' in locals() and os.path.exists(session_dir):
                shutil.rmtree(session_dir, ignore_errors=True)

    def get_safety_settings(self):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –Ω–∞—Å—Ç—Ä–æ–µ–∫ —Ä–µ–∂–∏–º–∞ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏"""
        safety_mode = os.environ.get('SAFETY_MODE', 'normal').lower()
        settings = {
            'slow': {'min_delay': 3, 'max_delay': 8, 'batch_size': 10, 'batch_pause_min': 60, 'batch_pause_max': 120, 'name': '–ú–ï–î–õ–ï–ù–ù–´–ô'},
            'normal': {'min_delay': 2, 'max_delay': 5, 'batch_size': 20, 'batch_pause_min': 30, 'batch_pause_max': 60, 'name': '–û–ë–´–ß–ù–´–ô'},
            'fast': {'min_delay': 1, 'max_delay': 3, 'batch_size': 30, 'batch_pause_min': 15, 'batch_pause_max': 30, 'name': '–ë–´–°–¢–†–´–ô'}
        }
        return settings.get(safety_mode, settings['normal'])

    def get_url_count(self, total_urls):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ URL –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
        try:
            count = int(os.environ.get('URL_COUNT', total_urls))
            return min(count, total_urls)
        except ValueError:
            return total_urls

    def print_progress(self, current, total, start_time, successful, failed, timeouts):
        """–í—ã–≤–æ–¥ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ —Å ETA"""
        elapsed = time.time() - start_time
        percent = (current / total) * 100
        eta = "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
        if current > 0:
            avg_time = elapsed / current
            remaining = (total - current) * avg_time
            remaining_min = remaining / 60
            eta = f"{remaining_min / 60:.1f}—á" if remaining_min > 60 else f"{remaining_min:.1f}–º–∏–Ω"
        self._update_status(f"üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {current}/{total} ({percent:.1f}%) | ‚è≥ –û—Å—Ç–∞–ª–æ—Å—å: ~{eta}", -1)
        self._update_status(f"‚úÖ –£—Å–ø–µ—à–Ω–æ: {successful} | ‚ùå –û—à–∏–±–æ–∫: {failed} | ‚ùó –ó–∞–≤–∏—Å–∞–Ω–∏–π: {timeouts}", -1)
        cpu_percent = psutil.cpu_percent()
        memory = psutil.virtual_memory()
        self._update_status(f"üñ•Ô∏è CPU: {cpu_percent}% | üß† –ü–∞–º—è—Ç—å: {memory.percent}% –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∞", -1)

    def process_batch(self, urls_batch, safety_settings):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –±–∞—Ç—á–∞ URL"""
        batch_start_time = time.time()
        batch_successful, batch_failed, batch_timeouts = 0, 0, 0
        self._update_status(f"üöÄ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –±–∞—Ç—á–∞ –∏–∑ {len(urls_batch)} URL...", -1)
        result_queue = multiprocessing.Queue()
        collector_config = {
            "credentials_path": self.credentials_path,
            "gdrive_folder_id": self.gdrive_folder_id,
            "bq_project_id": self.bq_project_id,
            "bq_dataset_id": self.bq_dataset_id,
            "bq_table_id": self.bq_table_id,
            "min_duration_seconds": self.min_duration_seconds,
            "cookies_path": self.cookies_path
        }
        
        for i, url_data in enumerate(urls_batch, 1):
            self._update_status(f"‚ñ∂Ô∏è [{i}/{len(urls_batch)}] –ó–∞–ø—É—Å–∫–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å –¥–ª—è URL ...{url_data['url'][-40:]}", -1)
            process = multiprocessing.Process(target=worker_process_url, args=(collector_config, url_data, result_queue))
            process.start()
            process.join(timeout=PROCESS_TIMEOUT_PER_URL)
            
            if process.is_alive():
                self._update_status(f"‚ùó –¢–ê–ô–ú–ê–£–¢! –ü—Ä–æ—Ü–µ—Å—Å –¥–ª—è URL ...{url_data['url'][-40:]} –∑–∞–≤–∏—Å. –ó–∞–≤–µ—Ä—à–∞–µ–º.", -1)
                process.terminate()
                process.join()
                batch_timeouts += 1
                batch_failed += 1
                self.mark_url_as_processed(url_data['url'], success=False)
            else:
                try:
                    success = result_queue.get_nowait()
                    if success:
                        batch_successful += 1
                    else:
                        batch_failed += 1
                except queue.Empty:
                    batch_failed += 1
                    self.mark_url_as_processed(url_data['url'], success=False)
            
            if i < len(urls_batch):
                delay = random.uniform(safety_settings['min_delay'], safety_settings['max_delay'])
                self._update_status(f"‚è±Ô∏è –ü–∞—É–∑–∞ {delay:.1f} —Å–µ–∫...", -1)
                time.sleep(delay)
            
            if i % 5 == 0 or i == len(urls_batch):
                self.print_progress(i, len(urls_batch), batch_start_time, batch_successful, batch_failed, batch_timeouts)
        
        self.total_processed += len(urls_batch)
        self.total_successful += batch_successful
        self.total_failed += batch_failed
        self.total_timeouts += batch_timeouts
        batch_time = time.time() - batch_start_time
        self._update_status(f"üì¶ –ë–∞—Ç—á –∑–∞–≤–µ—Ä—à–µ–Ω –∑–∞ {batch_time/60:.1f} –º–∏–Ω. [–£—Å–ø–µ—à–Ω–æ: {batch_successful}, –û—à–∏–±–æ–∫: {batch_failed}, –ó–∞–≤–∏—Å–∞–Ω–∏–π: {batch_timeouts}]", -1)
        
    def run(self):
        """–ó–∞–ø—É—Å–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
        self.start_time = time.time()
        self._update_status("üöÄ –°–ë–û–†–©–ò–ö –°–ö–†–ò–ù–®–û–¢–û–í SESSION REPLAY", 10)
        self._update_status("BigQuery ‚Üí Screenshots ‚Üí Google Drive", -1)
        
        safety_settings = self.get_safety_settings()
        self._update_status(f"üõ°Ô∏è –†–µ–∂–∏–º –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏: {safety_settings['name']}", -1)
        self._update_status(f"‚è±Ô∏è –¢–∞–π–º–∞—É—Ç –Ω–∞ 1 URL: {PROCESS_TIMEOUT_PER_URL} —Å–µ–∫", -1)
        self._update_status(f"‚òÅÔ∏è Google Drive –ø–∞–ø–∫–∞: {self.gdrive_folder_id}", -1)

        urls_data = self.get_unprocessed_urls()
        if not urls_data:
            self._update_status("üéâ –í—Å–µ URL —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã!", -1)
            return

        count_to_process = self.get_url_count(len(urls_data))
        urls_to_process = urls_data[:count_to_process]
        self._update_status(f"üéØ –ë—É–¥–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {len(urls_to_process)} URL", -1)

        try:
            for i in range(0, len(urls_to_process), safety_settings['batch_size']):
                batch = urls_to_process[i:i + safety_settings['batch_size']]
                self.process_batch(batch, safety_settings)
                if i + safety_settings['batch_size'] < len(urls_to_process):
                    batch_pause = random.uniform(safety_settings['batch_pause_min'], safety_settings['batch_pause_max'])
                    self._update_status(f"‚è∏Ô∏è –ü–∞—É–∑–∞ –º–µ–∂–¥—É –±–∞—Ç—á–∞–º–∏: {batch_pause:.1f} —Å–µ–∫...", -1)
                    time.sleep(batch_pause)
        except KeyboardInterrupt:
            self._update_status("‚ö†Ô∏è –ü–æ–ª—É—á–µ–Ω —Å–∏–≥–Ω–∞–ª –æ—Å—Ç–∞–Ω–æ–≤–∫–∏.", -1)
        except Exception as e:
            self._update_status(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}", -1)
            import traceback
            traceback.print_exc()
        self.print_overall_stats()

    def print_overall_stats(self):
        """–í—ã–≤–æ–¥ –æ–±—â–µ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
        if self.start_time:
            elapsed = time.time() - self.start_time
            elapsed_hours = elapsed / 3600
            success_rate = (self.total_successful / self.total_processed * 100) if self.total_processed > 0 else 0
            self._update_status("=" * 60, -1)
            self._update_status("üìä –û–ë–©–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê –†–ê–ë–û–¢–´", -1)
            self._update_status(f"‚è±Ô∏è –í—Ä–µ–º—è —Ä–∞–±–æ—Ç—ã: {elapsed_hours:.1f} —á–∞—Å–æ–≤", -1)
            self._update_status(f"üìà –í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {self.total_processed} URL", -1)
            self._update_status(f"‚úÖ –£—Å–ø–µ—à–Ω–æ: {self.total_successful}", -1)
            self._update_status(f"‚ùå –û—à–∏–±–æ–∫: {self.total_failed}", -1)
            self._update_status(f"‚ùó –ó–∞–≤–∏—Å–∞–Ω–∏–π (Timeout): {self.total_timeouts}", -1)
            self._update_status(f"üìä –ü—Ä–æ—Ü–µ–Ω—Ç —É—Å–ø–µ—Ö–∞: {success_rate:.1f}%", -1)
            if self.total_processed > 0:
                avg_time_per_url = elapsed / self.total_processed
                self._update_status(f"‚ö° –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –Ω–∞ URL: {avg_time_per_url:.1f} —Å–µ–∫", -1)
            self._update_status("=" * 60, -1)

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    if sys.platform != 'win32':
        multiprocessing.set_start_method('spawn', force=True)
    multiprocessing.freeze_support()
    try:
        collector = RenderScreenshotCollector()
        collector.run()
    except Exception as e:
        print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()