from fastapi import FastAPI, BackgroundTasks, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from contextlib import asynccontextmanager
import schedule
import time
import threading
import logging
import os
from datetime import datetime
import pytz
from typing import Dict, Any

from app.endpoints import router, run_script_safe

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# --- –ù–û–í–û–ï: –•—Ä–∞–Ω–∏–ª–∏—â–µ —Å—Ç–∞—Ç—É—Å–æ–≤ –∑–∞–¥–∞—á ---
# –ö–ª—é—á - task_id, –∑–Ω–∞—á–µ–Ω–∏–µ - –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∑–∞–¥–∞—á–µ
task_statuses: Dict[str, Any] = {}
# ----------------------------------------

# –ì–ª–æ–±–∞–ª—å–Ω–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–æ–º
scheduler_running = True
moscow_tz = pytz.timezone("Europe/Moscow")

def run_daily_analytics_pipeline():
    """–ï–∂–µ–¥–Ω–µ–≤–Ω—ã–π –∑–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞ –∞–Ω–∞–ª–∏—Ç–∏–∫–∏"""
    logger.info("üöÄ –ó–∞–ø—É—Å–∫ –µ–∂–µ–¥–Ω–µ–≤–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞ –∞–Ω–∞–ª–∏—Ç–∏–∫–∏")
    
    pipeline_steps = [
        ("scripts/1_collect_links_put_gbq.py", "–°–±–æ—Ä Session Replay —Å—Å—ã–ª–æ–∫"),
        ("scripts/2_replay_ai_gbq.py", "–°–æ–∑–¥–∞–Ω–∏–µ —Å–∫—Ä–∏–Ω—à–æ—Ç–æ–≤"),
        ("scripts/3_collect_replay_screens.py", "–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞"),
        ("scripts/4_get_clasters_gbq.py", "–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö"),
        ("scripts/5_summarazing.py", "–°–æ–∑–¥–∞–Ω–∏–µ —Å–∞–º–º–∞—Ä–∏")
    ]
    
    results = []
    total_start = datetime.now(moscow_tz)
    
    for script_path, step_name in pipeline_steps:
        logger.info(f"üìù –í—ã–ø–æ–ª–Ω—è–µ–º —ç—Ç–∞–ø: {step_name}")
        step_start = datetime.now(moscow_tz)
        
        try:
            # –ü—Ä–∏–º–µ—á–∞–Ω–∏–µ: –¥–ª—è –µ–∂–µ–¥–Ω–µ–≤–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞ –º–æ–∂–Ω–æ –æ—Å—Ç–∞–≤–∏—Ç—å —Å—Ç–∞—Ä—ã–π –∑–∞–ø—É—Å–∫
            # –∏–ª–∏ –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å –Ω–æ–≤—É—é —Å–∏—Å—Ç–µ–º—É –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –∏ —Å—é–¥–∞.
            # –ü–æ–∫–∞ –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å –¥–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã.
            result = run_script_safe(script_path, step_name)
            result["step_name"] = step_name
            results.append(result)
            
            step_end = datetime.now(moscow_tz)
            step_duration = (step_end - step_start).total_seconds()
            
            if result["status"] == "success":
                logger.info(f"‚úÖ {step_name} –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ –∑–∞ {step_duration:.1f} —Å–µ–∫")
            else:
                logger.error(f"‚ùå {step_name} –∑–∞–≤–µ—Ä—à–µ–Ω —Å –æ—à–∏–±–∫–æ–π: {result.get('message', 'Unknown error')}")
                break
                
        except Exception as e:
            logger.error(f"üí• –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ —ç—Ç–∞–ø–µ {step_name}: {str(e)}")
            results.append({
                "status": "critical_error",
                "step_name": step_name,
                "error": str(e),
                "start_time": step_start.isoformat(),
                "end_time": datetime.now(moscow_tz).isoformat()
            })
            break
    
    total_end = datetime.now(moscow_tz)
    total_duration = (total_end - total_start).total_seconds()
    
    successful_steps = len([r for r in results if r["status"] == "success"])
    
    pipeline_result = {
        "pipeline_status": "completed" if successful_steps == len(pipeline_steps) else "failed",
        "total_duration_seconds": total_duration,
        "start_time": total_start.isoformat(),
        "end_time": total_end.isoformat(),
        "successful_steps": successful_steps,
        "total_steps": len(results),
        "steps_results": results
    }
    
    logger.info(f"üèÅ –ü–∞–π–ø–ª–∞–π–Ω –∑–∞–≤–µ—Ä—à–µ–Ω: {successful_steps}/{len(pipeline_steps)} —ç—Ç–∞–ø–æ–≤ —É—Å–ø–µ—à–Ω–æ")
    logger.info(f"‚è±Ô∏è –û–±—â–µ–µ –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {total_duration/60:.1f} –º–∏–Ω—É—Ç")
    
    return pipeline_result

def run_scheduler():
    """–ó–∞–ø—É—Å–∫ –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞ –∑–∞–¥–∞—á –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ"""
    logger.info("‚è∞ –ü–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ –∑–∞–¥–∞—á –∑–∞–ø—É—â–µ–Ω")
    
    while scheduler_running:
        try:
            schedule.run_pending()
            time.sleep(60)
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≤ –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–µ: {str(e)}")
            time.sleep(60)

@asynccontextmanager
async def lifespan(app: FastAPI):
    """–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∂–∏–∑–Ω–µ–Ω–Ω—ã–º —Ü–∏–∫–ª–æ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"""
    schedule.every().day.at("06:00").do(run_daily_analytics_pipeline)
    
    scheduler_thread = threading.Thread(target=run_scheduler, daemon=True)
    scheduler_thread.start()
    
    logger.info("üöÄ –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –∑–∞–ø—É—â–µ–Ω–æ")
    logger.info("üìÖ –ï–∂–µ–¥–Ω–µ–≤–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω: –∫–∞–∂–¥—ã–π –¥–µ–Ω—å –≤ 09:00 MSK")
    
    yield
    
    global scheduler_running
    scheduler_running = False
    logger.info("üõë –ü–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")

app = FastAPI(
    title="üìä Analytics Scripts API",
    description="""
    ## üöÄ –ê–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏—Ö —Å–∫—Ä–∏–ø—Ç–æ–≤ Session Replay
    
    –°–∏—Å—Ç–µ–º–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ Session Replay –¥–∞–Ω–Ω—ã—Ö.
    """,
    version="1.0.0",
    lifespan=lifespan,
    docs_url="/docs",
    redoc_url="/redoc"
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

app.include_router(router, prefix="/api")

# --- –ù–û–í–´–ô –≠–ù–î–ü–û–ò–ù–¢ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å—Ç–∞—Ç—É—Å–∞ –∑–∞–¥–∞—á–∏ ---
@app.get("/api/task-status/{task_id}", tags=["üìä Monitoring"])
async def get_task_status(task_id: str):
    """
    –ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç—É—Å –∏ –ø—Ä–æ–≥—Ä–µ—Å—Å –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Ñ–æ–Ω–æ–≤–æ–π –∑–∞–¥–∞—á–∏.
    """
    status = task_statuses.get(task_id)
    if not status:
        raise HTTPException(status_code=404, detail="–ó–∞–¥–∞—á–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
    return status
# ----------------------------------------------------

@app.get("/", tags=["üìç General"])
async def root():
    """üè† –ì–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ API"""
    return {
        "service": "üìä Analytics Scripts API",
        "status": "üü¢ running",
        "version": "1.0.0",
        "description": "–ê–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è —Å–∫—Ä–∏–ø—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞ Session Replay",
        "scheduler_active": scheduler_running,
        "endpoints": {
            "üìà track_task": "/api/task-status/{task_id}",
            "üìñ documentation": "/docs"
        }
    }

@app.get("/health", tags=["üìç General"])
async def health_check():
    """üíä –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è —Å–µ—Ä–≤–∏—Å–∞"""
    return {
        "status": "üü¢ healthy",
        "timestamp": datetime.now().isoformat(),
        "scheduler_running": scheduler_running
    }

@app.get("/scheduler/status", tags=["‚è∞ Scheduler"])
async def scheduler_status():
    """‚è∞ –°—Ç–∞—Ç—É—Å –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞ –∏ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è"""
    jobs_info = []
    for job in schedule.jobs:
        jobs_info.append(str(job))
    
    return {
        "scheduler_running": scheduler_running,
        "jobs_count": len(schedule.jobs),
        "jobs": jobs_info
    }

if __name__ == "__main__":
    import uvicorn
    port = int(os.environ.get("PORT", 8000))
    uvicorn.run(app, host="0.0.0.0", port=port)