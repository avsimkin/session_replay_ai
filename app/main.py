from fastapi import FastAPI, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from contextlib import asynccontextmanager
import schedule
import time
import threading
import logging
import os
from datetime import datetime
import pytz
from typing import Dict, Any

from app.endpoints import router, run_script_safe

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# –ì–ª–æ–±–∞–ª—å–Ω–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–æ–º
scheduler_running = True
moscow_tz = pytz.timezone("Europe/Moscow")

def run_daily_analytics_pipeline():
    """–ï–∂–µ–¥–Ω–µ–≤–Ω—ã–π –∑–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞ –∞–Ω–∞–ª–∏—Ç–∏–∫–∏"""
    logger.info("üöÄ –ó–∞–ø—É—Å–∫ –µ–∂–µ–¥–Ω–µ–≤–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞ –∞–Ω–∞–ª–∏—Ç–∏–∫–∏")
    
    pipeline_steps = [
        ("scripts/collect_links_put_gbq.py", "–°–±–æ—Ä Session Replay —Å—Å—ã–ª–æ–∫"),
        ("scripts/replay_ai_gbq.py", "–°–æ–∑–¥–∞–Ω–∏–µ —Å–∫—Ä–∏–Ω—à–æ—Ç–æ–≤"),
        ("scripts/get_clasters_gbq.py", "–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö"),
        ("scripts/summarazing.py", "–°–æ–∑–¥–∞–Ω–∏–µ —Å–∞–º–º–∞—Ä–∏")
    ]
    
    results = []
    total_start = datetime.now(moscow_tz)
    
    for script_path, step_name in pipeline_steps:
        logger.info(f"üìù –í—ã–ø–æ–ª–Ω—è–µ–º —ç—Ç–∞–ø: {step_name}")
        step_start = datetime.now(moscow_tz)
        
        try:
            result = run_script_safe(script_path, step_name)
            result["step_name"] = step_name
            results.append(result)
            
            step_end = datetime.now(moscow_tz)
            step_duration = (step_end - step_start).total_seconds()
            
            if result["status"] == "success":
                logger.info(f"‚úÖ {step_name} –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ –∑–∞ {step_duration:.1f} —Å–µ–∫")
            else:
                logger.error(f"‚ùå {step_name} –∑–∞–≤–µ—Ä—à–µ–Ω —Å –æ—à–∏–±–∫–æ–π: {result.get('message', 'Unknown error')}")
                # –ü—Ä–∏ –æ—à–∏–±–∫–µ –ø—Ä–µ—Ä—ã–≤–∞–µ–º –ø–∞–π–ø–ª–∞–π–Ω
                break
                
        except Exception as e:
            logger.error(f"üí• –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ —ç—Ç–∞–ø–µ {step_name}: {str(e)}")
            results.append({
                "status": "critical_error",
                "step_name": step_name,
                "error": str(e),
                "start_time": step_start.isoformat(),
                "end_time": datetime.now(moscow_tz).isoformat()
            })
            break
    
    total_end = datetime.now(moscow_tz)
    total_duration = (total_end - total_start).total_seconds()
    
    # –§–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç
    successful_steps = len([r for r in results if r["status"] == "success"])
    total_steps = len(results)
    
    pipeline_result = {
        "pipeline_status": "completed" if successful_steps == len(pipeline_steps) else "failed",
        "total_duration_seconds": total_duration,
        "total_duration_minutes": total_duration / 60,
        "start_time": total_start.isoformat(),
        "end_time": total_end.isoformat(),
        "successful_steps": successful_steps,
        "total_steps": total_steps,
        "steps_results": results
    }
    
    logger.info(f"üèÅ –ü–∞–π–ø–ª–∞–π–Ω –∑–∞–≤–µ—Ä—à–µ–Ω: {successful_steps}/{len(pipeline_steps)} —ç—Ç–∞–ø–æ–≤ —É—Å–ø–µ—à–Ω–æ")
    logger.info(f"‚è±Ô∏è –û–±—â–µ–µ –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {total_duration/60:.1f} –º–∏–Ω—É—Ç")
    
    return pipeline_result

def run_scheduler():
    """–ó–∞–ø—É—Å–∫ –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞ –∑–∞–¥–∞—á –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ"""
    logger.info("‚è∞ –ü–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ –∑–∞–¥–∞—á –∑–∞–ø—É—â–µ–Ω")
    
    while scheduler_running:
        try:
            schedule.run_pending()
            time.sleep(60)  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—É—é –º–∏–Ω—É—Ç—É
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≤ –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–µ: {str(e)}")
            time.sleep(60)

@asynccontextmanager
async def lifespan(app: FastAPI):
    """–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∂–∏–∑–Ω–µ–Ω–Ω—ã–º —Ü–∏–∫–ª–æ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"""
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è
    # –û—Å–Ω–æ–≤–Ω–æ–π –ø–∞–π–ø–ª–∞–π–Ω –∫–∞–∂–¥—ã–π –¥–µ–Ω—å –≤ 09:00 MSK
    schedule.every().day.at("06:00").do(run_daily_analytics_pipeline)  # 09:00 MSK = 06:00 UTC
    
    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∑–∞–¥–∞—á–∏ (–ø–æ –∂–µ–ª–∞–Ω–∏—é)
    # schedule.every().day.at("18:00").do(lambda: run_script_safe("scripts/summarazing.py", "Evening Summary"))
    
    # –ó–∞–ø—É—Å–∫ –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ
    scheduler_thread = threading.Thread(target=run_scheduler, daemon=True)
    scheduler_thread.start()
    
    logger.info("üöÄ –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –∑–∞–ø—É—â–µ–Ω–æ")
    logger.info("üìÖ –ï–∂–µ–¥–Ω–µ–≤–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω: –∫–∞–∂–¥—ã–π –¥–µ–Ω—å –≤ 09:00 MSK")
    
    yield
    
    # –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞
    global scheduler_running
    scheduler_running = False
    logger.info("üõë –ü–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")

# –°–æ–∑–¥–∞–Ω–∏–µ FastAPI –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
app = FastAPI(
    title="Analytics Scripts API",
    description="API –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏ –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏—Ö —Å–∫—Ä–∏–ø—Ç–æ–≤ Session Replay",
    version="1.0.0",
    lifespan=lifespan
)

# CORS middleware –¥–ª—è –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞ (–µ—Å–ª–∏ –Ω—É–∂–µ–Ω)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ —Ä–æ—É—Ç–µ—Ä–æ–≤
app.include_router(router, prefix="/api")

@app.get("/")
async def root():
    """–ö–æ—Ä–Ω–µ–≤–æ–π endpoint"""
    return {
        "service": "Analytics Scripts API",
        "status": "running",
        "version": "1.0.0",
        "description": "–ê–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è —Å–∫—Ä–∏–ø—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞ Session Replay",
        "scheduler_active": scheduler_running,
        "scheduled_jobs": len(schedule.jobs),
        "current_time_utc": datetime.now().isoformat(),
        "current_time_msk": datetime.now(moscow_tz).isoformat(),
        "endpoints": {
            "collect_links": "/api/collect-links",
            "screenshots": "/api/replay-screenshots", 
            "clustering": "/api/clustering",
            "summarize": "/api/summarize",
            "full_pipeline": "/api/full-pipeline",
            "scripts_status": "/api/scripts/status",
            "scheduler_status": "/scheduler/status",
            "manual_pipeline": "/run/daily-pipeline"
        }
    }

@app.get("/health")
async def health_check():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è —Å–µ—Ä–≤–∏—Å–∞"""
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "scheduler_running": scheduler_running,
        "environment": os.environ.get("ENVIRONMENT", "production")
    }

@app.get("/scheduler/status")
async def scheduler_status():
    """–°—Ç–∞—Ç—É—Å –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞ –∏ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è"""
    jobs_info = []
    
    for job in schedule.jobs:
        try:
            next_run = job.next_run
            if next_run:
                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ –º–æ—Å–∫–æ–≤—Å–∫–æ–µ –≤—Ä–µ–º—è –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞
                next_run_msk = next_run.replace(tzinfo=pytz.UTC).astimezone(moscow_tz)
                next_run_str = next_run_msk.strftime("%Y-%m-%d %H:%M:%S MSK")
            else:
                next_run_str = "Not scheduled"
                
            jobs_info.append({
                "job_function": str(job.job_func.__name__),
                "interval": str(job.interval),
                "unit": str(job.unit),
                "next_run_utc": str(job.next_run) if job.next_run else None,
                "next_run_msk": next_run_str,
                "tags": list(job.tags) if job.tags else []
            })
        except Exception as e:
            jobs_info.append({
                "error": f"Error getting job info: {str(e)}"
            })
    
    return {
        "scheduler_running": scheduler_running,
        "jobs_count": len(schedule.jobs),
        "jobs": jobs_info,
        "current_time_utc": datetime.now().isoformat(),
        "current_time_msk": datetime.now(moscow_tz).isoformat()
    }

@app.post("/run/daily-pipeline")
async def run_daily_pipeline_manual(background_tasks: BackgroundTasks):
    """–†—É—á–Ω–æ–π –∑–∞–ø—É—Å–∫ –µ–∂–µ–¥–Ω–µ–≤–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞"""
    
    def execute_pipeline():
        logger.info("üéØ –†—É—á–Ω–æ–π –∑–∞–ø—É—Å–∫ –µ–∂–µ–¥–Ω–µ–≤–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞")
        return run_daily_analytics_pipeline()
    
    background_tasks.add_task(execute_pipeline)
    
    return {
        "message": "–ï–∂–µ–¥–Ω–µ–≤–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω –∑–∞–ø—É—â–µ–Ω –≤—Ä—É—á–Ω—É—é",
        "status": "queued", 
        "start_time": datetime.now().isoformat(),
        "estimated_duration_minutes": "10-30"
    }

@app.get("/logs")
async def get_recent_logs():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –ª–æ–≥–æ–≤ (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)"""
    # –í –ø—Ä–æ–¥–∞–∫—à–µ–Ω–µ –ª—É—á—à–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤–Ω–µ—à–Ω–µ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ (–Ω–∞–ø—Ä–∏–º–µ—Ä, —á–µ—Ä–µ–∑ Render Dashboard)
    return {
        "message": "–î–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –ª–æ–≥–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ Render Dashboard",
        "log_location": "Render Dashboard -> Service -> Logs",
        "note": "–í—Å–µ –ª–æ–≥–∏ –∑–∞–ø–∏—Å—ã–≤–∞—é—Ç—Å—è —á–µ—Ä–µ–∑ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π logger Python"
    }

if __name__ == "__main__":
    import uvicorn
    port = int(os.environ.get("PORT", 8000))
    uvicorn.run(app, host="0.0.0.0", port=port)